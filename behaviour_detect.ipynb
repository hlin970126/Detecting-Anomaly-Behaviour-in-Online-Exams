{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20664,"status":"ok","timestamp":1685082333007,"user":{"displayName":"凌豪","userId":"01537499298288856098"},"user_tz":-600},"id":"651B6PltGnYE","outputId":"eff62491-3536-4460-ca9c-7071597c1c26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TSW27Ju8ZgPk","executionInfo":{"status":"ok","timestamp":1685082333008,"user_tz":-600,"elapsed":6,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/My Drive\")\n","root_dir = \"/content/drive/My Drive/tensors\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"W4mT4P7Kaav6","executionInfo":{"status":"ok","timestamp":1685082333009,"user_tz":-600,"elapsed":6,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["import numpy as np\n","import os\n","\n","def get_training_data(data_path):\n","    # Labels dict\n","    behaviours = {'book': 0,\n","                'cell_phone': 1,\n","                'drink_water': 2,\n","                'speaking': 3,\n","                'stand_up': 4,\n","                'sit_down': 5,\n","                'face_up': 6,\n","                'face_down': 7,\n","                'face_left': 8,\n","                'face_right': 9,\n","                'face_upper_left': 10,\n","                'face_upper_right': 11,\n","                'face_lower_left': 12,\n","                'face_lower_right': 13,\n","                'hands_up': 14,\n","                'look_up': 15,\n","                'look_down': 16,\n","                'look_left': 17,\n","                'look_right': 18,\n","                'look_upper_left': 19,\n","                'look_upper_right': 20,\n","                'look_lower_left': 21,\n","                'look_lower_right': 22,\n","                'makefau1': 23,\n","                'makefau4': 24,\n","                'makefau5': 25,\n","                'makefau7': 26,\n","                'makefau9': 27,\n","                'makefau17': 28,\n","                'makefau23': 29,\n","                'makefau28': 30}\n","\n","    # initialize folder names to read from\n","    folder_names = []\n","    for k in behaviours:\n","        folder_names.append(k + '_frames')\n","\n","    # empty lists to store training data\n","    x_data = []\n","    y_data = []\n","\n","    # loop through folders to load data into lists\n","    for folder_name in folder_names:\n","        folder_path = os.path.join(data_path, folder_name)\n","        i = 0\n","        for file_name in os.listdir(folder_path):\n","            if file_name.endswith('.npz'):\n","                file_path = os.path.join(folder_path, file_name)\n","                data = np.load(file_path, allow_pickle=True)\n","                frames = data['frames']\n","                labels = data['labels']\n","                # ignore data that faces are not detected\n","                if len(frames) == 0 or len(labels) == 0:\n","                    continue\n","                x_data.append(frames)\n","                y_data.append(labels)\n","            i += 1\n","\n","    return x_data, y_data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"4fxHF5K5FVJZ","executionInfo":{"status":"ok","timestamp":1685082336745,"user_tz":-600,"elapsed":3741,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, TimeDistributed\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from keras.optimizers import Adam\n","\n","def define_model(input_shape, num_classes):\n","    # define the model architecture\n","\n","    cnn_model = Sequential()\n","    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n","    cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n","    cnn_model.add(Flatten())\n","\n","    model = Sequential()\n","    model.add(TimeDistributed(cnn_model, input_shape=(240, 64, 64, 1)))  \n","    model.add(LSTM(64))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    return model\n","\n","def model_training(x_data, y_data):\n","\n","    input_shape = x_data.shape\n","    num_classes = 31\n","    model = define_model(input_shape, num_classes)\n","\n","    # compile the model\n","    optimizer = Adam(learning_rate=0.001)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    # train the model\n","    model.fit(x_data, y_data, validation_split=0.2, epochs=30, batch_size=4)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIU96XM9cbAa"},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Reshape\n","from sklearn.preprocessing import MinMaxScaler\n","\n","def training(root_dir, data_batch_num):\n","    print(\"processing data batch {}\".format(data_batch_num))\n","\n","    x_data, y_data = get_training_data(root_dir + str(data_batch_num) + '/')\n","\n","    # Reshape each 3D array in x_data to a 2D array of shape (num_frames, img_height * img_width)\n","    x_data_2d = [x.reshape(x.shape[0], -1) for x in x_data]\n","\n","    # Normalize x_data_2d to the range [0, 1]\n","    scaler = MinMaxScaler()\n","    x_data_norm_2d = [scaler.fit_transform(x) for x in x_data_2d]\n","\n","    # Reshape each 2D array back to a 3D array of shape (num_frames, img_height, img_width)\n","    x_data = [x.reshape(x.shape[0], 64, 64) for x in x_data_norm_2d]\n","\n","    # find the maximum length of frames arrays\n","    max_length = max(len(frames) for frames in x_data)\n","\n","    # restrict the shape of x_data to become a 10 second video data of 24 fps\n","    if max_length > 240:\n","        x_data = x_data[:240]\n","\n","    # pad the frames arrays with zeros to 240 if less than 240\n","    x_padded = pad_sequences(x_data, maxlen=240, dtype='float32', padding='post', truncating='post')\n","\n","    # y_data squeeze\n","    y_data = [labels[0] for labels in y_data]\n","\n","    # reshape x_padded to have the correct shape for model input\n","    x_reshaped = np.reshape(x_padded, (len(x_data), 240, 64, 64, 1))\n","\n","    # transform into np array\n","    x_train = np.array(x_reshaped)\n","    print(x_train.shape)\n","    y_train = np.array(y_data)\n","\n","    y_train = to_categorical(y_train, num_classes=31)\n","\n","    # training\n","    model = model_training(x_train, y_train)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8550811,"status":"ok","timestamp":1684563174771,"user":{"displayName":"凌豪","userId":"01537499298288856098"},"user_tz":-600},"id":"w6VfI_gqJQHy","outputId":"ce45bef8-187b-4d47-95e3-d0a444549f58"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2282 - accuracy: 0.0833 - val_loss: 3.4594 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1590 - accuracy: 0.1250 - val_loss: 3.5228 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0706 - accuracy: 0.0833 - val_loss: 3.7493 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9810 - accuracy: 0.1250 - val_loss: 4.1199 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8693 - accuracy: 0.1250 - val_loss: 4.4649 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8044 - accuracy: 0.1250 - val_loss: 4.7107 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7546 - accuracy: 0.0833 - val_loss: 4.9314 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7058 - accuracy: 0.1250 - val_loss: 5.1400 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6742 - accuracy: 0.1250 - val_loss: 5.2876 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6337 - accuracy: 0.0833 - val_loss: 5.4634 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6040 - accuracy: 0.1250 - val_loss: 5.5959 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5845 - accuracy: 0.1250 - val_loss: 5.7474 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5698 - accuracy: 0.1250 - val_loss: 5.8820 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5467 - accuracy: 0.1667 - val_loss: 6.0097 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5257 - accuracy: 0.1667 - val_loss: 6.0994 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4983 - accuracy: 0.1667 - val_loss: 6.1918 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.4825 - accuracy: 0.2083 - val_loss: 6.2765 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4818 - accuracy: 0.1667 - val_loss: 6.3466 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4585 - accuracy: 0.1667 - val_loss: 6.4236 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4406 - accuracy: 0.2083 - val_loss: 6.4778 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4214 - accuracy: 0.2500 - val_loss: 6.5575 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4276 - accuracy: 0.2083 - val_loss: 6.6329 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4052 - accuracy: 0.2500 - val_loss: 6.7016 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3823 - accuracy: 0.2500 - val_loss: 6.7680 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3867 - accuracy: 0.1667 - val_loss: 6.8072 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3727 - accuracy: 0.2500 - val_loss: 6.8602 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3493 - accuracy: 0.2500 - val_loss: 6.8929 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3926 - accuracy: 0.1667 - val_loss: 6.9257 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3371 - accuracy: 0.2917 - val_loss: 6.9785 - val_accuracy: 0.0000e+00\n","processing data batch 76\n","Epoch 1/30\n","6/6 [==============================] - 3s 239ms/step - loss: 3.4656 - accuracy: 0.0417 - val_loss: 3.4648 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 32ms/step - loss: 3.3277 - accuracy: 0.0417 - val_loss: 3.4683 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3095 - accuracy: 0.1250 - val_loss: 3.4641 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2898 - accuracy: 0.1250 - val_loss: 3.5030 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2477 - accuracy: 0.0833 - val_loss: 3.5620 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2101 - accuracy: 0.0833 - val_loss: 3.6856 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1112 - accuracy: 0.0833 - val_loss: 3.9659 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9983 - accuracy: 0.1667 - val_loss: 4.3425 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9011 - accuracy: 0.1667 - val_loss: 4.6904 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8239 - accuracy: 0.1667 - val_loss: 4.9792 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.7523 - accuracy: 0.2083 - val_loss: 5.2711 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7229 - accuracy: 0.1667 - val_loss: 5.3630 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.7271 - accuracy: 0.1667 - val_loss: 5.3672 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7245 - accuracy: 0.1250 - val_loss: 5.3979 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6126 - accuracy: 0.1667 - val_loss: 5.5419 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5919 - accuracy: 0.1667 - val_loss: 5.7465 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5643 - accuracy: 0.2083 - val_loss: 5.9425 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5149 - accuracy: 0.2500 - val_loss: 6.1192 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4915 - accuracy: 0.2500 - val_loss: 6.2808 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4749 - accuracy: 0.2083 - val_loss: 6.4219 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4541 - accuracy: 0.2500 - val_loss: 6.5721 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4377 - accuracy: 0.2083 - val_loss: 6.6900 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4348 - accuracy: 0.2500 - val_loss: 6.8043 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4270 - accuracy: 0.2500 - val_loss: 6.8743 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4191 - accuracy: 0.2500 - val_loss: 6.9504 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4098 - accuracy: 0.2083 - val_loss: 7.0550 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4081 - accuracy: 0.2083 - val_loss: 7.1633 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.3967 - accuracy: 0.2083 - val_loss: 7.2278 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3942 - accuracy: 0.2083 - val_loss: 7.3189 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3934 - accuracy: 0.2500 - val_loss: 7.3896 - val_accuracy: 0.0000e+00\n","processing data batch 77\n","Epoch 1/30\n","6/6 [==============================] - 2s 127ms/step - loss: 3.4678 - accuracy: 0.0000e+00 - val_loss: 3.5115 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3801 - accuracy: 0.0417 - val_loss: 3.5392 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3591 - accuracy: 0.0417 - val_loss: 3.5860 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3326 - accuracy: 0.0833 - val_loss: 3.6601 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2713 - accuracy: 0.0833 - val_loss: 3.7665 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2164 - accuracy: 0.0833 - val_loss: 3.8968 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1732 - accuracy: 0.0417 - val_loss: 4.0522 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1234 - accuracy: 0.0417 - val_loss: 4.1675 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0865 - accuracy: 0.0417 - val_loss: 4.2625 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0680 - accuracy: 0.0833 - val_loss: 4.3649 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0392 - accuracy: 0.0417 - val_loss: 4.4653 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0318 - accuracy: 0.0417 - val_loss: 4.5359 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0120 - accuracy: 0.0833 - val_loss: 4.6402 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9975 - accuracy: 0.0417 - val_loss: 4.7382 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9947 - accuracy: 0.0417 - val_loss: 4.8426 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9774 - accuracy: 0.0417 - val_loss: 4.9120 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9742 - accuracy: 0.0417 - val_loss: 4.9574 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9635 - accuracy: 0.0833 - val_loss: 5.0262 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9577 - accuracy: 0.0417 - val_loss: 5.0876 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9567 - accuracy: 0.0417 - val_loss: 5.1737 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9512 - accuracy: 0.0417 - val_loss: 5.2547 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9468 - accuracy: 0.0833 - val_loss: 5.3168 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9371 - accuracy: 0.0833 - val_loss: 5.3965 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9397 - accuracy: 0.0417 - val_loss: 5.4971 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9365 - accuracy: 0.0417 - val_loss: 5.5600 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9325 - accuracy: 0.0417 - val_loss: 5.6184 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9329 - accuracy: 0.0833 - val_loss: 5.6985 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9295 - accuracy: 0.0417 - val_loss: 5.7552 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.9318 - accuracy: 0.0000e+00 - val_loss: 5.7823 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9286 - accuracy: 0.0000e+00 - val_loss: 5.8334 - val_accuracy: 0.0000e+00\n","processing data batch 78\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4693 - accuracy: 0.0000e+00 - val_loss: 3.4453 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3029 - accuracy: 0.0417 - val_loss: 3.4621 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2457 - accuracy: 0.0833 - val_loss: 3.5071 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1528 - accuracy: 0.0833 - val_loss: 3.6336 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0374 - accuracy: 0.0833 - val_loss: 3.9446 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.9028 - accuracy: 0.1250 - val_loss: 4.2557 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8173 - accuracy: 0.1250 - val_loss: 4.5226 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7423 - accuracy: 0.1250 - val_loss: 4.7750 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6827 - accuracy: 0.0833 - val_loss: 4.9361 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6096 - accuracy: 0.1250 - val_loss: 5.1348 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5537 - accuracy: 0.1250 - val_loss: 5.4202 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5011 - accuracy: 0.0833 - val_loss: 5.6487 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4601 - accuracy: 0.1250 - val_loss: 5.8519 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4467 - accuracy: 0.1250 - val_loss: 6.0653 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4174 - accuracy: 0.1667 - val_loss: 6.1302 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3954 - accuracy: 0.2083 - val_loss: 6.1800 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3633 - accuracy: 0.2917 - val_loss: 6.2894 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3428 - accuracy: 0.2917 - val_loss: 6.4071 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.3372 - accuracy: 0.2500 - val_loss: 6.5046 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3436 - accuracy: 0.2083 - val_loss: 6.5972 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3090 - accuracy: 0.2083 - val_loss: 6.6603 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2997 - accuracy: 0.2500 - val_loss: 6.7236 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2524 - accuracy: 0.3333 - val_loss: 6.8007 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2404 - accuracy: 0.2500 - val_loss: 6.8387 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2028 - accuracy: 0.3750 - val_loss: 6.8911 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1746 - accuracy: 0.3333 - val_loss: 6.9293 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1538 - accuracy: 0.3750 - val_loss: 6.9817 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1495 - accuracy: 0.2500 - val_loss: 7.0092 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1433 - accuracy: 0.2083 - val_loss: 6.8487 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0525 - accuracy: 0.3750 - val_loss: 7.0931 - val_accuracy: 0.0000e+00\n","processing data batch 79\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.5156 - accuracy: 0.0000e+00 - val_loss: 3.4539 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3037 - accuracy: 0.0417 - val_loss: 3.5206 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1926 - accuracy: 0.0833 - val_loss: 3.6942 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0664 - accuracy: 0.1250 - val_loss: 3.9757 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9341 - accuracy: 0.0833 - val_loss: 4.1963 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.8092 - accuracy: 0.1250 - val_loss: 4.4388 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6765 - accuracy: 0.2500 - val_loss: 4.7123 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5445 - accuracy: 0.2500 - val_loss: 4.9235 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4066 - accuracy: 0.2500 - val_loss: 5.1567 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3828 - accuracy: 0.2917 - val_loss: 5.3614 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3021 - accuracy: 0.3333 - val_loss: 5.4768 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2560 - accuracy: 0.3750 - val_loss: 5.5722 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1703 - accuracy: 0.4167 - val_loss: 5.7474 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1638 - accuracy: 0.3333 - val_loss: 5.9194 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0694 - accuracy: 0.4167 - val_loss: 6.0761 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9649 - accuracy: 0.5000 - val_loss: 6.1462 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8117 - accuracy: 0.5417 - val_loss: 6.2607 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6966 - accuracy: 0.5833 - val_loss: 6.3644 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5959 - accuracy: 0.5833 - val_loss: 6.4717 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4784 - accuracy: 0.5833 - val_loss: 6.5971 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3870 - accuracy: 0.5833 - val_loss: 6.6612 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3837 - accuracy: 0.5833 - val_loss: 6.6963 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3587 - accuracy: 0.5833 - val_loss: 6.7625 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3458 - accuracy: 0.5833 - val_loss: 6.8339 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3164 - accuracy: 0.5833 - val_loss: 6.9539 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3260 - accuracy: 0.5417 - val_loss: 6.9891 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3456 - accuracy: 0.5417 - val_loss: 6.8087 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4027 - accuracy: 0.5417 - val_loss: 6.4598 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.3915 - accuracy: 0.5417 - val_loss: 6.1204 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3221 - accuracy: 0.5833 - val_loss: 6.2861 - val_accuracy: 0.0000e+00\n","processing data batch 80\n","Epoch 1/30\n","6/6 [==============================] - 2s 120ms/step - loss: 3.4366 - accuracy: 0.0000e+00 - val_loss: 3.5168 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3623 - accuracy: 0.0833 - val_loss: 3.5874 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3167 - accuracy: 0.0833 - val_loss: 3.6781 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2633 - accuracy: 0.0833 - val_loss: 3.8532 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2049 - accuracy: 0.0417 - val_loss: 4.1180 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1164 - accuracy: 0.0417 - val_loss: 4.4704 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0457 - accuracy: 0.1250 - val_loss: 4.6791 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9816 - accuracy: 0.1250 - val_loss: 4.9554 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9263 - accuracy: 0.1250 - val_loss: 5.1005 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9030 - accuracy: 0.1250 - val_loss: 5.1815 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8615 - accuracy: 0.1250 - val_loss: 5.2790 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8526 - accuracy: 0.1250 - val_loss: 5.4312 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8260 - accuracy: 0.1250 - val_loss: 5.5529 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8123 - accuracy: 0.0833 - val_loss: 5.6913 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8008 - accuracy: 0.1667 - val_loss: 5.7662 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8030 - accuracy: 0.1250 - val_loss: 5.8754 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7874 - accuracy: 0.1250 - val_loss: 5.9795 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7682 - accuracy: 0.1250 - val_loss: 6.0635 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7699 - accuracy: 0.1250 - val_loss: 6.1229 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7597 - accuracy: 0.1250 - val_loss: 6.2122 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7485 - accuracy: 0.1250 - val_loss: 6.2754 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7420 - accuracy: 0.1667 - val_loss: 6.2514 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7361 - accuracy: 0.1667 - val_loss: 6.3699 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7300 - accuracy: 0.1250 - val_loss: 6.4243 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7339 - accuracy: 0.1250 - val_loss: 6.4741 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7277 - accuracy: 0.1250 - val_loss: 6.5531 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7218 - accuracy: 0.1667 - val_loss: 6.6308 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7164 - accuracy: 0.1667 - val_loss: 6.6409 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7176 - accuracy: 0.1667 - val_loss: 6.6160 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7136 - accuracy: 0.1250 - val_loss: 6.8425 - val_accuracy: 0.0000e+00\n","processing data batch 81\n","Epoch 1/30\n","6/6 [==============================] - 3s 130ms/step - loss: 3.5474 - accuracy: 0.0000e+00 - val_loss: 3.8837 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3777 - accuracy: 0.0417 - val_loss: 3.9463 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3216 - accuracy: 0.0417 - val_loss: 3.9990 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2687 - accuracy: 0.0833 - val_loss: 4.0698 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1953 - accuracy: 0.0833 - val_loss: 4.1469 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1140 - accuracy: 0.0833 - val_loss: 4.1733 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0204 - accuracy: 0.1250 - val_loss: 4.3229 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8552 - accuracy: 0.1667 - val_loss: 4.5369 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7338 - accuracy: 0.1250 - val_loss: 4.7199 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6333 - accuracy: 0.1250 - val_loss: 4.8863 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4876 - accuracy: 0.2083 - val_loss: 5.0280 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4261 - accuracy: 0.2917 - val_loss: 5.1540 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3652 - accuracy: 0.2917 - val_loss: 5.2130 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3317 - accuracy: 0.2500 - val_loss: 5.3243 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2601 - accuracy: 0.3333 - val_loss: 5.3796 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2278 - accuracy: 0.3750 - val_loss: 5.4274 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1526 - accuracy: 0.3750 - val_loss: 5.4733 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0728 - accuracy: 0.3333 - val_loss: 5.5759 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0325 - accuracy: 0.3750 - val_loss: 5.6652 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9723 - accuracy: 0.4167 - val_loss: 5.8263 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9632 - accuracy: 0.3333 - val_loss: 5.8281 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9280 - accuracy: 0.4167 - val_loss: 5.9014 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9127 - accuracy: 0.3750 - val_loss: 5.9234 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8918 - accuracy: 0.4167 - val_loss: 5.8433 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8605 - accuracy: 0.3750 - val_loss: 5.8196 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8554 - accuracy: 0.4167 - val_loss: 5.8775 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8495 - accuracy: 0.3750 - val_loss: 5.9057 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8229 - accuracy: 0.3750 - val_loss: 5.8603 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8131 - accuracy: 0.3750 - val_loss: 5.8837 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8012 - accuracy: 0.3750 - val_loss: 5.9394 - val_accuracy: 0.0000e+00\n","processing data batch 82\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5011 - accuracy: 0.0000e+00 - val_loss: 3.9407 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2801 - accuracy: 0.1250 - val_loss: 4.0102 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2200 - accuracy: 0.1250 - val_loss: 4.0774 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1321 - accuracy: 0.0833 - val_loss: 4.2061 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0405 - accuracy: 0.1250 - val_loss: 4.3813 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9421 - accuracy: 0.1250 - val_loss: 4.5589 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8175 - accuracy: 0.1667 - val_loss: 4.6585 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7006 - accuracy: 0.1667 - val_loss: 4.8788 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6139 - accuracy: 0.1250 - val_loss: 4.9951 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5153 - accuracy: 0.1667 - val_loss: 4.9402 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4852 - accuracy: 0.1667 - val_loss: 5.1647 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4086 - accuracy: 0.1667 - val_loss: 5.2770 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.3349 - accuracy: 0.1667 - val_loss: 5.2974 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2828 - accuracy: 0.2083 - val_loss: 5.3944 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2329 - accuracy: 0.3333 - val_loss: 5.5587 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1702 - accuracy: 0.3333 - val_loss: 5.5691 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1502 - accuracy: 0.3750 - val_loss: 5.6496 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0731 - accuracy: 0.3750 - val_loss: 5.8804 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0528 - accuracy: 0.4167 - val_loss: 5.7983 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0261 - accuracy: 0.3750 - val_loss: 5.7796 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9984 - accuracy: 0.3750 - val_loss: 5.9179 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9750 - accuracy: 0.4167 - val_loss: 5.9242 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9411 - accuracy: 0.3750 - val_loss: 5.8216 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9223 - accuracy: 0.3750 - val_loss: 5.8570 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9246 - accuracy: 0.3750 - val_loss: 5.9415 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9251 - accuracy: 0.4583 - val_loss: 6.0607 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8788 - accuracy: 0.3750 - val_loss: 6.3058 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8322 - accuracy: 0.4583 - val_loss: 6.5205 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1237 - accuracy: 0.4167 - val_loss: 6.4992 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0162 - accuracy: 0.4167 - val_loss: 6.5045 - val_accuracy: 0.0000e+00\n","processing data batch 83\n","Epoch 1/30\n","6/6 [==============================] - 2s 121ms/step - loss: 3.5279 - accuracy: 0.0000e+00 - val_loss: 3.6788 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2473 - accuracy: 0.1250 - val_loss: 3.7640 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.0986 - accuracy: 0.1250 - val_loss: 3.9224 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9511 - accuracy: 0.1667 - val_loss: 4.0789 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7674 - accuracy: 0.2917 - val_loss: 4.3759 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5353 - accuracy: 0.4167 - val_loss: 4.5881 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3090 - accuracy: 0.4167 - val_loss: 4.9423 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9678 - accuracy: 0.4583 - val_loss: 5.2641 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7155 - accuracy: 0.5417 - val_loss: 5.1381 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7558 - accuracy: 0.5000 - val_loss: 5.2140 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6049 - accuracy: 0.5417 - val_loss: 5.0429 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7091 - accuracy: 0.4583 - val_loss: 4.7793 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6194 - accuracy: 0.5000 - val_loss: 4.8373 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5181 - accuracy: 0.5000 - val_loss: 4.8124 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4757 - accuracy: 0.5000 - val_loss: 4.7678 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4595 - accuracy: 0.5417 - val_loss: 4.8054 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4092 - accuracy: 0.5417 - val_loss: 4.8631 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3914 - accuracy: 0.5417 - val_loss: 5.0167 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3699 - accuracy: 0.5000 - val_loss: 4.9061 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3521 - accuracy: 0.5417 - val_loss: 4.9694 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3211 - accuracy: 0.5417 - val_loss: 5.0743 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2939 - accuracy: 0.6250 - val_loss: 5.1513 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2664 - accuracy: 0.6250 - val_loss: 5.4176 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2493 - accuracy: 0.6250 - val_loss: 5.5072 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2353 - accuracy: 0.5833 - val_loss: 5.4574 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2194 - accuracy: 0.6250 - val_loss: 5.3557 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2128 - accuracy: 0.6250 - val_loss: 5.2726 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1926 - accuracy: 0.5833 - val_loss: 5.2834 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1827 - accuracy: 0.5833 - val_loss: 5.3399 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1697 - accuracy: 0.5833 - val_loss: 5.3894 - val_accuracy: 0.0000e+00\n","processing data batch 84\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.6156 - accuracy: 0.0000e+00 - val_loss: 3.5050 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3219 - accuracy: 0.0833 - val_loss: 3.5347 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2147 - accuracy: 0.1250 - val_loss: 3.5666 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1507 - accuracy: 0.1250 - val_loss: 3.5977 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0588 - accuracy: 0.1667 - val_loss: 3.6264 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9880 - accuracy: 0.2500 - val_loss: 3.6770 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8941 - accuracy: 0.2500 - val_loss: 3.6905 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8236 - accuracy: 0.2500 - val_loss: 3.7154 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7694 - accuracy: 0.2500 - val_loss: 3.7421 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6996 - accuracy: 0.2917 - val_loss: 3.7918 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6045 - accuracy: 0.3750 - val_loss: 3.8101 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4791 - accuracy: 0.3333 - val_loss: 3.8709 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3374 - accuracy: 0.3750 - val_loss: 3.9005 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2139 - accuracy: 0.4583 - val_loss: 4.1028 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0755 - accuracy: 0.4583 - val_loss: 4.4044 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8883 - accuracy: 0.5417 - val_loss: 4.7391 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4412 - accuracy: 0.6250 - val_loss: 4.4058 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9486 - accuracy: 0.6250 - val_loss: 4.5713 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6630 - accuracy: 0.6250 - val_loss: 4.6878 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5412 - accuracy: 0.6250 - val_loss: 4.9000 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4216 - accuracy: 0.6250 - val_loss: 5.1502 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3244 - accuracy: 0.7083 - val_loss: 5.4077 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2545 - accuracy: 0.7083 - val_loss: 5.5374 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1773 - accuracy: 0.6667 - val_loss: 5.6856 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1386 - accuracy: 0.6667 - val_loss: 5.8734 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1261 - accuracy: 0.6667 - val_loss: 5.9430 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0898 - accuracy: 0.7083 - val_loss: 6.1095 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3395 - accuracy: 0.6250 - val_loss: 6.2739 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3668 - accuracy: 0.6667 - val_loss: 6.2615 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2927 - accuracy: 0.6667 - val_loss: 5.6411 - val_accuracy: 0.0000e+00\n","processing data batch 85\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4582 - accuracy: 0.0000e+00 - val_loss: 3.5829 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3130 - accuracy: 0.0417 - val_loss: 3.6397 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2262 - accuracy: 0.0000e+00 - val_loss: 3.7023 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1019 - accuracy: 0.0417 - val_loss: 3.8708 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0226 - accuracy: 0.0417 - val_loss: 3.9843 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9201 - accuracy: 0.1250 - val_loss: 4.1359 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.8355 - accuracy: 0.1250 - val_loss: 4.2386 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7472 - accuracy: 0.1667 - val_loss: 4.3224 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7107 - accuracy: 0.1667 - val_loss: 4.3900 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6794 - accuracy: 0.2083 - val_loss: 4.5016 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6777 - accuracy: 0.1250 - val_loss: 4.5256 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6447 - accuracy: 0.2083 - val_loss: 4.6307 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6117 - accuracy: 0.1667 - val_loss: 4.4866 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6015 - accuracy: 0.1667 - val_loss: 4.3660 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5742 - accuracy: 0.2083 - val_loss: 4.3871 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5506 - accuracy: 0.1667 - val_loss: 4.6675 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5266 - accuracy: 0.2083 - val_loss: 4.7599 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5622 - accuracy: 0.1667 - val_loss: 4.7585 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5129 - accuracy: 0.2083 - val_loss: 4.7125 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5008 - accuracy: 0.2500 - val_loss: 4.7413 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4817 - accuracy: 0.2500 - val_loss: 4.8689 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5013 - accuracy: 0.2917 - val_loss: 4.9240 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5024 - accuracy: 0.2917 - val_loss: 4.9208 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4666 - accuracy: 0.2500 - val_loss: 4.8475 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4058 - accuracy: 0.2500 - val_loss: 4.8877 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4845 - accuracy: 0.2500 - val_loss: 4.8975 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4105 - accuracy: 0.2917 - val_loss: 4.8898 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5169 - accuracy: 0.2917 - val_loss: 4.9825 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4751 - accuracy: 0.2917 - val_loss: 4.9455 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4497 - accuracy: 0.2500 - val_loss: 4.9559 - val_accuracy: 0.0000e+00\n","processing data batch 86\n","Epoch 1/30\n","6/6 [==============================] - 3s 133ms/step - loss: 3.5959 - accuracy: 0.0000e+00 - val_loss: 3.6822 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.3357 - accuracy: 0.0833 - val_loss: 3.7454 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2354 - accuracy: 0.0833 - val_loss: 3.8208 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1402 - accuracy: 0.1250 - val_loss: 3.8992 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0119 - accuracy: 0.1667 - val_loss: 4.0193 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8322 - accuracy: 0.1667 - val_loss: 4.1833 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6893 - accuracy: 0.1667 - val_loss: 4.4328 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5642 - accuracy: 0.1667 - val_loss: 4.6751 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4746 - accuracy: 0.2083 - val_loss: 4.8446 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3733 - accuracy: 0.2917 - val_loss: 4.9228 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2522 - accuracy: 0.3333 - val_loss: 5.1095 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1710 - accuracy: 0.4167 - val_loss: 5.1700 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0787 - accuracy: 0.5417 - val_loss: 5.4712 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0940 - accuracy: 0.5000 - val_loss: 5.5389 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9808 - accuracy: 0.5000 - val_loss: 5.7468 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9312 - accuracy: 0.5417 - val_loss: 5.7402 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8655 - accuracy: 0.5000 - val_loss: 6.0157 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8579 - accuracy: 0.5417 - val_loss: 5.9182 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8543 - accuracy: 0.5417 - val_loss: 5.9391 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7796 - accuracy: 0.5833 - val_loss: 6.2821 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7596 - accuracy: 0.5417 - val_loss: 6.3253 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7548 - accuracy: 0.5000 - val_loss: 6.2254 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6976 - accuracy: 0.5833 - val_loss: 6.0126 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6366 - accuracy: 0.5417 - val_loss: 6.2325 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5908 - accuracy: 0.5417 - val_loss: 6.1178 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5608 - accuracy: 0.5000 - val_loss: 6.0870 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5219 - accuracy: 0.5000 - val_loss: 6.3311 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4721 - accuracy: 0.5417 - val_loss: 6.4349 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5043 - accuracy: 0.5833 - val_loss: 6.3108 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4658 - accuracy: 0.5833 - val_loss: 6.3029 - val_accuracy: 0.0000e+00\n","processing data batch 87\n","Epoch 1/30\n","6/6 [==============================] - 2s 127ms/step - loss: 3.6731 - accuracy: 0.0000e+00 - val_loss: 3.4398 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.4070 - accuracy: 0.0417 - val_loss: 3.4643 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3343 - accuracy: 0.0833 - val_loss: 3.5225 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2351 - accuracy: 0.0833 - val_loss: 3.6643 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1149 - accuracy: 0.1250 - val_loss: 3.9207 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9520 - accuracy: 0.1667 - val_loss: 4.2392 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8309 - accuracy: 0.2083 - val_loss: 4.5411 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7228 - accuracy: 0.2083 - val_loss: 4.8811 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5971 - accuracy: 0.1667 - val_loss: 5.0669 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5077 - accuracy: 0.2083 - val_loss: 5.2552 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4070 - accuracy: 0.2917 - val_loss: 5.4613 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3096 - accuracy: 0.3333 - val_loss: 5.6262 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1825 - accuracy: 0.4167 - val_loss: 5.7606 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1032 - accuracy: 0.5000 - val_loss: 5.8186 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0102 - accuracy: 0.4583 - val_loss: 5.9002 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8978 - accuracy: 0.5000 - val_loss: 6.0006 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8079 - accuracy: 0.5833 - val_loss: 6.0867 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6483 - accuracy: 0.5000 - val_loss: 6.1670 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5030 - accuracy: 0.5833 - val_loss: 6.2854 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2701 - accuracy: 0.6250 - val_loss: 6.4103 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1851 - accuracy: 0.6250 - val_loss: 6.4878 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.0815 - accuracy: 0.6667 - val_loss: 6.5777 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0248 - accuracy: 0.6667 - val_loss: 6.6648 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9788 - accuracy: 0.6667 - val_loss: 6.8211 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9508 - accuracy: 0.6667 - val_loss: 6.9266 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9228 - accuracy: 0.7083 - val_loss: 6.4920 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9795 - accuracy: 0.6667 - val_loss: 6.3885 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9476 - accuracy: 0.7083 - val_loss: 6.5147 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9262 - accuracy: 0.7500 - val_loss: 6.4250 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9089 - accuracy: 0.7083 - val_loss: 5.4636 - val_accuracy: 0.0000e+00\n","processing data batch 88\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.4583 - accuracy: 0.0000e+00 - val_loss: 3.9843 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2662 - accuracy: 0.0417 - val_loss: 4.0485 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.1952 - accuracy: 0.0417 - val_loss: 4.1474 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1121 - accuracy: 0.0833 - val_loss: 4.2872 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9811 - accuracy: 0.1250 - val_loss: 4.3809 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8826 - accuracy: 0.0833 - val_loss: 4.5210 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7683 - accuracy: 0.2083 - val_loss: 4.6171 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6585 - accuracy: 0.2083 - val_loss: 4.7214 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5804 - accuracy: 0.2500 - val_loss: 4.8421 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4743 - accuracy: 0.2917 - val_loss: 4.9945 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4088 - accuracy: 0.3333 - val_loss: 5.1370 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3289 - accuracy: 0.2917 - val_loss: 5.2875 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2705 - accuracy: 0.2917 - val_loss: 5.4165 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2427 - accuracy: 0.3333 - val_loss: 5.5013 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1604 - accuracy: 0.3750 - val_loss: 5.5214 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1948 - accuracy: 0.3333 - val_loss: 5.4495 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3583 - accuracy: 0.2917 - val_loss: 5.3602 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2342 - accuracy: 0.2500 - val_loss: 5.3102 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1649 - accuracy: 0.3333 - val_loss: 5.6401 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1576 - accuracy: 0.3333 - val_loss: 5.6134 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1126 - accuracy: 0.3333 - val_loss: 5.5511 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2673 - accuracy: 0.3333 - val_loss: 5.6207 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1529 - accuracy: 0.2500 - val_loss: 5.9345 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1208 - accuracy: 0.3750 - val_loss: 5.8725 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1038 - accuracy: 0.3750 - val_loss: 5.9582 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0909 - accuracy: 0.3333 - val_loss: 6.0335 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1147 - accuracy: 0.3750 - val_loss: 6.0573 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0708 - accuracy: 0.3750 - val_loss: 5.8528 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0480 - accuracy: 0.4167 - val_loss: 5.8522 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0146 - accuracy: 0.4167 - val_loss: 5.9752 - val_accuracy: 0.0000e+00\n","processing data batch 89\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5617 - accuracy: 0.0000e+00 - val_loss: 3.6763 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4079 - accuracy: 0.0417 - val_loss: 3.8684 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2725 - accuracy: 0.1250 - val_loss: 4.0082 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1959 - accuracy: 0.1250 - val_loss: 4.2694 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0757 - accuracy: 0.1250 - val_loss: 4.3712 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9507 - accuracy: 0.1667 - val_loss: 4.4119 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8694 - accuracy: 0.0833 - val_loss: 4.5149 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8161 - accuracy: 0.1250 - val_loss: 4.6192 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7192 - accuracy: 0.1667 - val_loss: 4.6531 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6319 - accuracy: 0.1667 - val_loss: 4.7316 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5494 - accuracy: 0.1667 - val_loss: 4.7682 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5055 - accuracy: 0.1667 - val_loss: 4.7705 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3865 - accuracy: 0.2917 - val_loss: 4.6021 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2730 - accuracy: 0.2917 - val_loss: 4.5544 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2101 - accuracy: 0.2500 - val_loss: 4.6847 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0982 - accuracy: 0.4167 - val_loss: 4.4935 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0021 - accuracy: 0.5000 - val_loss: 4.4264 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8714 - accuracy: 0.5417 - val_loss: 4.6517 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7291 - accuracy: 0.5417 - val_loss: 4.7074 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6478 - accuracy: 0.5417 - val_loss: 4.6581 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6090 - accuracy: 0.5417 - val_loss: 4.7597 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5352 - accuracy: 0.5417 - val_loss: 4.9238 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5229 - accuracy: 0.5417 - val_loss: 5.1127 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5036 - accuracy: 0.5417 - val_loss: 5.3151 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4709 - accuracy: 0.5417 - val_loss: 5.3389 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4447 - accuracy: 0.5417 - val_loss: 5.3440 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4346 - accuracy: 0.5000 - val_loss: 5.4991 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4075 - accuracy: 0.5417 - val_loss: 5.5204 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3913 - accuracy: 0.5000 - val_loss: 5.4806 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3826 - accuracy: 0.5000 - val_loss: 5.4271 - val_accuracy: 0.0000e+00\n","processing data batch 90\n","Epoch 1/30\n","6/6 [==============================] - 2s 122ms/step - loss: 3.7883 - accuracy: 0.0000e+00 - val_loss: 3.4449 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4766 - accuracy: 0.0417 - val_loss: 3.4485 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3723 - accuracy: 0.1250 - val_loss: 3.4562 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2911 - accuracy: 0.1250 - val_loss: 3.4633 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2093 - accuracy: 0.1250 - val_loss: 3.4703 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1406 - accuracy: 0.1250 - val_loss: 3.4763 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0846 - accuracy: 0.1667 - val_loss: 3.4825 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0066 - accuracy: 0.1667 - val_loss: 3.4861 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9401 - accuracy: 0.1667 - val_loss: 3.4895 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8714 - accuracy: 0.1667 - val_loss: 3.4935 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7838 - accuracy: 0.2083 - val_loss: 3.5272 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6719 - accuracy: 0.2083 - val_loss: 3.6415 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5623 - accuracy: 0.2083 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4733 - accuracy: 0.2083 - val_loss: 4.0003 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3963 - accuracy: 0.2083 - val_loss: 4.2332 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3430 - accuracy: 0.2500 - val_loss: 4.4408 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2973 - accuracy: 0.2083 - val_loss: 4.6753 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2488 - accuracy: 0.2500 - val_loss: 4.9532 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1988 - accuracy: 0.2500 - val_loss: 5.2755 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1378 - accuracy: 0.2083 - val_loss: 5.5883 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0829 - accuracy: 0.2500 - val_loss: 5.8029 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7188 - accuracy: 0.2917 - val_loss: 3.5052 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7303 - accuracy: 0.2917 - val_loss: 3.4197 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5413 - accuracy: 0.2917 - val_loss: 3.4881 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3625 - accuracy: 0.2917 - val_loss: 3.6853 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2561 - accuracy: 0.3333 - val_loss: 3.9144 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1688 - accuracy: 0.3750 - val_loss: 4.1647 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0984 - accuracy: 0.3750 - val_loss: 4.4082 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0531 - accuracy: 0.3333 - val_loss: 4.6121 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0072 - accuracy: 0.3333 - val_loss: 4.7800 - val_accuracy: 0.0000e+00\n","processing data batch 91\n","Epoch 1/30\n","6/6 [==============================] - 3s 130ms/step - loss: 3.4833 - accuracy: 0.0000e+00 - val_loss: 3.5678 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3398 - accuracy: 0.0417 - val_loss: 3.6426 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3018 - accuracy: 0.0833 - val_loss: 3.6993 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2685 - accuracy: 0.1250 - val_loss: 3.7656 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2379 - accuracy: 0.0833 - val_loss: 3.8581 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2020 - accuracy: 0.0833 - val_loss: 3.9820 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1350 - accuracy: 0.1250 - val_loss: 4.1193 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0656 - accuracy: 0.1250 - val_loss: 4.3000 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9758 - accuracy: 0.1250 - val_loss: 4.4891 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8843 - accuracy: 0.1667 - val_loss: 4.6720 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7966 - accuracy: 0.2083 - val_loss: 4.9027 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7004 - accuracy: 0.1667 - val_loss: 5.1411 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6291 - accuracy: 0.2083 - val_loss: 5.3677 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5624 - accuracy: 0.1667 - val_loss: 5.5536 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4890 - accuracy: 0.2083 - val_loss: 5.6754 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4303 - accuracy: 0.2500 - val_loss: 5.7600 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3813 - accuracy: 0.2917 - val_loss: 5.8378 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3229 - accuracy: 0.2917 - val_loss: 5.8440 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2854 - accuracy: 0.2500 - val_loss: 5.8498 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2614 - accuracy: 0.2500 - val_loss: 5.8215 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2362 - accuracy: 0.2500 - val_loss: 5.7940 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2143 - accuracy: 0.2083 - val_loss: 5.7981 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1398 - accuracy: 0.2917 - val_loss: 5.7687 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1717 - accuracy: 0.2083 - val_loss: 5.8025 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1303 - accuracy: 0.2917 - val_loss: 5.8570 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0864 - accuracy: 0.3333 - val_loss: 5.8495 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0972 - accuracy: 0.2500 - val_loss: 5.9016 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0461 - accuracy: 0.2917 - val_loss: 5.9817 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0101 - accuracy: 0.2917 - val_loss: 5.9665 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0100 - accuracy: 0.2917 - val_loss: 6.0328 - val_accuracy: 0.0000e+00\n","processing data batch 92\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.5074 - accuracy: 0.0000e+00 - val_loss: 3.4507 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3377 - accuracy: 0.0417 - val_loss: 3.4563 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2538 - accuracy: 0.0417 - val_loss: 3.4784 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1759 - accuracy: 0.0833 - val_loss: 3.5495 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0574 - accuracy: 0.0417 - val_loss: 3.8306 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8937 - accuracy: 0.0833 - val_loss: 4.1159 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8113 - accuracy: 0.1250 - val_loss: 4.4174 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6680 - accuracy: 0.0833 - val_loss: 4.5995 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5490 - accuracy: 0.2083 - val_loss: 4.8126 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4295 - accuracy: 0.2917 - val_loss: 5.0030 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3200 - accuracy: 0.3333 - val_loss: 5.2569 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2698 - accuracy: 0.3333 - val_loss: 5.4220 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1591 - accuracy: 0.3333 - val_loss: 5.6502 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1697 - accuracy: 0.5000 - val_loss: 5.7939 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1563 - accuracy: 0.4167 - val_loss: 5.8563 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0516 - accuracy: 0.4583 - val_loss: 5.9694 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0079 - accuracy: 0.4583 - val_loss: 6.0485 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.9704 - accuracy: 0.5000 - val_loss: 6.1170 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9437 - accuracy: 0.4167 - val_loss: 6.2043 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8500 - accuracy: 0.5000 - val_loss: 6.2746 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8110 - accuracy: 0.5000 - val_loss: 6.3861 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7558 - accuracy: 0.5000 - val_loss: 6.4265 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7348 - accuracy: 0.4583 - val_loss: 6.2017 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6913 - accuracy: 0.5000 - val_loss: 6.2337 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6522 - accuracy: 0.5000 - val_loss: 6.3356 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6268 - accuracy: 0.5000 - val_loss: 6.3146 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5888 - accuracy: 0.5417 - val_loss: 6.4603 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5849 - accuracy: 0.5417 - val_loss: 5.9006 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5901 - accuracy: 0.5417 - val_loss: 5.9447 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5766 - accuracy: 0.4583 - val_loss: 6.1539 - val_accuracy: 0.0000e+00\n","processing data batch 93\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5320 - accuracy: 0.0000e+00 - val_loss: 3.5223 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.4152 - accuracy: 0.0417 - val_loss: 3.5455 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3585 - accuracy: 0.0417 - val_loss: 3.5745 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3094 - accuracy: 0.0833 - val_loss: 3.6397 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2556 - accuracy: 0.0833 - val_loss: 3.7180 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2090 - accuracy: 0.0833 - val_loss: 3.8073 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1585 - accuracy: 0.1667 - val_loss: 3.9206 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1050 - accuracy: 0.1250 - val_loss: 4.0408 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9992 - accuracy: 0.1667 - val_loss: 4.1897 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9199 - accuracy: 0.1667 - val_loss: 4.3251 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8344 - accuracy: 0.1667 - val_loss: 4.4085 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7685 - accuracy: 0.1667 - val_loss: 4.4628 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6948 - accuracy: 0.2083 - val_loss: 4.5266 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6386 - accuracy: 0.1667 - val_loss: 4.5990 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6013 - accuracy: 0.1667 - val_loss: 4.7037 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5711 - accuracy: 0.2083 - val_loss: 4.7739 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5212 - accuracy: 0.2500 - val_loss: 4.8680 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4963 - accuracy: 0.2083 - val_loss: 4.9925 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4669 - accuracy: 0.2083 - val_loss: 5.0660 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4562 - accuracy: 0.2083 - val_loss: 5.0995 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4219 - accuracy: 0.2083 - val_loss: 5.2223 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4273 - accuracy: 0.2500 - val_loss: 5.2865 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3902 - accuracy: 0.2500 - val_loss: 5.3972 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3830 - accuracy: 0.2917 - val_loss: 5.4551 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3578 - accuracy: 0.2500 - val_loss: 5.5454 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3617 - accuracy: 0.2500 - val_loss: 5.6014 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3390 - accuracy: 0.2083 - val_loss: 5.6131 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3513 - accuracy: 0.2917 - val_loss: 5.6345 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3334 - accuracy: 0.2500 - val_loss: 5.6994 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3175 - accuracy: 0.2917 - val_loss: 5.7447 - val_accuracy: 0.0000e+00\n","processing data batch 94\n","Epoch 1/30\n","6/6 [==============================] - 2s 128ms/step - loss: 3.5031 - accuracy: 0.0000e+00 - val_loss: 3.7626 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.3420 - accuracy: 0.0833 - val_loss: 3.8370 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2931 - accuracy: 0.0833 - val_loss: 3.9240 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2432 - accuracy: 0.0833 - val_loss: 4.0077 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1937 - accuracy: 0.0833 - val_loss: 4.1094 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1437 - accuracy: 0.1250 - val_loss: 4.2330 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0970 - accuracy: 0.0833 - val_loss: 4.3558 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0399 - accuracy: 0.0833 - val_loss: 4.4678 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9434 - accuracy: 0.0833 - val_loss: 4.5842 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 30ms/step - loss: 2.8191 - accuracy: 0.0833 - val_loss: 4.6412 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7322 - accuracy: 0.1250 - val_loss: 4.6702 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.6349 - accuracy: 0.2083 - val_loss: 4.7989 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5842 - accuracy: 0.2917 - val_loss: 4.8337 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.5390 - accuracy: 0.3333 - val_loss: 4.8251 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4787 - accuracy: 0.3750 - val_loss: 4.9584 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4548 - accuracy: 0.3750 - val_loss: 5.0327 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4151 - accuracy: 0.3750 - val_loss: 5.1354 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3886 - accuracy: 0.4167 - val_loss: 4.9913 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4368 - accuracy: 0.2500 - val_loss: 5.1516 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4177 - accuracy: 0.2500 - val_loss: 5.1785 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3806 - accuracy: 0.3333 - val_loss: 5.3075 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.3705 - accuracy: 0.2917 - val_loss: 5.3219 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3368 - accuracy: 0.2917 - val_loss: 5.3160 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2951 - accuracy: 0.3333 - val_loss: 5.4743 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2627 - accuracy: 0.3333 - val_loss: 5.4789 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2350 - accuracy: 0.3333 - val_loss: 5.6493 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2012 - accuracy: 0.4583 - val_loss: 5.6494 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1732 - accuracy: 0.5000 - val_loss: 5.7161 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1448 - accuracy: 0.4583 - val_loss: 5.7456 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1234 - accuracy: 0.4583 - val_loss: 5.7884 - val_accuracy: 0.0000e+00\n","processing data batch 95\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.5174 - accuracy: 0.0417 - val_loss: 3.7168 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3480 - accuracy: 0.0417 - val_loss: 3.7721 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3411 - accuracy: 0.0833 - val_loss: 3.8841 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2899 - accuracy: 0.0417 - val_loss: 3.9797 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2365 - accuracy: 0.0417 - val_loss: 4.0681 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1903 - accuracy: 0.0417 - val_loss: 4.1726 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1404 - accuracy: 0.1250 - val_loss: 4.2768 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0958 - accuracy: 0.1250 - val_loss: 4.3798 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0193 - accuracy: 0.1250 - val_loss: 4.4739 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9096 - accuracy: 0.1250 - val_loss: 4.5670 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8387 - accuracy: 0.1250 - val_loss: 4.6220 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0944 - accuracy: 0.0833 - val_loss: 4.7090 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1465 - accuracy: 0.0833 - val_loss: 4.7875 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7216 - accuracy: 0.1250 - val_loss: 4.8612 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6783 - accuracy: 0.1250 - val_loss: 4.9202 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6507 - accuracy: 0.1667 - val_loss: 4.9985 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6136 - accuracy: 0.1667 - val_loss: 5.0705 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5796 - accuracy: 0.1667 - val_loss: 5.1203 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5481 - accuracy: 0.1250 - val_loss: 5.1807 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5204 - accuracy: 0.1667 - val_loss: 5.2141 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4967 - accuracy: 0.2083 - val_loss: 5.3065 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4673 - accuracy: 0.2083 - val_loss: 5.3454 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4436 - accuracy: 0.2083 - val_loss: 5.4045 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4198 - accuracy: 0.1250 - val_loss: 5.5093 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4331 - accuracy: 0.1250 - val_loss: 5.5622 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4139 - accuracy: 0.0833 - val_loss: 5.6271 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3972 - accuracy: 0.1250 - val_loss: 5.6723 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3793 - accuracy: 0.1667 - val_loss: 5.7238 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3650 - accuracy: 0.2083 - val_loss: 5.7706 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3449 - accuracy: 0.1667 - val_loss: 5.8194 - val_accuracy: 0.0000e+00\n","processing data batch 96\n","Epoch 1/30\n","6/6 [==============================] - 3s 130ms/step - loss: 3.6444 - accuracy: 0.0000e+00 - val_loss: 3.7104 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.4229 - accuracy: 0.0417 - val_loss: 3.8054 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3669 - accuracy: 0.0833 - val_loss: 3.9394 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3141 - accuracy: 0.0833 - val_loss: 4.0621 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2393 - accuracy: 0.1667 - val_loss: 4.2393 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1613 - accuracy: 0.0417 - val_loss: 4.4694 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0441 - accuracy: 0.0417 - val_loss: 4.7981 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9525 - accuracy: 0.0417 - val_loss: 5.0364 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8788 - accuracy: 0.0833 - val_loss: 5.3914 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7941 - accuracy: 0.0833 - val_loss: 5.7335 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7145 - accuracy: 0.1250 - val_loss: 5.9155 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6524 - accuracy: 0.1250 - val_loss: 6.1590 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5820 - accuracy: 0.1667 - val_loss: 6.4112 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5539 - accuracy: 0.2083 - val_loss: 6.5371 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4992 - accuracy: 0.1667 - val_loss: 6.5992 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4550 - accuracy: 0.2083 - val_loss: 6.7190 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3880 - accuracy: 0.2083 - val_loss: 6.9981 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3382 - accuracy: 0.2083 - val_loss: 7.0292 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2751 - accuracy: 0.3333 - val_loss: 7.1530 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2142 - accuracy: 0.3333 - val_loss: 7.2261 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2244 - accuracy: 0.3750 - val_loss: 7.2710 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1792 - accuracy: 0.3750 - val_loss: 7.2728 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1004 - accuracy: 0.3750 - val_loss: 7.3934 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0286 - accuracy: 0.4583 - val_loss: 7.5088 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9831 - accuracy: 0.5417 - val_loss: 7.6395 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9368 - accuracy: 0.5417 - val_loss: 7.6881 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8787 - accuracy: 0.5833 - val_loss: 7.6652 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8424 - accuracy: 0.5833 - val_loss: 7.7727 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8253 - accuracy: 0.5833 - val_loss: 7.7494 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7585 - accuracy: 0.6250 - val_loss: 7.7894 - val_accuracy: 0.0000e+00\n","processing data batch 97\n","Epoch 1/30\n","6/6 [==============================] - 3s 128ms/step - loss: 3.5417 - accuracy: 0.0000e+00 - val_loss: 3.4669 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3447 - accuracy: 0.0417 - val_loss: 3.5882 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2110 - accuracy: 0.1250 - val_loss: 3.8507 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.0864 - accuracy: 0.1250 - val_loss: 4.1285 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9897 - accuracy: 0.1250 - val_loss: 4.3770 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8654 - accuracy: 0.1250 - val_loss: 4.4930 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7628 - accuracy: 0.2083 - val_loss: 4.6727 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6138 - accuracy: 0.2083 - val_loss: 4.8788 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5310 - accuracy: 0.2917 - val_loss: 5.0594 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4610 - accuracy: 0.3333 - val_loss: 5.2412 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3688 - accuracy: 0.3333 - val_loss: 5.4463 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2506 - accuracy: 0.4167 - val_loss: 5.5960 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1787 - accuracy: 0.3333 - val_loss: 5.7060 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1206 - accuracy: 0.4167 - val_loss: 5.7982 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0950 - accuracy: 0.3333 - val_loss: 5.9074 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9912 - accuracy: 0.4583 - val_loss: 6.0153 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9380 - accuracy: 0.4583 - val_loss: 6.1334 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8933 - accuracy: 0.4583 - val_loss: 6.2215 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8609 - accuracy: 0.4583 - val_loss: 6.3355 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8019 - accuracy: 0.4583 - val_loss: 6.4030 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7473 - accuracy: 0.4583 - val_loss: 6.5131 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7322 - accuracy: 0.4583 - val_loss: 6.5920 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6853 - accuracy: 0.4583 - val_loss: 6.6861 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6539 - accuracy: 0.4583 - val_loss: 6.7252 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6435 - accuracy: 0.5000 - val_loss: 6.7719 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6125 - accuracy: 0.5000 - val_loss: 6.8096 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6068 - accuracy: 0.5000 - val_loss: 6.9390 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5913 - accuracy: 0.5000 - val_loss: 6.9291 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5709 - accuracy: 0.5000 - val_loss: 7.0022 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5621 - accuracy: 0.5000 - val_loss: 7.0787 - val_accuracy: 0.0000e+00\n","processing data batch 98\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.4336 - accuracy: 0.0417 - val_loss: 3.4415 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3143 - accuracy: 0.0833 - val_loss: 3.4530 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2294 - accuracy: 0.0833 - val_loss: 3.5102 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.1241 - accuracy: 0.1667 - val_loss: 3.6305 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9936 - accuracy: 0.1667 - val_loss: 3.8580 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8660 - accuracy: 0.1667 - val_loss: 4.1278 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7666 - accuracy: 0.2083 - val_loss: 4.3971 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6801 - accuracy: 0.2500 - val_loss: 4.5881 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6219 - accuracy: 0.2083 - val_loss: 4.8230 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5755 - accuracy: 0.2083 - val_loss: 5.0002 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5278 - accuracy: 0.1667 - val_loss: 5.1652 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5007 - accuracy: 0.2500 - val_loss: 5.3207 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4640 - accuracy: 0.2500 - val_loss: 5.4519 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4357 - accuracy: 0.2917 - val_loss: 5.5893 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4254 - accuracy: 0.2500 - val_loss: 5.7657 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4050 - accuracy: 0.2917 - val_loss: 5.8737 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3722 - accuracy: 0.2917 - val_loss: 5.9347 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5124 - accuracy: 0.2500 - val_loss: 5.8908 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3770 - accuracy: 0.2917 - val_loss: 5.9318 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3665 - accuracy: 0.3333 - val_loss: 5.9452 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3340 - accuracy: 0.2917 - val_loss: 6.1378 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2962 - accuracy: 0.3333 - val_loss: 6.2836 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2624 - accuracy: 0.3333 - val_loss: 6.4156 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2633 - accuracy: 0.3333 - val_loss: 6.3866 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3896 - accuracy: 0.2083 - val_loss: 6.3865 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3897 - accuracy: 0.2500 - val_loss: 6.3976 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3701 - accuracy: 0.2917 - val_loss: 6.4703 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3325 - accuracy: 0.2500 - val_loss: 6.5744 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3166 - accuracy: 0.2500 - val_loss: 6.6290 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2926 - accuracy: 0.2917 - val_loss: 6.7678 - val_accuracy: 0.0000e+00\n","processing data batch 99\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4417 - accuracy: 0.0000e+00 - val_loss: 3.7102 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3231 - accuracy: 0.0833 - val_loss: 3.8064 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2703 - accuracy: 0.0833 - val_loss: 3.9074 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2106 - accuracy: 0.1250 - val_loss: 4.0511 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1001 - accuracy: 0.1250 - val_loss: 4.2516 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0047 - accuracy: 0.1667 - val_loss: 4.5084 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9142 - accuracy: 0.1250 - val_loss: 4.7065 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8526 - accuracy: 0.1250 - val_loss: 4.8689 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7870 - accuracy: 0.1250 - val_loss: 4.9649 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7464 - accuracy: 0.1667 - val_loss: 5.0298 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7000 - accuracy: 0.1250 - val_loss: 5.0394 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6695 - accuracy: 0.1250 - val_loss: 5.0905 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6494 - accuracy: 0.1667 - val_loss: 5.0962 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6313 - accuracy: 0.1667 - val_loss: 5.1334 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6063 - accuracy: 0.1667 - val_loss: 5.1983 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5952 - accuracy: 0.1667 - val_loss: 5.1944 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5904 - accuracy: 0.2083 - val_loss: 5.2342 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5787 - accuracy: 0.1667 - val_loss: 5.2608 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5625 - accuracy: 0.1667 - val_loss: 5.2895 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5529 - accuracy: 0.1667 - val_loss: 5.3317 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5544 - accuracy: 0.1667 - val_loss: 5.3726 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5463 - accuracy: 0.1667 - val_loss: 5.3814 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5403 - accuracy: 0.1250 - val_loss: 5.3862 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5305 - accuracy: 0.1250 - val_loss: 5.4519 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5312 - accuracy: 0.1667 - val_loss: 5.5173 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5224 - accuracy: 0.1667 - val_loss: 5.5415 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5203 - accuracy: 0.2083 - val_loss: 5.5758 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5162 - accuracy: 0.1667 - val_loss: 5.6105 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5151 - accuracy: 0.1667 - val_loss: 5.6637 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5100 - accuracy: 0.1250 - val_loss: 5.6916 - val_accuracy: 0.0000e+00\n","processing data batch 100\n","Epoch 1/30\n","6/6 [==============================] - 2s 122ms/step - loss: 3.5310 - accuracy: 0.0000e+00 - val_loss: 3.6244 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3529 - accuracy: 0.0417 - val_loss: 3.6903 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2851 - accuracy: 0.0417 - val_loss: 3.7601 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2328 - accuracy: 0.0833 - val_loss: 3.8314 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1666 - accuracy: 0.1250 - val_loss: 3.9260 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0781 - accuracy: 0.1250 - val_loss: 4.0819 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9254 - accuracy: 0.0833 - val_loss: 4.3769 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7342 - accuracy: 0.1667 - val_loss: 4.6798 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5667 - accuracy: 0.2083 - val_loss: 5.1322 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3837 - accuracy: 0.2917 - val_loss: 5.4024 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2226 - accuracy: 0.3333 - val_loss: 5.5862 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1236 - accuracy: 0.3333 - val_loss: 5.6154 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0053 - accuracy: 0.4167 - val_loss: 5.4151 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1183 - accuracy: 0.3333 - val_loss: 5.2259 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9312 - accuracy: 0.5000 - val_loss: 5.8128 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9112 - accuracy: 0.5000 - val_loss: 5.9448 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7857 - accuracy: 0.5000 - val_loss: 5.7691 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7489 - accuracy: 0.5000 - val_loss: 5.5005 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6309 - accuracy: 0.5417 - val_loss: 5.9337 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6241 - accuracy: 0.5417 - val_loss: 5.9698 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5886 - accuracy: 0.5417 - val_loss: 6.0842 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5224 - accuracy: 0.5000 - val_loss: 6.5635 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5474 - accuracy: 0.5417 - val_loss: 6.3557 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4965 - accuracy: 0.5833 - val_loss: 6.3504 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4566 - accuracy: 0.5833 - val_loss: 6.2266 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4040 - accuracy: 0.5417 - val_loss: 6.2813 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4519 - accuracy: 0.5833 - val_loss: 6.5379 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3866 - accuracy: 0.6250 - val_loss: 5.6868 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7732 - accuracy: 0.3333 - val_loss: 6.1973 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8238 - accuracy: 0.4167 - val_loss: 6.0719 - val_accuracy: 0.0000e+00\n","processing data batch 101\n","Epoch 1/30\n","6/6 [==============================] - 3s 129ms/step - loss: 3.4928 - accuracy: 0.0000e+00 - val_loss: 3.9428 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2844 - accuracy: 0.0417 - val_loss: 4.0362 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2271 - accuracy: 0.0833 - val_loss: 4.1378 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1778 - accuracy: 0.0833 - val_loss: 4.2555 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1243 - accuracy: 0.0833 - val_loss: 4.3976 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0739 - accuracy: 0.1667 - val_loss: 4.5495 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0281 - accuracy: 0.0833 - val_loss: 4.7316 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9311 - accuracy: 0.0833 - val_loss: 4.9322 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7932 - accuracy: 0.1250 - val_loss: 5.1323 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6908 - accuracy: 0.1250 - val_loss: 5.3373 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5953 - accuracy: 0.1667 - val_loss: 5.4953 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5117 - accuracy: 0.2083 - val_loss: 5.7123 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5108 - accuracy: 0.1250 - val_loss: 5.8076 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4079 - accuracy: 0.1667 - val_loss: 5.9282 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3548 - accuracy: 0.1250 - val_loss: 6.0861 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3001 - accuracy: 0.2917 - val_loss: 6.1828 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2215 - accuracy: 0.3750 - val_loss: 6.1644 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1894 - accuracy: 0.3333 - val_loss: 6.1580 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1399 - accuracy: 0.3333 - val_loss: 6.2682 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0466 - accuracy: 0.5000 - val_loss: 6.1523 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9429 - accuracy: 0.5000 - val_loss: 6.4462 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9286 - accuracy: 0.5000 - val_loss: 6.4391 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9243 - accuracy: 0.4583 - val_loss: 6.2434 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8779 - accuracy: 0.5000 - val_loss: 6.1443 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7869 - accuracy: 0.4583 - val_loss: 6.4531 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6699 - accuracy: 0.5833 - val_loss: 6.2486 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7301 - accuracy: 0.5417 - val_loss: 6.5551 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6743 - accuracy: 0.5417 - val_loss: 6.3498 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5239 - accuracy: 0.5833 - val_loss: 6.0914 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6642 - accuracy: 0.5000 - val_loss: 5.8700 - val_accuracy: 0.0000e+00\n","processing data batch 102\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.6245 - accuracy: 0.0000e+00 - val_loss: 3.9333 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3364 - accuracy: 0.0417 - val_loss: 3.9226 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2374 - accuracy: 0.1250 - val_loss: 4.0478 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1693 - accuracy: 0.1250 - val_loss: 4.1908 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1123 - accuracy: 0.1250 - val_loss: 4.3231 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0409 - accuracy: 0.0833 - val_loss: 4.3429 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9679 - accuracy: 0.1667 - val_loss: 4.4326 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8863 - accuracy: 0.1667 - val_loss: 4.5371 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7848 - accuracy: 0.1667 - val_loss: 4.6556 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6382 - accuracy: 0.1667 - val_loss: 4.7919 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5192 - accuracy: 0.2500 - val_loss: 4.9558 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4142 - accuracy: 0.3333 - val_loss: 4.8807 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3437 - accuracy: 0.3750 - val_loss: 4.9744 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2554 - accuracy: 0.4583 - val_loss: 5.1295 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1642 - accuracy: 0.5000 - val_loss: 5.2355 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0782 - accuracy: 0.5417 - val_loss: 5.2583 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9972 - accuracy: 0.5417 - val_loss: 5.4216 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9205 - accuracy: 0.5417 - val_loss: 5.6918 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8754 - accuracy: 0.5417 - val_loss: 5.7745 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7476 - accuracy: 0.5833 - val_loss: 5.6440 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6908 - accuracy: 0.5833 - val_loss: 5.8138 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6095 - accuracy: 0.5833 - val_loss: 5.8978 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5971 - accuracy: 0.5833 - val_loss: 5.7994 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5461 - accuracy: 0.5833 - val_loss: 5.9626 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.4888 - accuracy: 0.5833 - val_loss: 6.3094 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4270 - accuracy: 0.5417 - val_loss: 6.8033 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3379 - accuracy: 0.5833 - val_loss: 7.0276 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3064 - accuracy: 0.5417 - val_loss: 7.1360 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2617 - accuracy: 0.5417 - val_loss: 6.8360 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2392 - accuracy: 0.5833 - val_loss: 6.6222 - val_accuracy: 0.0000e+00\n","processing data batch 103\n","Epoch 1/30\n","6/6 [==============================] - 2s 128ms/step - loss: 3.5553 - accuracy: 0.0000e+00 - val_loss: 3.4432 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3249 - accuracy: 0.0833 - val_loss: 3.4998 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2194 - accuracy: 0.0833 - val_loss: 3.6404 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0834 - accuracy: 0.0833 - val_loss: 3.8660 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9548 - accuracy: 0.1250 - val_loss: 4.1880 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8453 - accuracy: 0.1250 - val_loss: 4.4490 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7660 - accuracy: 0.1250 - val_loss: 4.6898 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6624 - accuracy: 0.2083 - val_loss: 4.8402 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6043 - accuracy: 0.2500 - val_loss: 5.0140 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5112 - accuracy: 0.2500 - val_loss: 5.1952 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4407 - accuracy: 0.2083 - val_loss: 5.3728 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4010 - accuracy: 0.2500 - val_loss: 5.5747 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3117 - accuracy: 0.2917 - val_loss: 5.7273 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2411 - accuracy: 0.3333 - val_loss: 5.8270 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1899 - accuracy: 0.2917 - val_loss: 5.9568 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1401 - accuracy: 0.3750 - val_loss: 6.0869 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0606 - accuracy: 0.4167 - val_loss: 6.1999 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9956 - accuracy: 0.4167 - val_loss: 6.2971 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9160 - accuracy: 0.4167 - val_loss: 6.3444 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8558 - accuracy: 0.4167 - val_loss: 6.4327 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7909 - accuracy: 0.4583 - val_loss: 6.5199 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7930 - accuracy: 0.5000 - val_loss: 6.5740 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7216 - accuracy: 0.5000 - val_loss: 6.6319 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6586 - accuracy: 0.5000 - val_loss: 6.7167 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6427 - accuracy: 0.5000 - val_loss: 6.7884 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6109 - accuracy: 0.5000 - val_loss: 6.8403 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5725 - accuracy: 0.5417 - val_loss: 6.8892 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5515 - accuracy: 0.5417 - val_loss: 6.9533 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5230 - accuracy: 0.5417 - val_loss: 7.0109 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5186 - accuracy: 0.5417 - val_loss: 7.0475 - val_accuracy: 0.0000e+00\n","processing data batch 104\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.4705 - accuracy: 0.0417 - val_loss: 3.4429 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2574 - accuracy: 0.0833 - val_loss: 3.4567 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.1941 - accuracy: 0.0833 - val_loss: 3.4978 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1191 - accuracy: 0.0833 - val_loss: 3.5779 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0411 - accuracy: 0.0833 - val_loss: 3.8177 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9571 - accuracy: 0.1667 - val_loss: 4.1446 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8807 - accuracy: 0.1667 - val_loss: 4.4284 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8149 - accuracy: 0.1667 - val_loss: 4.7314 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7551 - accuracy: 0.1667 - val_loss: 5.0207 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7084 - accuracy: 0.2083 - val_loss: 5.2461 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6673 - accuracy: 0.2083 - val_loss: 5.4157 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6265 - accuracy: 0.2083 - val_loss: 5.5801 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5935 - accuracy: 0.1667 - val_loss: 5.7270 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5486 - accuracy: 0.2083 - val_loss: 5.8796 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5261 - accuracy: 0.2083 - val_loss: 6.0446 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4976 - accuracy: 0.2500 - val_loss: 6.1873 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4775 - accuracy: 0.2083 - val_loss: 6.3110 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4606 - accuracy: 0.2500 - val_loss: 6.4117 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4359 - accuracy: 0.2083 - val_loss: 6.5092 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4212 - accuracy: 0.2083 - val_loss: 6.6038 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4111 - accuracy: 0.2500 - val_loss: 6.7083 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4038 - accuracy: 0.2500 - val_loss: 6.8067 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3984 - accuracy: 0.2083 - val_loss: 6.9076 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3951 - accuracy: 0.2500 - val_loss: 6.9777 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3963 - accuracy: 0.2083 - val_loss: 7.0508 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4040 - accuracy: 0.2083 - val_loss: 7.1118 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4105 - accuracy: 0.2083 - val_loss: 7.1874 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4044 - accuracy: 0.2083 - val_loss: 7.2519 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3989 - accuracy: 0.2083 - val_loss: 7.3121 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3841 - accuracy: 0.2083 - val_loss: 7.3631 - val_accuracy: 0.0000e+00\n","processing data batch 105\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.4639 - accuracy: 0.0000e+00 - val_loss: 3.4431 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4011 - accuracy: 0.0417 - val_loss: 3.4804 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3616 - accuracy: 0.0417 - val_loss: 3.5678 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3350 - accuracy: 0.0417 - val_loss: 3.6860 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2875 - accuracy: 0.0417 - val_loss: 3.8367 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2417 - accuracy: 0.0417 - val_loss: 4.0484 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1747 - accuracy: 0.0417 - val_loss: 4.2311 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1249 - accuracy: 0.0833 - val_loss: 4.3832 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0758 - accuracy: 0.0417 - val_loss: 4.5663 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0351 - accuracy: 0.1250 - val_loss: 4.6982 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0166 - accuracy: 0.0833 - val_loss: 4.8626 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9782 - accuracy: 0.1250 - val_loss: 5.0993 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9626 - accuracy: 0.0833 - val_loss: 5.2595 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9465 - accuracy: 0.1250 - val_loss: 5.2991 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9417 - accuracy: 0.1250 - val_loss: 5.6761 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9298 - accuracy: 0.0833 - val_loss: 5.9511 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9183 - accuracy: 0.0833 - val_loss: 5.9651 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9105 - accuracy: 0.0833 - val_loss: 5.9942 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9081 - accuracy: 0.0833 - val_loss: 6.2048 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8976 - accuracy: 0.0833 - val_loss: 6.3556 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8960 - accuracy: 0.0833 - val_loss: 6.3830 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8913 - accuracy: 0.0833 - val_loss: 6.3857 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8849 - accuracy: 0.0833 - val_loss: 6.3902 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8873 - accuracy: 0.0833 - val_loss: 6.3954 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8852 - accuracy: 0.1250 - val_loss: 6.4002 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8789 - accuracy: 0.0833 - val_loss: 6.4494 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8763 - accuracy: 0.0833 - val_loss: 6.5051 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8741 - accuracy: 0.0833 - val_loss: 6.5480 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8756 - accuracy: 0.1250 - val_loss: 6.6030 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8694 - accuracy: 0.0833 - val_loss: 6.6359 - val_accuracy: 0.0000e+00\n","processing data batch 106\n","Epoch 1/30\n","6/6 [==============================] - 3s 129ms/step - loss: 3.5012 - accuracy: 0.0000e+00 - val_loss: 3.6280 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3395 - accuracy: 0.0833 - val_loss: 3.6926 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2691 - accuracy: 0.0833 - val_loss: 3.7661 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2104 - accuracy: 0.0833 - val_loss: 3.8626 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1541 - accuracy: 0.0833 - val_loss: 3.9674 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0941 - accuracy: 0.1250 - val_loss: 4.0541 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0463 - accuracy: 0.1667 - val_loss: 4.1669 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9932 - accuracy: 0.1250 - val_loss: 4.3282 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9223 - accuracy: 0.1667 - val_loss: 4.4801 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8382 - accuracy: 0.2083 - val_loss: 4.6162 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7113 - accuracy: 0.1667 - val_loss: 4.7362 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6205 - accuracy: 0.2500 - val_loss: 4.7628 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5422 - accuracy: 0.2917 - val_loss: 4.8062 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4866 - accuracy: 0.2500 - val_loss: 4.8184 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4274 - accuracy: 0.2500 - val_loss: 4.8952 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3513 - accuracy: 0.2917 - val_loss: 5.0424 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2710 - accuracy: 0.3750 - val_loss: 5.3567 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1732 - accuracy: 0.3333 - val_loss: 5.5514 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0854 - accuracy: 0.3333 - val_loss: 5.7533 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1143 - accuracy: 0.3333 - val_loss: 5.8114 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0495 - accuracy: 0.4583 - val_loss: 5.2531 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9688 - accuracy: 0.5417 - val_loss: 6.0402 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9450 - accuracy: 0.4583 - val_loss: 6.0163 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9124 - accuracy: 0.5000 - val_loss: 6.0199 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8536 - accuracy: 0.4583 - val_loss: 6.1598 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8325 - accuracy: 0.4583 - val_loss: 5.7345 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7641 - accuracy: 0.5417 - val_loss: 6.6656 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7363 - accuracy: 0.5000 - val_loss: 6.5108 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6896 - accuracy: 0.5417 - val_loss: 6.0915 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6565 - accuracy: 0.4583 - val_loss: 5.8762 - val_accuracy: 0.0000e+00\n","processing data batch 107\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5369 - accuracy: 0.0417 - val_loss: 3.5599 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2993 - accuracy: 0.0833 - val_loss: 3.6851 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1981 - accuracy: 0.1667 - val_loss: 3.8653 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0982 - accuracy: 0.2083 - val_loss: 3.9373 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9731 - accuracy: 0.2917 - val_loss: 4.1536 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7731 - accuracy: 0.4583 - val_loss: 4.3271 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4967 - accuracy: 0.5000 - val_loss: 4.4673 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1603 - accuracy: 0.6667 - val_loss: 4.7812 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8380 - accuracy: 0.5833 - val_loss: 5.1033 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6929 - accuracy: 0.5833 - val_loss: 5.3364 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4691 - accuracy: 0.6667 - val_loss: 5.4327 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2601 - accuracy: 0.7083 - val_loss: 5.2887 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1365 - accuracy: 0.6667 - val_loss: 5.6445 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0530 - accuracy: 0.7500 - val_loss: 5.3186 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0179 - accuracy: 0.7083 - val_loss: 5.4944 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9857 - accuracy: 0.7083 - val_loss: 5.9890 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9511 - accuracy: 0.7083 - val_loss: 5.1587 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.9406 - accuracy: 0.6667 - val_loss: 5.5514 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9046 - accuracy: 0.7083 - val_loss: 5.5383 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8680 - accuracy: 0.7083 - val_loss: 5.4935 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8280 - accuracy: 0.7083 - val_loss: 5.4710 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8127 - accuracy: 0.7083 - val_loss: 5.2978 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8022 - accuracy: 0.6667 - val_loss: 5.3959 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7885 - accuracy: 0.6667 - val_loss: 5.4474 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7828 - accuracy: 0.6667 - val_loss: 5.5523 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7733 - accuracy: 0.7083 - val_loss: 5.5826 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.7660 - accuracy: 0.7083 - val_loss: 5.5803 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7625 - accuracy: 0.7083 - val_loss: 5.8355 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7588 - accuracy: 0.7083 - val_loss: 5.8502 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7545 - accuracy: 0.6667 - val_loss: 5.8395 - val_accuracy: 0.0000e+00\n","processing data batch 108\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5258 - accuracy: 0.0000e+00 - val_loss: 3.4393 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3176 - accuracy: 0.0417 - val_loss: 3.4471 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2437 - accuracy: 0.0833 - val_loss: 3.4542 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1812 - accuracy: 0.0833 - val_loss: 3.4598 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1359 - accuracy: 0.1250 - val_loss: 3.4642 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0814 - accuracy: 0.0833 - val_loss: 3.4676 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0307 - accuracy: 0.1250 - val_loss: 3.4713 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9267 - accuracy: 0.2083 - val_loss: 3.4570 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7799 - accuracy: 0.2917 - val_loss: 3.4617 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5790 - accuracy: 0.4167 - val_loss: 4.0091 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4643 - accuracy: 0.4583 - val_loss: 3.6518 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3562 - accuracy: 0.5000 - val_loss: 3.9292 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2286 - accuracy: 0.5000 - val_loss: 4.0064 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1892 - accuracy: 0.5000 - val_loss: 3.9522 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0257 - accuracy: 0.5833 - val_loss: 4.1324 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8697 - accuracy: 0.6250 - val_loss: 4.2778 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7093 - accuracy: 0.6667 - val_loss: 4.3429 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6039 - accuracy: 0.6250 - val_loss: 4.2265 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4538 - accuracy: 0.6250 - val_loss: 4.3383 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3702 - accuracy: 0.5833 - val_loss: 4.7873 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2841 - accuracy: 0.6250 - val_loss: 4.4778 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2746 - accuracy: 0.5833 - val_loss: 4.9809 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5055 - accuracy: 0.6250 - val_loss: 5.0485 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3423 - accuracy: 0.6667 - val_loss: 4.9776 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3296 - accuracy: 0.6250 - val_loss: 5.1712 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2660 - accuracy: 0.5833 - val_loss: 5.4733 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2653 - accuracy: 0.5833 - val_loss: 5.6805 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2116 - accuracy: 0.6667 - val_loss: 5.7473 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1405 - accuracy: 0.6667 - val_loss: 5.8450 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1004 - accuracy: 0.6667 - val_loss: 5.9191 - val_accuracy: 0.0000e+00\n","processing data batch 109\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.4791 - accuracy: 0.0000e+00 - val_loss: 3.4435 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3764 - accuracy: 0.0417 - val_loss: 3.4538 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3385 - accuracy: 0.0833 - val_loss: 3.4648 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3121 - accuracy: 0.0833 - val_loss: 3.4764 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2742 - accuracy: 0.0833 - val_loss: 3.4888 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2244 - accuracy: 0.0833 - val_loss: 3.5018 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1658 - accuracy: 0.1250 - val_loss: 3.5152 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0877 - accuracy: 0.2083 - val_loss: 3.5281 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9764 - accuracy: 0.2083 - val_loss: 3.5386 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8794 - accuracy: 0.2083 - val_loss: 3.5512 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7757 - accuracy: 0.2083 - val_loss: 3.5658 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6835 - accuracy: 0.2083 - val_loss: 3.6747 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5584 - accuracy: 0.2083 - val_loss: 3.9699 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4451 - accuracy: 0.2083 - val_loss: 4.3064 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3686 - accuracy: 0.2083 - val_loss: 4.6407 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3342 - accuracy: 0.1667 - val_loss: 4.8538 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2615 - accuracy: 0.2083 - val_loss: 5.1866 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2215 - accuracy: 0.1250 - val_loss: 5.3944 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3462 - accuracy: 0.2083 - val_loss: 5.5401 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3042 - accuracy: 0.1667 - val_loss: 5.6819 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1681 - accuracy: 0.2083 - val_loss: 5.7070 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1345 - accuracy: 0.2083 - val_loss: 5.7509 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1399 - accuracy: 0.2500 - val_loss: 5.8139 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1256 - accuracy: 0.2500 - val_loss: 5.8688 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1042 - accuracy: 0.2917 - val_loss: 6.0024 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1035 - accuracy: 0.1667 - val_loss: 6.0881 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1262 - accuracy: 0.2083 - val_loss: 6.1540 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0837 - accuracy: 0.2917 - val_loss: 6.3304 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0887 - accuracy: 0.2083 - val_loss: 6.4279 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0831 - accuracy: 0.2917 - val_loss: 6.6277 - val_accuracy: 0.0000e+00\n","processing data batch 110\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.4415 - accuracy: 0.0000e+00 - val_loss: 3.4465 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.4316 - accuracy: 0.0000e+00 - val_loss: 3.4511 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.4270 - accuracy: 0.0000e+00 - val_loss: 3.4752 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.4139 - accuracy: 0.0000e+00 - val_loss: 3.5265 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3905 - accuracy: 0.0417 - val_loss: 3.7364 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3220 - accuracy: 0.0417 - val_loss: 3.9594 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2185 - accuracy: 0.0417 - val_loss: 4.2504 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1168 - accuracy: 0.0833 - val_loss: 4.6330 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9940 - accuracy: 0.0833 - val_loss: 4.9838 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9216 - accuracy: 0.0417 - val_loss: 5.4883 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9564 - accuracy: 0.1250 - val_loss: 5.3630 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.8445 - accuracy: 0.1667 - val_loss: 5.4685 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8193 - accuracy: 0.1250 - val_loss: 5.2846 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8186 - accuracy: 0.2083 - val_loss: 5.1181 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7960 - accuracy: 0.1250 - val_loss: 5.1955 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8861 - accuracy: 0.0833 - val_loss: 5.3569 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8544 - accuracy: 0.1250 - val_loss: 5.5451 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8281 - accuracy: 0.0833 - val_loss: 5.7116 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8035 - accuracy: 0.1250 - val_loss: 5.8779 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7838 - accuracy: 0.0833 - val_loss: 6.0293 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7610 - accuracy: 0.1250 - val_loss: 6.1732 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7581 - accuracy: 0.0833 - val_loss: 6.3000 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7405 - accuracy: 0.1250 - val_loss: 6.4074 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7191 - accuracy: 0.1667 - val_loss: 6.4967 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7094 - accuracy: 0.1667 - val_loss: 6.6038 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7639 - accuracy: 0.1250 - val_loss: 6.6607 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7576 - accuracy: 0.0833 - val_loss: 6.7250 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7493 - accuracy: 0.0833 - val_loss: 6.7797 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7201 - accuracy: 0.0833 - val_loss: 6.8452 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7152 - accuracy: 0.0833 - val_loss: 6.9129 - val_accuracy: 0.0000e+00\n","processing data batch 111\n","Epoch 1/30\n","6/6 [==============================] - 3s 128ms/step - loss: 3.4595 - accuracy: 0.0000e+00 - val_loss: 4.0275 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3504 - accuracy: 0.0417 - val_loss: 4.0481 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3235 - accuracy: 0.0417 - val_loss: 4.1049 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2829 - accuracy: 0.0417 - val_loss: 4.1803 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2375 - accuracy: 0.0833 - val_loss: 4.2968 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1890 - accuracy: 0.0833 - val_loss: 4.4590 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1530 - accuracy: 0.0417 - val_loss: 4.5118 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1120 - accuracy: 0.0417 - val_loss: 4.6259 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0736 - accuracy: 0.0417 - val_loss: 4.6660 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0452 - accuracy: 0.0417 - val_loss: 4.6945 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0126 - accuracy: 0.0833 - val_loss: 4.7608 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0038 - accuracy: 0.0833 - val_loss: 4.7981 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9968 - accuracy: 0.0833 - val_loss: 4.8472 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9743 - accuracy: 0.0417 - val_loss: 4.8696 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9628 - accuracy: 0.0833 - val_loss: 4.9026 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9562 - accuracy: 0.0417 - val_loss: 4.9354 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9504 - accuracy: 0.0417 - val_loss: 4.9644 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9392 - accuracy: 0.0833 - val_loss: 5.0612 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9359 - accuracy: 0.0417 - val_loss: 5.0810 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9323 - accuracy: 0.0833 - val_loss: 5.0353 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9335 - accuracy: 0.1250 - val_loss: 5.0704 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9229 - accuracy: 0.0833 - val_loss: 5.1023 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9245 - accuracy: 0.0833 - val_loss: 5.2164 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9171 - accuracy: 0.0833 - val_loss: 5.2817 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9093 - accuracy: 0.1250 - val_loss: 5.3113 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9076 - accuracy: 0.0833 - val_loss: 5.1977 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9070 - accuracy: 0.0833 - val_loss: 5.2273 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9053 - accuracy: 0.1250 - val_loss: 5.2538 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9036 - accuracy: 0.0833 - val_loss: 5.4330 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9001 - accuracy: 0.1250 - val_loss: 5.4893 - val_accuracy: 0.0000e+00\n","processing data batch 112\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5044 - accuracy: 0.0000e+00 - val_loss: 3.8955 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2361 - accuracy: 0.0833 - val_loss: 3.9658 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1696 - accuracy: 0.0833 - val_loss: 4.0248 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0899 - accuracy: 0.1250 - val_loss: 4.1578 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9977 - accuracy: 0.1667 - val_loss: 4.3227 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9013 - accuracy: 0.1667 - val_loss: 4.4485 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7848 - accuracy: 0.2917 - val_loss: 4.5519 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6671 - accuracy: 0.3333 - val_loss: 4.7932 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4927 - accuracy: 0.3750 - val_loss: 4.9649 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3212 - accuracy: 0.3750 - val_loss: 5.1294 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2097 - accuracy: 0.4583 - val_loss: 5.1104 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0852 - accuracy: 0.4583 - val_loss: 5.1230 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0173 - accuracy: 0.4167 - val_loss: 5.3826 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9128 - accuracy: 0.4167 - val_loss: 5.2363 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8628 - accuracy: 0.4583 - val_loss: 5.3373 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8185 - accuracy: 0.4167 - val_loss: 5.4212 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7753 - accuracy: 0.4167 - val_loss: 5.7367 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7538 - accuracy: 0.4583 - val_loss: 5.7641 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7082 - accuracy: 0.4583 - val_loss: 5.5227 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7239 - accuracy: 0.4583 - val_loss: 5.7537 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7157 - accuracy: 0.4583 - val_loss: 5.7357 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6992 - accuracy: 0.4583 - val_loss: 5.8723 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6928 - accuracy: 0.4167 - val_loss: 5.7325 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.6697 - accuracy: 0.4583 - val_loss: 5.5689 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6596 - accuracy: 0.4167 - val_loss: 5.4907 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6505 - accuracy: 0.4583 - val_loss: 5.6894 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6511 - accuracy: 0.4167 - val_loss: 5.8579 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6401 - accuracy: 0.4167 - val_loss: 5.8372 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6342 - accuracy: 0.4167 - val_loss: 5.8292 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6243 - accuracy: 0.4583 - val_loss: 5.7893 - val_accuracy: 0.0000e+00\n","processing data batch 113\n","Epoch 1/30\n","6/6 [==============================] - 2s 122ms/step - loss: 3.5465 - accuracy: 0.0000e+00 - val_loss: 3.8359 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2946 - accuracy: 0.0833 - val_loss: 3.8904 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1932 - accuracy: 0.1250 - val_loss: 4.0010 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0237 - accuracy: 0.1250 - val_loss: 4.1989 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8819 - accuracy: 0.0833 - val_loss: 4.3831 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7407 - accuracy: 0.0833 - val_loss: 4.6042 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5846 - accuracy: 0.1667 - val_loss: 4.8868 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4343 - accuracy: 0.2500 - val_loss: 4.9806 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3382 - accuracy: 0.2500 - val_loss: 5.2408 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2000 - accuracy: 0.3750 - val_loss: 5.5439 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1876 - accuracy: 0.2500 - val_loss: 5.6106 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0748 - accuracy: 0.3333 - val_loss: 5.5960 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9680 - accuracy: 0.4167 - val_loss: 5.8513 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9043 - accuracy: 0.4583 - val_loss: 5.8524 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7735 - accuracy: 0.5417 - val_loss: 5.5276 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6794 - accuracy: 0.5417 - val_loss: 5.9031 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5868 - accuracy: 0.6667 - val_loss: 5.9611 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4786 - accuracy: 0.5833 - val_loss: 6.1592 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4345 - accuracy: 0.6250 - val_loss: 6.3736 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3772 - accuracy: 0.6250 - val_loss: 5.7991 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4838 - accuracy: 0.6250 - val_loss: 5.7425 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4943 - accuracy: 0.6250 - val_loss: 5.5947 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4330 - accuracy: 0.6250 - val_loss: 5.7633 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3570 - accuracy: 0.6667 - val_loss: 5.5444 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2769 - accuracy: 0.6667 - val_loss: 5.8074 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2185 - accuracy: 0.6667 - val_loss: 5.7845 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1702 - accuracy: 0.6667 - val_loss: 5.9398 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1316 - accuracy: 0.6667 - val_loss: 5.9521 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1000 - accuracy: 0.6667 - val_loss: 5.9443 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0632 - accuracy: 0.6667 - val_loss: 5.9535 - val_accuracy: 0.0000e+00\n","processing data batch 114\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.5410 - accuracy: 0.0000e+00 - val_loss: 3.8101 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3375 - accuracy: 0.1250 - val_loss: 3.8571 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2787 - accuracy: 0.1250 - val_loss: 3.9284 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2259 - accuracy: 0.1250 - val_loss: 4.0079 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1777 - accuracy: 0.1250 - val_loss: 4.1018 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1239 - accuracy: 0.1250 - val_loss: 4.2111 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0753 - accuracy: 0.1667 - val_loss: 4.3126 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0146 - accuracy: 0.1667 - val_loss: 4.4075 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9407 - accuracy: 0.1667 - val_loss: 4.4777 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8505 - accuracy: 0.1667 - val_loss: 4.6265 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7774 - accuracy: 0.2083 - val_loss: 4.6840 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6868 - accuracy: 0.2917 - val_loss: 4.7072 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5955 - accuracy: 0.2917 - val_loss: 4.8029 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5122 - accuracy: 0.2917 - val_loss: 4.7099 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4222 - accuracy: 0.4167 - val_loss: 4.7803 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3560 - accuracy: 0.3333 - val_loss: 4.6944 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2478 - accuracy: 0.4583 - val_loss: 5.1005 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1434 - accuracy: 0.5417 - val_loss: 5.0454 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0812 - accuracy: 0.4583 - val_loss: 5.1156 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9677 - accuracy: 0.5833 - val_loss: 5.5142 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8615 - accuracy: 0.5000 - val_loss: 5.5346 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7652 - accuracy: 0.5000 - val_loss: 5.9269 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7592 - accuracy: 0.5417 - val_loss: 5.9837 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7631 - accuracy: 0.5417 - val_loss: 6.0565 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6010 - accuracy: 0.5000 - val_loss: 6.3052 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4810 - accuracy: 0.5000 - val_loss: 6.5024 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4043 - accuracy: 0.5417 - val_loss: 5.8068 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3156 - accuracy: 0.5833 - val_loss: 6.1638 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2899 - accuracy: 0.5833 - val_loss: 6.2071 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3992 - accuracy: 0.6250 - val_loss: 6.2280 - val_accuracy: 0.0000e+00\n","processing data batch 115\n","Epoch 1/30\n","6/6 [==============================] - 2s 122ms/step - loss: 3.5099 - accuracy: 0.0000e+00 - val_loss: 3.9493 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3377 - accuracy: 0.0417 - val_loss: 3.9943 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2337 - accuracy: 0.1667 - val_loss: 4.1549 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1056 - accuracy: 0.1250 - val_loss: 4.2937 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9748 - accuracy: 0.1667 - val_loss: 4.4161 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7997 - accuracy: 0.2083 - val_loss: 4.5605 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6481 - accuracy: 0.4167 - val_loss: 4.8786 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5252 - accuracy: 0.4583 - val_loss: 5.0183 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2910 - accuracy: 0.5417 - val_loss: 5.3567 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1367 - accuracy: 0.6250 - val_loss: 5.2378 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9775 - accuracy: 0.6250 - val_loss: 5.8056 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7424 - accuracy: 0.7500 - val_loss: 5.8042 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5977 - accuracy: 0.7500 - val_loss: 6.1256 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 26ms/step - loss: 1.3738 - accuracy: 0.7500 - val_loss: 6.2445 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 26ms/step - loss: 1.2671 - accuracy: 0.7917 - val_loss: 6.5850 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1774 - accuracy: 0.7500 - val_loss: 6.5443 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0957 - accuracy: 0.7917 - val_loss: 6.0080 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0899 - accuracy: 0.7500 - val_loss: 6.7209 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0289 - accuracy: 0.7500 - val_loss: 6.8307 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9614 - accuracy: 0.7917 - val_loss: 6.4387 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9135 - accuracy: 0.7917 - val_loss: 6.5144 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9074 - accuracy: 0.8333 - val_loss: 6.2638 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0037 - accuracy: 0.8333 - val_loss: 6.2308 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9325 - accuracy: 0.7917 - val_loss: 6.1350 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8274 - accuracy: 0.7917 - val_loss: 6.2087 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7590 - accuracy: 0.7917 - val_loss: 6.2662 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7409 - accuracy: 0.7500 - val_loss: 6.3444 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.6992 - accuracy: 0.7917 - val_loss: 6.3264 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.6782 - accuracy: 0.7917 - val_loss: 6.3204 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 26ms/step - loss: 0.6484 - accuracy: 0.7917 - val_loss: 6.2068 - val_accuracy: 0.0000e+00\n","processing data batch 116\n","Epoch 1/30\n","6/6 [==============================] - 3s 129ms/step - loss: 3.4993 - accuracy: 0.0000e+00 - val_loss: 3.6774 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3016 - accuracy: 0.0833 - val_loss: 3.8347 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2043 - accuracy: 0.0417 - val_loss: 3.9588 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0618 - accuracy: 0.0833 - val_loss: 4.2180 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9033 - accuracy: 0.1250 - val_loss: 4.4812 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7995 - accuracy: 0.1667 - val_loss: 4.7973 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7014 - accuracy: 0.2083 - val_loss: 5.0254 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6064 - accuracy: 0.1667 - val_loss: 5.2096 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5320 - accuracy: 0.1667 - val_loss: 5.3139 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4514 - accuracy: 0.2500 - val_loss: 5.4896 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3964 - accuracy: 0.2500 - val_loss: 5.6531 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3375 - accuracy: 0.2500 - val_loss: 5.8642 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2830 - accuracy: 0.2500 - val_loss: 6.0163 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2081 - accuracy: 0.2917 - val_loss: 6.2021 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1826 - accuracy: 0.3750 - val_loss: 6.3673 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1388 - accuracy: 0.3333 - val_loss: 6.4641 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0854 - accuracy: 0.4583 - val_loss: 6.8545 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0619 - accuracy: 0.3750 - val_loss: 6.9638 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0030 - accuracy: 0.3750 - val_loss: 7.0227 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0121 - accuracy: 0.4583 - val_loss: 7.0860 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0373 - accuracy: 0.4583 - val_loss: 6.9377 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9907 - accuracy: 0.4583 - val_loss: 7.0185 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9212 - accuracy: 0.4583 - val_loss: 7.3054 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8626 - accuracy: 0.5000 - val_loss: 7.3027 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9241 - accuracy: 0.4167 - val_loss: 7.3184 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8163 - accuracy: 0.5000 - val_loss: 7.3303 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7482 - accuracy: 0.5000 - val_loss: 7.5407 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7084 - accuracy: 0.5417 - val_loss: 7.5495 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6635 - accuracy: 0.5000 - val_loss: 7.7962 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6243 - accuracy: 0.5417 - val_loss: 7.6373 - val_accuracy: 0.0000e+00\n","processing data batch 117\n","Epoch 1/30\n","6/6 [==============================] - 2s 127ms/step - loss: 3.4664 - accuracy: 0.0417 - val_loss: 3.4540 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.1653 - accuracy: 0.0833 - val_loss: 3.4523 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.0707 - accuracy: 0.1667 - val_loss: 3.4608 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9840 - accuracy: 0.1667 - val_loss: 3.4686 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9132 - accuracy: 0.1667 - val_loss: 3.4751 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8103 - accuracy: 0.3333 - val_loss: 3.4892 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6620 - accuracy: 0.4167 - val_loss: 3.5501 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4028 - accuracy: 0.4583 - val_loss: 3.7339 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1649 - accuracy: 0.5833 - val_loss: 3.9519 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9468 - accuracy: 0.5417 - val_loss: 4.2406 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8071 - accuracy: 0.5000 - val_loss: 4.5269 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6895 - accuracy: 0.5417 - val_loss: 4.8726 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5565 - accuracy: 0.5417 - val_loss: 5.1726 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5074 - accuracy: 0.5417 - val_loss: 5.4037 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4290 - accuracy: 0.5417 - val_loss: 5.6000 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3810 - accuracy: 0.5833 - val_loss: 5.7940 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3546 - accuracy: 0.5833 - val_loss: 6.0192 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2979 - accuracy: 0.5417 - val_loss: 6.1596 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2724 - accuracy: 0.5417 - val_loss: 6.3027 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2502 - accuracy: 0.5417 - val_loss: 6.4054 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2283 - accuracy: 0.5417 - val_loss: 6.5385 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2059 - accuracy: 0.5417 - val_loss: 6.6419 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2037 - accuracy: 0.5417 - val_loss: 6.7332 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2040 - accuracy: 0.5417 - val_loss: 6.7797 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2065 - accuracy: 0.5833 - val_loss: 6.8854 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1926 - accuracy: 0.5833 - val_loss: 6.9483 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1815 - accuracy: 0.5417 - val_loss: 7.0251 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1770 - accuracy: 0.5417 - val_loss: 7.0882 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1719 - accuracy: 0.5417 - val_loss: 7.1624 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1688 - accuracy: 0.5417 - val_loss: 7.2161 - val_accuracy: 0.0000e+00\n","processing data batch 118\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.4754 - accuracy: 0.0000e+00 - val_loss: 3.6201 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3032 - accuracy: 0.0417 - val_loss: 3.7008 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2084 - accuracy: 0.1250 - val_loss: 3.9409 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0602 - accuracy: 0.1250 - val_loss: 4.0928 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9503 - accuracy: 0.1250 - val_loss: 4.2619 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8368 - accuracy: 0.2500 - val_loss: 4.3698 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7198 - accuracy: 0.2083 - val_loss: 4.4757 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6326 - accuracy: 0.1667 - val_loss: 4.6025 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5336 - accuracy: 0.2083 - val_loss: 4.7237 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4808 - accuracy: 0.2083 - val_loss: 4.8219 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4190 - accuracy: 0.2500 - val_loss: 4.8962 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3354 - accuracy: 0.2500 - val_loss: 4.9901 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4061 - accuracy: 0.2500 - val_loss: 5.0552 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3711 - accuracy: 0.2083 - val_loss: 4.8954 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3143 - accuracy: 0.2917 - val_loss: 5.0055 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2505 - accuracy: 0.2500 - val_loss: 5.1033 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1982 - accuracy: 0.3333 - val_loss: 5.0988 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2319 - accuracy: 0.3333 - val_loss: 5.0581 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1672 - accuracy: 0.3333 - val_loss: 5.1265 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1316 - accuracy: 0.2917 - val_loss: 5.1997 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0908 - accuracy: 0.2917 - val_loss: 5.2856 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0452 - accuracy: 0.3333 - val_loss: 5.3123 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0047 - accuracy: 0.3750 - val_loss: 5.3916 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9642 - accuracy: 0.3750 - val_loss: 5.4502 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9439 - accuracy: 0.4583 - val_loss: 5.6031 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9643 - accuracy: 0.3750 - val_loss: 5.6689 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9539 - accuracy: 0.4167 - val_loss: 5.4462 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9851 - accuracy: 0.3333 - val_loss: 5.7890 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0081 - accuracy: 0.3333 - val_loss: 5.7948 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9500 - accuracy: 0.3750 - val_loss: 5.6887 - val_accuracy: 0.0000e+00\n","processing data batch 119\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4622 - accuracy: 0.0000e+00 - val_loss: 3.6694 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2835 - accuracy: 0.0417 - val_loss: 3.7477 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2365 - accuracy: 0.0833 - val_loss: 3.8001 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1824 - accuracy: 0.1250 - val_loss: 3.8733 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 26ms/step - loss: 3.1102 - accuracy: 0.0833 - val_loss: 3.9688 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0374 - accuracy: 0.0833 - val_loss: 4.0685 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9361 - accuracy: 0.1250 - val_loss: 4.2292 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7972 - accuracy: 0.1250 - val_loss: 4.4367 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6477 - accuracy: 0.1250 - val_loss: 4.6533 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4913 - accuracy: 0.2083 - val_loss: 4.8206 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3648 - accuracy: 0.2083 - val_loss: 4.8113 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3044 - accuracy: 0.1667 - val_loss: 4.9082 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2780 - accuracy: 0.2083 - val_loss: 5.1472 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1654 - accuracy: 0.2083 - val_loss: 5.0875 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1254 - accuracy: 0.2500 - val_loss: 5.3000 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0515 - accuracy: 0.2500 - val_loss: 5.4061 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0099 - accuracy: 0.2500 - val_loss: 5.5626 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9945 - accuracy: 0.2917 - val_loss: 5.6824 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0824 - accuracy: 0.2500 - val_loss: 5.6733 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1684 - accuracy: 0.2917 - val_loss: 5.6363 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9793 - accuracy: 0.2500 - val_loss: 5.6093 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9960 - accuracy: 0.2917 - val_loss: 5.6595 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9288 - accuracy: 0.3333 - val_loss: 5.6693 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9277 - accuracy: 0.3333 - val_loss: 5.6902 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9049 - accuracy: 0.2917 - val_loss: 5.7361 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8649 - accuracy: 0.3333 - val_loss: 5.8196 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8379 - accuracy: 0.4167 - val_loss: 5.9020 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7817 - accuracy: 0.4583 - val_loss: 5.9272 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7800 - accuracy: 0.4167 - val_loss: 5.9909 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7447 - accuracy: 0.3333 - val_loss: 6.0752 - val_accuracy: 0.0000e+00\n","processing data batch 120\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.5063 - accuracy: 0.0000e+00 - val_loss: 3.7638 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3701 - accuracy: 0.0833 - val_loss: 3.8057 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3321 - accuracy: 0.0833 - val_loss: 3.8577 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2854 - accuracy: 0.0833 - val_loss: 3.9233 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2496 - accuracy: 0.0833 - val_loss: 4.0033 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2043 - accuracy: 0.0833 - val_loss: 4.0886 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1421 - accuracy: 0.0417 - val_loss: 4.1909 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0519 - accuracy: 0.0417 - val_loss: 4.2978 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9690 - accuracy: 0.0833 - val_loss: 4.4157 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 30ms/step - loss: 2.8908 - accuracy: 0.0833 - val_loss: 4.5158 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8240 - accuracy: 0.0417 - val_loss: 4.6326 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7693 - accuracy: 0.1250 - val_loss: 4.7597 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7053 - accuracy: 0.1667 - val_loss: 4.8777 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6499 - accuracy: 0.1667 - val_loss: 4.9953 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6003 - accuracy: 0.2083 - val_loss: 5.0822 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5274 - accuracy: 0.1667 - val_loss: 5.1473 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4627 - accuracy: 0.1667 - val_loss: 5.1969 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3815 - accuracy: 0.2083 - val_loss: 5.2395 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3248 - accuracy: 0.2500 - val_loss: 5.2981 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2590 - accuracy: 0.2500 - val_loss: 5.3806 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2200 - accuracy: 0.2500 - val_loss: 5.4356 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1806 - accuracy: 0.2917 - val_loss: 5.5223 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1917 - accuracy: 0.2500 - val_loss: 5.5596 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1148 - accuracy: 0.3333 - val_loss: 5.5950 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0758 - accuracy: 0.3333 - val_loss: 5.7083 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0459 - accuracy: 0.3333 - val_loss: 5.7833 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.0210 - accuracy: 0.2917 - val_loss: 5.8683 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9935 - accuracy: 0.3333 - val_loss: 5.9440 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9668 - accuracy: 0.2917 - val_loss: 6.0294 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9552 - accuracy: 0.3333 - val_loss: 6.1058 - val_accuracy: 0.0000e+00\n","processing data batch 121\n","Epoch 1/30\n","6/6 [==============================] - 3s 127ms/step - loss: 3.5603 - accuracy: 0.0000e+00 - val_loss: 3.4811 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3911 - accuracy: 0.0833 - val_loss: 3.5092 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3171 - accuracy: 0.0417 - val_loss: 3.5287 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2481 - accuracy: 0.0833 - val_loss: 3.5349 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1926 - accuracy: 0.0833 - val_loss: 3.5576 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1219 - accuracy: 0.0833 - val_loss: 3.5599 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0573 - accuracy: 0.0833 - val_loss: 3.5814 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9904 - accuracy: 0.0833 - val_loss: 3.5785 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9059 - accuracy: 0.1667 - val_loss: 3.5796 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7789 - accuracy: 0.1667 - val_loss: 3.6870 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6535 - accuracy: 0.2083 - val_loss: 3.8701 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5605 - accuracy: 0.2083 - val_loss: 4.0597 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4999 - accuracy: 0.2500 - val_loss: 4.2161 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3886 - accuracy: 0.3750 - val_loss: 4.3707 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3341 - accuracy: 0.3750 - val_loss: 4.5372 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2638 - accuracy: 0.4167 - val_loss: 4.6956 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1593 - accuracy: 0.5000 - val_loss: 4.8150 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1068 - accuracy: 0.4583 - val_loss: 4.9270 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0221 - accuracy: 0.5417 - val_loss: 5.0407 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9241 - accuracy: 0.5000 - val_loss: 5.1816 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8626 - accuracy: 0.5000 - val_loss: 5.2948 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7765 - accuracy: 0.5417 - val_loss: 5.3608 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7586 - accuracy: 0.5417 - val_loss: 5.4536 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6714 - accuracy: 0.5000 - val_loss: 5.5447 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6115 - accuracy: 0.5417 - val_loss: 5.6914 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5579 - accuracy: 0.5000 - val_loss: 5.7894 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5252 - accuracy: 0.5417 - val_loss: 5.7945 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4914 - accuracy: 0.5000 - val_loss: 5.8226 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4688 - accuracy: 0.5417 - val_loss: 5.9050 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4475 - accuracy: 0.5417 - val_loss: 6.0051 - val_accuracy: 0.0000e+00\n","processing data batch 122\n","Epoch 1/30\n","6/6 [==============================] - 2s 127ms/step - loss: 3.4829 - accuracy: 0.0000e+00 - val_loss: 3.4408 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.2982 - accuracy: 0.0833 - val_loss: 3.4482 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2283 - accuracy: 0.0833 - val_loss: 3.4551 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1655 - accuracy: 0.0833 - val_loss: 3.4834 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1027 - accuracy: 0.1250 - val_loss: 3.4806 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0364 - accuracy: 0.1250 - val_loss: 3.5438 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9249 - accuracy: 0.1667 - val_loss: 3.6879 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7667 - accuracy: 0.1667 - val_loss: 3.9476 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6713 - accuracy: 0.1667 - val_loss: 4.1678 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5450 - accuracy: 0.2083 - val_loss: 4.2800 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4520 - accuracy: 0.2083 - val_loss: 4.5098 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3671 - accuracy: 0.2500 - val_loss: 4.7226 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3012 - accuracy: 0.2500 - val_loss: 4.8418 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2509 - accuracy: 0.3333 - val_loss: 4.9984 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1882 - accuracy: 0.3333 - val_loss: 5.1966 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1662 - accuracy: 0.3333 - val_loss: 5.4688 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1240 - accuracy: 0.2917 - val_loss: 5.6729 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0898 - accuracy: 0.2917 - val_loss: 5.9728 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0723 - accuracy: 0.2917 - val_loss: 6.0214 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0383 - accuracy: 0.3333 - val_loss: 5.8704 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0145 - accuracy: 0.3750 - val_loss: 5.8418 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0163 - accuracy: 0.2917 - val_loss: 5.9529 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.9660 - accuracy: 0.3333 - val_loss: 5.9671 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9552 - accuracy: 0.3333 - val_loss: 6.0928 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9404 - accuracy: 0.3750 - val_loss: 6.1259 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 26ms/step - loss: 1.9259 - accuracy: 0.3750 - val_loss: 6.4126 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8847 - accuracy: 0.3333 - val_loss: 7.5647 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8272 - accuracy: 0.5000 - val_loss: 6.3810 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8334 - accuracy: 0.4583 - val_loss: 6.2920 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8047 - accuracy: 0.4167 - val_loss: 6.2446 - val_accuracy: 0.0000e+00\n","processing data batch 123\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5063 - accuracy: 0.0000e+00 - val_loss: 3.4439 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3337 - accuracy: 0.0417 - val_loss: 3.4471 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2926 - accuracy: 0.0833 - val_loss: 3.4550 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2523 - accuracy: 0.0833 - val_loss: 3.4624 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2034 - accuracy: 0.0833 - val_loss: 3.4700 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1690 - accuracy: 0.0833 - val_loss: 3.4775 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1203 - accuracy: 0.0833 - val_loss: 3.4858 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0838 - accuracy: 0.1250 - val_loss: 3.4948 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0353 - accuracy: 0.1250 - val_loss: 3.5092 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9764 - accuracy: 0.1250 - val_loss: 3.5650 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8608 - accuracy: 0.1250 - val_loss: 3.7346 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7819 - accuracy: 0.1667 - val_loss: 3.8243 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7183 - accuracy: 0.1667 - val_loss: 4.2910 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6717 - accuracy: 0.1667 - val_loss: 4.5087 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6305 - accuracy: 0.1667 - val_loss: 4.6924 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5890 - accuracy: 0.1667 - val_loss: 4.8724 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5624 - accuracy: 0.1667 - val_loss: 5.0302 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5321 - accuracy: 0.1667 - val_loss: 5.1878 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5149 - accuracy: 0.1667 - val_loss: 5.3045 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4907 - accuracy: 0.1250 - val_loss: 5.4326 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4741 - accuracy: 0.1250 - val_loss: 5.5395 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4581 - accuracy: 0.1667 - val_loss: 5.6522 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4391 - accuracy: 0.1667 - val_loss: 5.7493 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4307 - accuracy: 0.2083 - val_loss: 5.8343 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4163 - accuracy: 0.2083 - val_loss: 5.9135 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4055 - accuracy: 0.1667 - val_loss: 5.9992 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3949 - accuracy: 0.1667 - val_loss: 6.0754 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3827 - accuracy: 0.1250 - val_loss: 6.1506 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3745 - accuracy: 0.1667 - val_loss: 6.2184 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3671 - accuracy: 0.1250 - val_loss: 6.2878 - val_accuracy: 0.0000e+00\n","processing data batch 124\n","Epoch 1/30\n","6/6 [==============================] - 2s 121ms/step - loss: 3.5368 - accuracy: 0.0000e+00 - val_loss: 3.5004 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3601 - accuracy: 0.0833 - val_loss: 3.5454 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3159 - accuracy: 0.0833 - val_loss: 3.6458 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2721 - accuracy: 0.1250 - val_loss: 3.7410 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2225 - accuracy: 0.1250 - val_loss: 3.8492 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1707 - accuracy: 0.1250 - val_loss: 3.9739 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1227 - accuracy: 0.2083 - val_loss: 4.1056 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0743 - accuracy: 0.2083 - val_loss: 4.3093 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0169 - accuracy: 0.1667 - val_loss: 4.5495 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9440 - accuracy: 0.2083 - val_loss: 4.8426 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8795 - accuracy: 0.2083 - val_loss: 5.1625 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7650 - accuracy: 0.2500 - val_loss: 5.4246 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6818 - accuracy: 0.1667 - val_loss: 5.5202 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5905 - accuracy: 0.1250 - val_loss: 5.7372 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4841 - accuracy: 0.2500 - val_loss: 5.8324 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3823 - accuracy: 0.3333 - val_loss: 5.7843 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2843 - accuracy: 0.3333 - val_loss: 6.0225 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2283 - accuracy: 0.2917 - val_loss: 5.9194 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1319 - accuracy: 0.3750 - val_loss: 5.9546 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2117 - accuracy: 0.3333 - val_loss: 5.3862 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1820 - accuracy: 0.2917 - val_loss: 5.6545 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0290 - accuracy: 0.4167 - val_loss: 6.2094 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1169 - accuracy: 0.3333 - val_loss: 6.3889 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 26ms/step - loss: 1.9864 - accuracy: 0.3333 - val_loss: 6.0706 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9341 - accuracy: 0.4167 - val_loss: 6.3710 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8821 - accuracy: 0.4167 - val_loss: 6.5828 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8713 - accuracy: 0.4167 - val_loss: 6.4259 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8312 - accuracy: 0.4167 - val_loss: 6.3737 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8089 - accuracy: 0.4167 - val_loss: 6.1144 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7968 - accuracy: 0.4583 - val_loss: 6.1675 - val_accuracy: 0.0000e+00\n","processing data batch 125\n","Epoch 1/30\n","6/6 [==============================] - 3s 248ms/step - loss: 3.4777 - accuracy: 0.0000e+00 - val_loss: 3.7855 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.3053 - accuracy: 0.0417 - val_loss: 3.8520 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2547 - accuracy: 0.1250 - val_loss: 3.8724 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1888 - accuracy: 0.1667 - val_loss: 3.9419 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0885 - accuracy: 0.1667 - val_loss: 4.0277 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9672 - accuracy: 0.2500 - val_loss: 4.2214 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8536 - accuracy: 0.2500 - val_loss: 4.3823 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7143 - accuracy: 0.2500 - val_loss: 4.4664 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6025 - accuracy: 0.2083 - val_loss: 4.4700 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4632 - accuracy: 0.3333 - val_loss: 4.6858 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3529 - accuracy: 0.2917 - val_loss: 4.8568 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3114 - accuracy: 0.2917 - val_loss: 4.8338 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.3720 - accuracy: 0.2500 - val_loss: 4.9044 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.2086 - accuracy: 0.3333 - val_loss: 4.9064 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1701 - accuracy: 0.3333 - val_loss: 4.8156 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1249 - accuracy: 0.2917 - val_loss: 4.9331 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.0978 - accuracy: 0.3750 - val_loss: 5.0494 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0646 - accuracy: 0.2917 - val_loss: 5.2480 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0436 - accuracy: 0.2917 - val_loss: 5.3437 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0113 - accuracy: 0.2917 - val_loss: 5.3856 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9954 - accuracy: 0.3333 - val_loss: 5.3431 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9735 - accuracy: 0.3750 - val_loss: 5.4166 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9537 - accuracy: 0.3333 - val_loss: 5.2746 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.9562 - accuracy: 0.2917 - val_loss: 5.2591 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9136 - accuracy: 0.3750 - val_loss: 5.2418 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.9156 - accuracy: 0.3333 - val_loss: 5.2357 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8783 - accuracy: 0.3750 - val_loss: 5.3182 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8898 - accuracy: 0.3750 - val_loss: 5.4283 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8630 - accuracy: 0.3750 - val_loss: 5.2189 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8532 - accuracy: 0.3750 - val_loss: 5.0522 - val_accuracy: 0.0000e+00\n","processing data batch 126\n","Epoch 1/30\n","6/6 [==============================] - 2s 127ms/step - loss: 3.5025 - accuracy: 0.0000e+00 - val_loss: 3.9781 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3457 - accuracy: 0.0417 - val_loss: 4.0678 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2474 - accuracy: 0.0417 - val_loss: 4.1875 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1858 - accuracy: 0.0833 - val_loss: 4.3497 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1366 - accuracy: 0.1250 - val_loss: 4.5002 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0354 - accuracy: 0.1667 - val_loss: 4.6603 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8419 - accuracy: 0.2083 - val_loss: 4.7957 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6474 - accuracy: 0.2917 - val_loss: 5.0071 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4759 - accuracy: 0.2083 - val_loss: 5.2236 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3304 - accuracy: 0.3333 - val_loss: 5.2377 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2744 - accuracy: 0.2500 - val_loss: 5.3890 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2171 - accuracy: 0.4583 - val_loss: 5.3842 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1405 - accuracy: 0.4167 - val_loss: 5.3256 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0748 - accuracy: 0.4583 - val_loss: 5.4665 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0174 - accuracy: 0.4583 - val_loss: 5.5313 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9487 - accuracy: 0.4583 - val_loss: 5.4423 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8832 - accuracy: 0.4583 - val_loss: 5.4616 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8186 - accuracy: 0.4583 - val_loss: 5.6395 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7292 - accuracy: 0.5417 - val_loss: 5.6688 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7522 - accuracy: 0.5000 - val_loss: 5.5446 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7215 - accuracy: 0.5000 - val_loss: 5.5550 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7227 - accuracy: 0.4167 - val_loss: 5.5014 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7456 - accuracy: 0.4583 - val_loss: 5.5082 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7161 - accuracy: 0.5000 - val_loss: 5.1265 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7126 - accuracy: 0.5000 - val_loss: 5.1737 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6780 - accuracy: 0.5000 - val_loss: 5.3451 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6347 - accuracy: 0.5000 - val_loss: 5.4170 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6247 - accuracy: 0.5000 - val_loss: 5.3994 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6006 - accuracy: 0.5000 - val_loss: 5.3594 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6267 - accuracy: 0.5000 - val_loss: 5.5809 - val_accuracy: 0.0000e+00\n","processing data batch 127\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.6468 - accuracy: 0.0000e+00 - val_loss: 3.3588 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2861 - accuracy: 0.0833 - val_loss: 3.4456 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1483 - accuracy: 0.1250 - val_loss: 3.5567 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9960 - accuracy: 0.1667 - val_loss: 3.6819 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8303 - accuracy: 0.2083 - val_loss: 3.8317 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6464 - accuracy: 0.3333 - val_loss: 4.0382 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4201 - accuracy: 0.5417 - val_loss: 4.2693 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2963 - accuracy: 0.4583 - val_loss: 4.5937 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0802 - accuracy: 0.5417 - val_loss: 4.8136 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9176 - accuracy: 0.7083 - val_loss: 4.9243 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8328 - accuracy: 0.7083 - val_loss: 5.0267 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6625 - accuracy: 0.7083 - val_loss: 5.2198 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5265 - accuracy: 0.7917 - val_loss: 5.3451 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3395 - accuracy: 0.9167 - val_loss: 5.4166 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1963 - accuracy: 0.8750 - val_loss: 5.3325 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0938 - accuracy: 0.8333 - val_loss: 5.3281 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9414 - accuracy: 0.9167 - val_loss: 5.2361 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.9478 - accuracy: 0.8750 - val_loss: 5.4339 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.8465 - accuracy: 0.8750 - val_loss: 5.6173 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.8047 - accuracy: 0.9167 - val_loss: 5.5475 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.7187 - accuracy: 0.8750 - val_loss: 5.6789 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.6608 - accuracy: 0.8750 - val_loss: 5.6189 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.5785 - accuracy: 0.9167 - val_loss: 5.5930 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.5422 - accuracy: 0.9167 - val_loss: 5.7295 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.4813 - accuracy: 0.9167 - val_loss: 5.8193 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.4720 - accuracy: 0.9167 - val_loss: 5.9080 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.4402 - accuracy: 0.8750 - val_loss: 5.9553 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.4085 - accuracy: 0.8750 - val_loss: 6.0011 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.3747 - accuracy: 0.8750 - val_loss: 6.0509 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.3589 - accuracy: 0.9167 - val_loss: 6.0983 - val_accuracy: 0.0000e+00\n","processing data batch 128\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.6976 - accuracy: 0.0000e+00 - val_loss: 3.4411 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3991 - accuracy: 0.0833 - val_loss: 3.4482 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2916 - accuracy: 0.0833 - val_loss: 3.4568 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1989 - accuracy: 0.1250 - val_loss: 3.4724 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1131 - accuracy: 0.2083 - val_loss: 3.5101 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0038 - accuracy: 0.2083 - val_loss: 3.5853 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8495 - accuracy: 0.2083 - val_loss: 3.7371 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6588 - accuracy: 0.2083 - val_loss: 3.9739 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4449 - accuracy: 0.2500 - val_loss: 4.2125 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2676 - accuracy: 0.3333 - val_loss: 4.3990 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2277 - accuracy: 0.3333 - val_loss: 4.6234 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1432 - accuracy: 0.2917 - val_loss: 4.7510 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0511 - accuracy: 0.3333 - val_loss: 4.8890 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0565 - accuracy: 0.4167 - val_loss: 5.0161 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9638 - accuracy: 0.4583 - val_loss: 5.1238 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8603 - accuracy: 0.5833 - val_loss: 5.2177 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8120 - accuracy: 0.6250 - val_loss: 5.3410 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7592 - accuracy: 0.5833 - val_loss: 5.4786 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8134 - accuracy: 0.6250 - val_loss: 5.5113 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0331 - accuracy: 0.5000 - val_loss: 5.5370 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8122 - accuracy: 0.5417 - val_loss: 5.5057 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7876 - accuracy: 0.5833 - val_loss: 5.5530 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7514 - accuracy: 0.5417 - val_loss: 5.6436 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6586 - accuracy: 0.6250 - val_loss: 5.7333 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6097 - accuracy: 0.6250 - val_loss: 5.8193 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5694 - accuracy: 0.5833 - val_loss: 5.9068 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5092 - accuracy: 0.6667 - val_loss: 6.0104 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4672 - accuracy: 0.5833 - val_loss: 6.1905 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4057 - accuracy: 0.5833 - val_loss: 6.1881 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4078 - accuracy: 0.6250 - val_loss: 6.3446 - val_accuracy: 0.0000e+00\n","processing data batch 129\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.4486 - accuracy: 0.0000e+00 - val_loss: 3.6228 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3279 - accuracy: 0.0417 - val_loss: 3.6792 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2961 - accuracy: 0.0833 - val_loss: 3.7738 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2527 - accuracy: 0.0833 - val_loss: 3.8241 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2199 - accuracy: 0.0833 - val_loss: 3.8857 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1878 - accuracy: 0.0833 - val_loss: 3.9651 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1550 - accuracy: 0.0833 - val_loss: 4.0565 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1080 - accuracy: 0.1250 - val_loss: 4.1397 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0541 - accuracy: 0.1250 - val_loss: 4.2448 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9635 - accuracy: 0.1250 - val_loss: 4.3001 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8946 - accuracy: 0.1250 - val_loss: 4.3495 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8576 - accuracy: 0.1250 - val_loss: 4.4034 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8131 - accuracy: 0.0833 - val_loss: 4.4537 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7819 - accuracy: 0.1250 - val_loss: 4.5148 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7533 - accuracy: 0.1250 - val_loss: 4.5855 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7193 - accuracy: 0.1250 - val_loss: 4.6642 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6991 - accuracy: 0.1250 - val_loss: 4.7292 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6774 - accuracy: 0.0833 - val_loss: 4.8300 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6578 - accuracy: 0.0833 - val_loss: 4.9332 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6398 - accuracy: 0.0833 - val_loss: 4.8013 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6284 - accuracy: 0.1250 - val_loss: 5.1457 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6170 - accuracy: 0.1250 - val_loss: 5.2087 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6009 - accuracy: 0.1250 - val_loss: 5.2852 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5908 - accuracy: 0.1250 - val_loss: 5.0962 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5809 - accuracy: 0.1667 - val_loss: 5.0755 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5722 - accuracy: 0.2083 - val_loss: 5.1785 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5620 - accuracy: 0.2083 - val_loss: 5.5274 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5535 - accuracy: 0.2083 - val_loss: 5.6225 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.5522 - accuracy: 0.2500 - val_loss: 5.7223 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5514 - accuracy: 0.2500 - val_loss: 5.7758 - val_accuracy: 0.0000e+00\n","processing data batch 130\n","Epoch 1/30\n","6/6 [==============================] - 3s 132ms/step - loss: 3.4717 - accuracy: 0.0000e+00 - val_loss: 3.4647 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3439 - accuracy: 0.0417 - val_loss: 3.5032 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3000 - accuracy: 0.0417 - val_loss: 3.5109 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2670 - accuracy: 0.0833 - val_loss: 3.5580 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2301 - accuracy: 0.0833 - val_loss: 3.6271 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1676 - accuracy: 0.0833 - val_loss: 3.7370 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1105 - accuracy: 0.0833 - val_loss: 3.9394 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0253 - accuracy: 0.0833 - val_loss: 4.2200 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9530 - accuracy: 0.1250 - val_loss: 4.5458 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8821 - accuracy: 0.1250 - val_loss: 4.8011 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8351 - accuracy: 0.1250 - val_loss: 5.0984 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7872 - accuracy: 0.0833 - val_loss: 5.3526 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7541 - accuracy: 0.0833 - val_loss: 5.6189 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7354 - accuracy: 0.0833 - val_loss: 5.7915 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7046 - accuracy: 0.1250 - val_loss: 5.9731 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6826 - accuracy: 0.1667 - val_loss: 6.1794 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6932 - accuracy: 0.0833 - val_loss: 6.3440 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6757 - accuracy: 0.0833 - val_loss: 6.4830 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6432 - accuracy: 0.2083 - val_loss: 6.6020 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6226 - accuracy: 0.2500 - val_loss: 6.6909 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6169 - accuracy: 0.1667 - val_loss: 6.7997 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6083 - accuracy: 0.1667 - val_loss: 6.8723 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5899 - accuracy: 0.2083 - val_loss: 6.9733 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5766 - accuracy: 0.2500 - val_loss: 7.0423 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.5633 - accuracy: 0.2500 - val_loss: 7.1446 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5590 - accuracy: 0.2083 - val_loss: 7.2308 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5526 - accuracy: 0.2500 - val_loss: 7.2312 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5343 - accuracy: 0.2083 - val_loss: 7.3108 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5236 - accuracy: 0.2083 - val_loss: 7.3509 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5444 - accuracy: 0.2083 - val_loss: 7.4244 - val_accuracy: 0.0000e+00\n","processing data batch 131\n","Epoch 1/30\n","6/6 [==============================] - 2s 127ms/step - loss: 3.5494 - accuracy: 0.0000e+00 - val_loss: 3.4678 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4184 - accuracy: 0.0833 - val_loss: 3.5139 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3408 - accuracy: 0.0833 - val_loss: 3.7693 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2333 - accuracy: 0.0833 - val_loss: 4.1376 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1160 - accuracy: 0.0833 - val_loss: 4.4329 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0091 - accuracy: 0.0833 - val_loss: 4.6410 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9135 - accuracy: 0.0833 - val_loss: 4.8097 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8419 - accuracy: 0.0833 - val_loss: 4.9677 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7787 - accuracy: 0.0417 - val_loss: 5.1704 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7395 - accuracy: 0.0833 - val_loss: 5.3525 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6847 - accuracy: 0.1250 - val_loss: 5.5150 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6592 - accuracy: 0.0833 - val_loss: 5.6300 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6242 - accuracy: 0.1250 - val_loss: 5.7493 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6029 - accuracy: 0.1667 - val_loss: 5.8721 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5882 - accuracy: 0.1250 - val_loss: 5.9777 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5523 - accuracy: 0.1250 - val_loss: 6.0588 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5422 - accuracy: 0.1667 - val_loss: 6.1538 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5308 - accuracy: 0.1667 - val_loss: 6.2145 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5363 - accuracy: 0.2083 - val_loss: 6.3160 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5330 - accuracy: 0.1667 - val_loss: 6.3795 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5360 - accuracy: 0.1667 - val_loss: 6.4585 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5283 - accuracy: 0.2083 - val_loss: 6.4402 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4891 - accuracy: 0.1250 - val_loss: 6.5036 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.4549 - accuracy: 0.2083 - val_loss: 6.5837 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4164 - accuracy: 0.1667 - val_loss: 6.6523 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5345 - accuracy: 0.1667 - val_loss: 6.6901 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4899 - accuracy: 0.1250 - val_loss: 6.7134 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5398 - accuracy: 0.1250 - val_loss: 6.7842 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5276 - accuracy: 0.0833 - val_loss: 6.7271 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4792 - accuracy: 0.1667 - val_loss: 6.7765 - val_accuracy: 0.0000e+00\n","processing data batch 132\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4593 - accuracy: 0.0000e+00 - val_loss: 3.7434 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3442 - accuracy: 0.0417 - val_loss: 3.7715 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3047 - accuracy: 0.0833 - val_loss: 3.8165 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2708 - accuracy: 0.0833 - val_loss: 3.8655 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2309 - accuracy: 0.0833 - val_loss: 3.9193 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1929 - accuracy: 0.0833 - val_loss: 4.0240 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1527 - accuracy: 0.0833 - val_loss: 4.1254 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1015 - accuracy: 0.1250 - val_loss: 4.1882 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0497 - accuracy: 0.0833 - val_loss: 4.2535 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9781 - accuracy: 0.0833 - val_loss: 4.3138 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9111 - accuracy: 0.1250 - val_loss: 4.3557 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8715 - accuracy: 0.1250 - val_loss: 4.3985 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8203 - accuracy: 0.1250 - val_loss: 4.4486 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7676 - accuracy: 0.1667 - val_loss: 4.5025 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7272 - accuracy: 0.1667 - val_loss: 4.5554 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7065 - accuracy: 0.1667 - val_loss: 4.6118 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6767 - accuracy: 0.1667 - val_loss: 4.6547 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6564 - accuracy: 0.1667 - val_loss: 4.7045 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6318 - accuracy: 0.2083 - val_loss: 4.7442 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6117 - accuracy: 0.1667 - val_loss: 4.8090 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5975 - accuracy: 0.1667 - val_loss: 4.8596 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5760 - accuracy: 0.1667 - val_loss: 4.9070 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5562 - accuracy: 0.2500 - val_loss: 4.9525 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5491 - accuracy: 0.1667 - val_loss: 4.9888 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5340 - accuracy: 0.2083 - val_loss: 5.1548 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.4933 - accuracy: 0.3333 - val_loss: 5.2898 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4836 - accuracy: 0.2500 - val_loss: 5.3442 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4674 - accuracy: 0.2917 - val_loss: 5.4783 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4374 - accuracy: 0.2917 - val_loss: 5.6334 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4086 - accuracy: 0.2917 - val_loss: 5.7015 - val_accuracy: 0.0000e+00\n","processing data batch 133\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.4501 - accuracy: 0.0000e+00 - val_loss: 3.8106 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3016 - accuracy: 0.0833 - val_loss: 4.0450 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2550 - accuracy: 0.0833 - val_loss: 4.3100 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2174 - accuracy: 0.1250 - val_loss: 4.5267 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1650 - accuracy: 0.1250 - val_loss: 4.7338 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1124 - accuracy: 0.1250 - val_loss: 4.9802 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0466 - accuracy: 0.1667 - val_loss: 5.4065 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9815 - accuracy: 0.1250 - val_loss: 5.4945 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8888 - accuracy: 0.1667 - val_loss: 5.6125 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8330 - accuracy: 0.1250 - val_loss: 5.7456 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7939 - accuracy: 0.1250 - val_loss: 5.8089 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7536 - accuracy: 0.2083 - val_loss: 5.9003 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7120 - accuracy: 0.1667 - val_loss: 5.9735 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6853 - accuracy: 0.2083 - val_loss: 6.0582 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6525 - accuracy: 0.2083 - val_loss: 6.0769 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6497 - accuracy: 0.1667 - val_loss: 6.1835 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6255 - accuracy: 0.1667 - val_loss: 6.2481 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6090 - accuracy: 0.1667 - val_loss: 6.2627 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6034 - accuracy: 0.1667 - val_loss: 6.3272 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5858 - accuracy: 0.2083 - val_loss: 6.4094 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.5852 - accuracy: 0.1667 - val_loss: 6.4403 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5712 - accuracy: 0.1667 - val_loss: 6.5164 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5745 - accuracy: 0.2083 - val_loss: 6.5605 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5617 - accuracy: 0.2083 - val_loss: 6.6541 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5626 - accuracy: 0.1667 - val_loss: 6.6999 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5559 - accuracy: 0.2083 - val_loss: 6.5880 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5587 - accuracy: 0.2083 - val_loss: 6.5456 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5460 - accuracy: 0.1667 - val_loss: 6.5866 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5639 - accuracy: 0.1667 - val_loss: 6.4624 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5532 - accuracy: 0.2083 - val_loss: 6.6121 - val_accuracy: 0.0000e+00\n","processing data batch 134\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.6734 - accuracy: 0.0000e+00 - val_loss: 3.6452 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4726 - accuracy: 0.0833 - val_loss: 3.7123 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3389 - accuracy: 0.0417 - val_loss: 3.7810 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2232 - accuracy: 0.0833 - val_loss: 3.8956 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0783 - accuracy: 0.0833 - val_loss: 3.9964 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9734 - accuracy: 0.1250 - val_loss: 4.1262 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8509 - accuracy: 0.0833 - val_loss: 4.3956 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7737 - accuracy: 0.0833 - val_loss: 4.5120 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7084 - accuracy: 0.0417 - val_loss: 4.5647 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6387 - accuracy: 0.2917 - val_loss: 4.8028 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6260 - accuracy: 0.2083 - val_loss: 5.1202 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5621 - accuracy: 0.2500 - val_loss: 5.0589 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4914 - accuracy: 0.2917 - val_loss: 5.1388 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4374 - accuracy: 0.4167 - val_loss: 5.1389 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4009 - accuracy: 0.4167 - val_loss: 5.2685 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3412 - accuracy: 0.3333 - val_loss: 5.2905 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2947 - accuracy: 0.4167 - val_loss: 5.4398 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2332 - accuracy: 0.5000 - val_loss: 5.7148 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1933 - accuracy: 0.4583 - val_loss: 5.7450 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1546 - accuracy: 0.5000 - val_loss: 5.7223 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1034 - accuracy: 0.5000 - val_loss: 5.8372 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0575 - accuracy: 0.5000 - val_loss: 5.8077 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9701 - accuracy: 0.4583 - val_loss: 5.8161 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9134 - accuracy: 0.5417 - val_loss: 5.8813 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8115 - accuracy: 0.5417 - val_loss: 6.0783 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7475 - accuracy: 0.5000 - val_loss: 5.8943 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7031 - accuracy: 0.5417 - val_loss: 5.6955 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6865 - accuracy: 0.5000 - val_loss: 5.4638 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6230 - accuracy: 0.5417 - val_loss: 5.2673 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5769 - accuracy: 0.5417 - val_loss: 5.3966 - val_accuracy: 0.0000e+00\n","processing data batch 135\n","Epoch 1/30\n","6/6 [==============================] - 3s 129ms/step - loss: 3.7036 - accuracy: 0.0000e+00 - val_loss: 3.5618 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3320 - accuracy: 0.0833 - val_loss: 3.6244 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1849 - accuracy: 0.0417 - val_loss: 3.7974 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0150 - accuracy: 0.0833 - val_loss: 4.0203 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8799 - accuracy: 0.1250 - val_loss: 4.2512 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7482 - accuracy: 0.2083 - val_loss: 4.4326 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6442 - accuracy: 0.3333 - val_loss: 4.6221 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5439 - accuracy: 0.3750 - val_loss: 4.8061 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4027 - accuracy: 0.3750 - val_loss: 4.9429 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3494 - accuracy: 0.3333 - val_loss: 5.0307 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1807 - accuracy: 0.3750 - val_loss: 5.1544 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0440 - accuracy: 0.5000 - val_loss: 5.2977 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9214 - accuracy: 0.5833 - val_loss: 5.4323 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8218 - accuracy: 0.5417 - val_loss: 5.5564 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8109 - accuracy: 0.6250 - val_loss: 5.7254 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6990 - accuracy: 0.5833 - val_loss: 5.7883 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6213 - accuracy: 0.5833 - val_loss: 5.8424 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5362 - accuracy: 0.6250 - val_loss: 5.7970 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4994 - accuracy: 0.6667 - val_loss: 5.6378 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5044 - accuracy: 0.6250 - val_loss: 5.6965 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4665 - accuracy: 0.6250 - val_loss: 5.8458 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4867 - accuracy: 0.6250 - val_loss: 5.9721 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4245 - accuracy: 0.6250 - val_loss: 5.9333 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3625 - accuracy: 0.6250 - val_loss: 5.9530 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3240 - accuracy: 0.5833 - val_loss: 6.0827 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2904 - accuracy: 0.5833 - val_loss: 6.2047 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2604 - accuracy: 0.6250 - val_loss: 6.2670 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2324 - accuracy: 0.6250 - val_loss: 6.3006 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2159 - accuracy: 0.5833 - val_loss: 6.3737 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1944 - accuracy: 0.5833 - val_loss: 6.4349 - val_accuracy: 0.0000e+00\n","processing data batch 136\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.5295 - accuracy: 0.0000e+00 - val_loss: 3.6602 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2559 - accuracy: 0.1250 - val_loss: 3.7249 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0966 - accuracy: 0.2083 - val_loss: 3.8472 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9494 - accuracy: 0.2083 - val_loss: 3.9521 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7756 - accuracy: 0.2917 - val_loss: 4.0899 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6437 - accuracy: 0.2917 - val_loss: 4.0819 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5409 - accuracy: 0.1667 - val_loss: 4.2929 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3632 - accuracy: 0.3750 - val_loss: 4.6675 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1577 - accuracy: 0.4167 - val_loss: 4.5356 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9872 - accuracy: 0.5417 - val_loss: 5.0090 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8313 - accuracy: 0.5833 - val_loss: 5.0195 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7309 - accuracy: 0.6250 - val_loss: 5.1581 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7754 - accuracy: 0.5833 - val_loss: 4.9204 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.7346 - accuracy: 0.6250 - val_loss: 5.1653 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 30ms/step - loss: 1.6301 - accuracy: 0.6250 - val_loss: 5.1061 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5267 - accuracy: 0.5833 - val_loss: 5.0505 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4587 - accuracy: 0.5833 - val_loss: 5.3442 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3916 - accuracy: 0.5833 - val_loss: 5.5420 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3419 - accuracy: 0.5833 - val_loss: 5.4825 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3280 - accuracy: 0.5833 - val_loss: 5.7448 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2611 - accuracy: 0.6250 - val_loss: 6.0362 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2074 - accuracy: 0.6250 - val_loss: 5.7670 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1826 - accuracy: 0.6250 - val_loss: 5.7526 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2024 - accuracy: 0.6250 - val_loss: 5.7957 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2064 - accuracy: 0.6250 - val_loss: 5.8028 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1950 - accuracy: 0.6250 - val_loss: 5.7413 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1663 - accuracy: 0.6250 - val_loss: 5.7207 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1363 - accuracy: 0.6250 - val_loss: 5.7886 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1237 - accuracy: 0.5833 - val_loss: 5.9357 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.0981 - accuracy: 0.5833 - val_loss: 6.0587 - val_accuracy: 0.0000e+00\n","processing data batch 137\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.4618 - accuracy: 0.0000e+00 - val_loss: 3.4844 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2919 - accuracy: 0.0417 - val_loss: 3.4772 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2354 - accuracy: 0.0833 - val_loss: 3.5141 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1897 - accuracy: 0.0833 - val_loss: 3.5415 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1514 - accuracy: 0.0833 - val_loss: 3.5614 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1087 - accuracy: 0.0833 - val_loss: 3.5868 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0837 - accuracy: 0.0833 - val_loss: 3.6170 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0578 - accuracy: 0.1667 - val_loss: 3.6360 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0165 - accuracy: 0.1667 - val_loss: 3.6580 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9723 - accuracy: 0.2083 - val_loss: 3.7122 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9187 - accuracy: 0.2500 - val_loss: 3.7803 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8330 - accuracy: 0.2917 - val_loss: 4.0101 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7665 - accuracy: 0.2917 - val_loss: 4.2843 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7041 - accuracy: 0.2917 - val_loss: 4.6219 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6434 - accuracy: 0.2500 - val_loss: 4.9941 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6100 - accuracy: 0.2083 - val_loss: 5.0930 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5612 - accuracy: 0.2917 - val_loss: 5.2915 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5270 - accuracy: 0.2917 - val_loss: 5.3947 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4988 - accuracy: 0.2917 - val_loss: 5.5455 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4813 - accuracy: 0.2500 - val_loss: 5.6954 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4763 - accuracy: 0.2500 - val_loss: 5.8378 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4363 - accuracy: 0.2917 - val_loss: 5.9138 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4817 - accuracy: 0.2917 - val_loss: 6.0695 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4492 - accuracy: 0.2917 - val_loss: 6.0740 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4459 - accuracy: 0.2917 - val_loss: 6.0963 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4789 - accuracy: 0.2500 - val_loss: 6.1935 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4962 - accuracy: 0.2083 - val_loss: 6.3351 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.4704 - accuracy: 0.2500 - val_loss: 6.4051 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4477 - accuracy: 0.2500 - val_loss: 6.4673 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4209 - accuracy: 0.2500 - val_loss: 6.5841 - val_accuracy: 0.0000e+00\n","processing data batch 138\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.5302 - accuracy: 0.0000e+00 - val_loss: 3.6040 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3024 - accuracy: 0.0833 - val_loss: 3.6278 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2411 - accuracy: 0.0833 - val_loss: 3.6653 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1587 - accuracy: 0.1250 - val_loss: 3.7727 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0570 - accuracy: 0.1250 - val_loss: 3.9034 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9306 - accuracy: 0.1250 - val_loss: 4.0663 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7952 - accuracy: 0.0833 - val_loss: 4.2119 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6117 - accuracy: 0.1667 - val_loss: 4.3597 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5074 - accuracy: 0.1667 - val_loss: 4.4933 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3781 - accuracy: 0.1667 - val_loss: 4.5799 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2524 - accuracy: 0.3750 - val_loss: 4.8959 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1488 - accuracy: 0.3750 - val_loss: 4.9714 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0746 - accuracy: 0.3750 - val_loss: 4.9595 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1759 - accuracy: 0.3750 - val_loss: 5.1066 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2332 - accuracy: 0.3333 - val_loss: 4.9092 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1713 - accuracy: 0.4167 - val_loss: 4.8278 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0905 - accuracy: 0.4167 - val_loss: 5.1213 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0551 - accuracy: 0.4167 - val_loss: 5.2739 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0227 - accuracy: 0.4167 - val_loss: 5.4567 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8299 - accuracy: 0.3750 - val_loss: 5.2655 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8178 - accuracy: 0.4583 - val_loss: 5.4923 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8990 - accuracy: 0.4167 - val_loss: 5.5223 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7858 - accuracy: 0.4167 - val_loss: 5.3536 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7839 - accuracy: 0.3750 - val_loss: 5.3034 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7406 - accuracy: 0.4167 - val_loss: 5.3467 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7839 - accuracy: 0.4167 - val_loss: 5.6795 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8025 - accuracy: 0.4167 - val_loss: 5.7402 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7832 - accuracy: 0.4167 - val_loss: 5.9511 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8020 - accuracy: 0.4583 - val_loss: 5.6546 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8112 - accuracy: 0.4167 - val_loss: 5.6274 - val_accuracy: 0.0000e+00\n","processing data batch 139\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.5282 - accuracy: 0.0000e+00 - val_loss: 3.5760 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.3577 - accuracy: 0.0833 - val_loss: 3.6748 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2421 - accuracy: 0.0833 - val_loss: 3.8086 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1044 - accuracy: 0.1250 - val_loss: 3.9024 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0021 - accuracy: 0.1250 - val_loss: 4.0118 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8996 - accuracy: 0.1250 - val_loss: 4.1017 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8240 - accuracy: 0.1250 - val_loss: 4.1910 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7687 - accuracy: 0.1667 - val_loss: 4.2665 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7430 - accuracy: 0.2500 - val_loss: 4.3222 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6760 - accuracy: 0.2083 - val_loss: 4.3220 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6304 - accuracy: 0.2083 - val_loss: 4.3179 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5699 - accuracy: 0.2500 - val_loss: 4.3346 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5142 - accuracy: 0.2083 - val_loss: 4.4183 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4723 - accuracy: 0.2500 - val_loss: 4.5082 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4196 - accuracy: 0.2917 - val_loss: 4.5495 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3863 - accuracy: 0.2500 - val_loss: 4.5869 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3371 - accuracy: 0.2500 - val_loss: 4.6098 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2791 - accuracy: 0.2917 - val_loss: 4.6980 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2346 - accuracy: 0.3333 - val_loss: 4.7534 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2154 - accuracy: 0.2083 - val_loss: 4.8000 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1622 - accuracy: 0.2083 - val_loss: 4.8545 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1644 - accuracy: 0.1667 - val_loss: 4.8974 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1674 - accuracy: 0.2917 - val_loss: 4.9377 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2221 - accuracy: 0.2500 - val_loss: 4.9260 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1839 - accuracy: 0.2500 - val_loss: 4.9237 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1914 - accuracy: 0.2083 - val_loss: 4.9278 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1551 - accuracy: 0.2500 - val_loss: 4.9591 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0852 - accuracy: 0.3333 - val_loss: 5.0505 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0802 - accuracy: 0.2917 - val_loss: 5.1090 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0481 - accuracy: 0.3333 - val_loss: 5.1342 - val_accuracy: 0.0000e+00\n","processing data batch 140\n","Epoch 1/30\n","6/6 [==============================] - 3s 130ms/step - loss: 3.5488 - accuracy: 0.0000e+00 - val_loss: 3.9443 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.2693 - accuracy: 0.1250 - val_loss: 3.9877 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1864 - accuracy: 0.1250 - val_loss: 4.0525 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1041 - accuracy: 0.1667 - val_loss: 4.1300 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9640 - accuracy: 0.1667 - val_loss: 4.2579 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8341 - accuracy: 0.0833 - val_loss: 4.3247 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7130 - accuracy: 0.1250 - val_loss: 4.4361 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6035 - accuracy: 0.2083 - val_loss: 4.4465 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5553 - accuracy: 0.2917 - val_loss: 4.5085 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4551 - accuracy: 0.2917 - val_loss: 4.5404 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4001 - accuracy: 0.3333 - val_loss: 4.5562 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3693 - accuracy: 0.2917 - val_loss: 4.5915 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2817 - accuracy: 0.2500 - val_loss: 4.6463 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2271 - accuracy: 0.2917 - val_loss: 4.8475 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1187 - accuracy: 0.4167 - val_loss: 4.8540 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0511 - accuracy: 0.4167 - val_loss: 4.9316 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9596 - accuracy: 0.4167 - val_loss: 4.9133 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8562 - accuracy: 0.5417 - val_loss: 4.8258 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7822 - accuracy: 0.5833 - val_loss: 4.7748 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7224 - accuracy: 0.6250 - val_loss: 4.8532 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5936 - accuracy: 0.5833 - val_loss: 4.8602 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5087 - accuracy: 0.5833 - val_loss: 4.8537 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4008 - accuracy: 0.6250 - val_loss: 4.7616 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3630 - accuracy: 0.5833 - val_loss: 4.7461 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2540 - accuracy: 0.5833 - val_loss: 4.8840 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2558 - accuracy: 0.5833 - val_loss: 4.6451 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3087 - accuracy: 0.5833 - val_loss: 4.6206 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3864 - accuracy: 0.5833 - val_loss: 4.6574 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2902 - accuracy: 0.5833 - val_loss: 4.7397 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 26ms/step - loss: 1.2337 - accuracy: 0.5833 - val_loss: 4.6652 - val_accuracy: 0.0000e+00\n","processing data batch 141\n","Epoch 1/30\n","6/6 [==============================] - 3s 129ms/step - loss: 3.7319 - accuracy: 0.0000e+00 - val_loss: 3.4885 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3654 - accuracy: 0.0417 - val_loss: 3.5464 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2382 - accuracy: 0.1250 - val_loss: 3.7100 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0408 - accuracy: 0.2083 - val_loss: 3.9223 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8644 - accuracy: 0.2083 - val_loss: 4.2382 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6782 - accuracy: 0.2500 - val_loss: 4.6100 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5195 - accuracy: 0.1667 - val_loss: 4.6545 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4218 - accuracy: 0.3333 - val_loss: 4.8512 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3224 - accuracy: 0.3333 - val_loss: 4.9601 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2090 - accuracy: 0.3750 - val_loss: 5.1216 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.1773 - accuracy: 0.3333 - val_loss: 5.2799 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1136 - accuracy: 0.3333 - val_loss: 5.3839 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0774 - accuracy: 0.3750 - val_loss: 5.3991 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0062 - accuracy: 0.4583 - val_loss: 5.4818 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9600 - accuracy: 0.5833 - val_loss: 5.6399 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9296 - accuracy: 0.5833 - val_loss: 5.6955 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8829 - accuracy: 0.5417 - val_loss: 5.8184 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8329 - accuracy: 0.6250 - val_loss: 5.8780 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8364 - accuracy: 0.5417 - val_loss: 5.8964 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7621 - accuracy: 0.5417 - val_loss: 5.9729 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7515 - accuracy: 0.5833 - val_loss: 6.0588 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8010 - accuracy: 0.5417 - val_loss: 6.1408 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7404 - accuracy: 0.5000 - val_loss: 6.1867 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6650 - accuracy: 0.5417 - val_loss: 6.2338 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6463 - accuracy: 0.6250 - val_loss: 6.3114 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5882 - accuracy: 0.5417 - val_loss: 6.3346 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4739 - accuracy: 0.7500 - val_loss: 6.3717 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4857 - accuracy: 0.6667 - val_loss: 6.3617 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3793 - accuracy: 0.6667 - val_loss: 6.4028 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.2943 - accuracy: 0.6667 - val_loss: 6.5002 - val_accuracy: 0.0000e+00\n","processing data batch 142\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.6810 - accuracy: 0.0000e+00 - val_loss: 3.4441 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.2999 - accuracy: 0.0417 - val_loss: 3.4516 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2151 - accuracy: 0.0417 - val_loss: 3.5120 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1606 - accuracy: 0.1250 - val_loss: 3.6222 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0425 - accuracy: 0.1250 - val_loss: 3.9143 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9007 - accuracy: 0.2500 - val_loss: 4.1211 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7678 - accuracy: 0.2083 - val_loss: 4.3616 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6644 - accuracy: 0.2083 - val_loss: 4.6258 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5690 - accuracy: 0.2500 - val_loss: 4.9453 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4683 - accuracy: 0.2917 - val_loss: 5.1609 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3973 - accuracy: 0.2917 - val_loss: 5.2928 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2899 - accuracy: 0.3333 - val_loss: 5.5625 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.2490 - accuracy: 0.3333 - val_loss: 5.6328 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1679 - accuracy: 0.3750 - val_loss: 5.6852 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1326 - accuracy: 0.4583 - val_loss: 5.6564 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0705 - accuracy: 0.4583 - val_loss: 5.8537 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0384 - accuracy: 0.4583 - val_loss: 5.7752 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0454 - accuracy: 0.4167 - val_loss: 5.8346 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9641 - accuracy: 0.4583 - val_loss: 5.7921 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9534 - accuracy: 0.4167 - val_loss: 5.7839 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9975 - accuracy: 0.4583 - val_loss: 5.8777 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9916 - accuracy: 0.5000 - val_loss: 5.9344 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9700 - accuracy: 0.4583 - val_loss: 6.0847 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8792 - accuracy: 0.5000 - val_loss: 6.1000 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 26ms/step - loss: 1.8308 - accuracy: 0.4583 - val_loss: 5.9280 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7797 - accuracy: 0.4583 - val_loss: 6.2380 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7314 - accuracy: 0.4583 - val_loss: 6.4309 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7148 - accuracy: 0.4167 - val_loss: 6.4447 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6955 - accuracy: 0.5000 - val_loss: 6.3316 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.7223 - accuracy: 0.5000 - val_loss: 6.3580 - val_accuracy: 0.0000e+00\n","processing data batch 143\n","Epoch 1/30\n","6/6 [==============================] - 2s 122ms/step - loss: 3.5548 - accuracy: 0.0000e+00 - val_loss: 3.4572 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3731 - accuracy: 0.0417 - val_loss: 3.4916 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2458 - accuracy: 0.0833 - val_loss: 3.6665 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1518 - accuracy: 0.0833 - val_loss: 4.0167 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0645 - accuracy: 0.0833 - val_loss: 4.2913 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9747 - accuracy: 0.0833 - val_loss: 4.4751 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9017 - accuracy: 0.1250 - val_loss: 4.6825 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8673 - accuracy: 0.0833 - val_loss: 4.9143 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7950 - accuracy: 0.1250 - val_loss: 5.1014 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7613 - accuracy: 0.0833 - val_loss: 5.2803 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7275 - accuracy: 0.0833 - val_loss: 5.4854 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7088 - accuracy: 0.0833 - val_loss: 5.6387 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6865 - accuracy: 0.0833 - val_loss: 5.7990 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6518 - accuracy: 0.0833 - val_loss: 5.9437 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6445 - accuracy: 0.0833 - val_loss: 6.0476 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6269 - accuracy: 0.1250 - val_loss: 6.1514 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6078 - accuracy: 0.0833 - val_loss: 6.2465 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5976 - accuracy: 0.1250 - val_loss: 6.3526 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5900 - accuracy: 0.1667 - val_loss: 6.4748 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5829 - accuracy: 0.1250 - val_loss: 6.4999 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5726 - accuracy: 0.1667 - val_loss: 6.5729 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5574 - accuracy: 0.1667 - val_loss: 6.6633 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5428 - accuracy: 0.1667 - val_loss: 6.7342 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5409 - accuracy: 0.1667 - val_loss: 6.8246 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5320 - accuracy: 0.2083 - val_loss: 6.8607 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5425 - accuracy: 0.1667 - val_loss: 6.2614 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5700 - accuracy: 0.1667 - val_loss: 6.6919 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5488 - accuracy: 0.1250 - val_loss: 6.7185 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5342 - accuracy: 0.1667 - val_loss: 6.7773 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5226 - accuracy: 0.2083 - val_loss: 6.8371 - val_accuracy: 0.0000e+00\n","processing data batch 144\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4445 - accuracy: 0.0000e+00 - val_loss: 3.5031 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.4332 - accuracy: 0.0000e+00 - val_loss: 3.5225 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.4222 - accuracy: 0.0417 - val_loss: 3.6323 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3965 - accuracy: 0.0417 - val_loss: 4.0253 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3831 - accuracy: 0.0417 - val_loss: 4.5022 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.3344 - accuracy: 0.0417 - val_loss: 4.6694 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2892 - accuracy: 0.0000e+00 - val_loss: 4.8083 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2782 - accuracy: 0.0000e+00 - val_loss: 5.0362 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2611 - accuracy: 0.0417 - val_loss: 5.2778 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2418 - accuracy: 0.0000e+00 - val_loss: 5.4825 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2444 - accuracy: 0.0000e+00 - val_loss: 5.6418 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2404 - accuracy: 0.0417 - val_loss: 5.8173 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2328 - accuracy: 0.0417 - val_loss: 5.9571 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2247 - accuracy: 0.0000e+00 - val_loss: 6.0714 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2275 - accuracy: 0.0000e+00 - val_loss: 6.2038 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2200 - accuracy: 0.0000e+00 - val_loss: 6.3037 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2132 - accuracy: 0.0417 - val_loss: 6.4158 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2137 - accuracy: 0.0417 - val_loss: 6.5224 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2129 - accuracy: 0.0417 - val_loss: 6.5834 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2109 - accuracy: 0.0417 - val_loss: 6.6439 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2074 - accuracy: 0.0417 - val_loss: 6.7103 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2110 - accuracy: 0.0000e+00 - val_loss: 6.7554 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2067 - accuracy: 0.0417 - val_loss: 6.8438 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2010 - accuracy: 0.0000e+00 - val_loss: 6.9206 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2014 - accuracy: 0.0417 - val_loss: 6.9927 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2016 - accuracy: 0.0417 - val_loss: 7.0678 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2024 - accuracy: 0.0000e+00 - val_loss: 7.1053 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1999 - accuracy: 0.0417 - val_loss: 7.1702 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2016 - accuracy: 0.0417 - val_loss: 7.2047 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1996 - accuracy: 0.0417 - val_loss: 7.2659 - val_accuracy: 0.0000e+00\n","processing data batch 145\n","Epoch 1/30\n","6/6 [==============================] - 3s 127ms/step - loss: 3.4405 - accuracy: 0.0000e+00 - val_loss: 3.4480 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4359 - accuracy: 0.0000e+00 - val_loss: 3.4494 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.4309 - accuracy: 0.0000e+00 - val_loss: 3.4624 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.4242 - accuracy: 0.0417 - val_loss: 3.5023 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.4081 - accuracy: 0.0833 - val_loss: 3.6318 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3701 - accuracy: 0.0833 - val_loss: 3.9614 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3305 - accuracy: 0.0417 - val_loss: 4.2784 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2759 - accuracy: 0.0417 - val_loss: 4.4789 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2325 - accuracy: 0.0417 - val_loss: 4.7524 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2197 - accuracy: 0.0417 - val_loss: 4.9855 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1579 - accuracy: 0.0833 - val_loss: 5.1100 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1452 - accuracy: 0.0833 - val_loss: 5.3077 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1217 - accuracy: 0.0833 - val_loss: 5.4944 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1057 - accuracy: 0.0833 - val_loss: 5.7413 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0925 - accuracy: 0.0833 - val_loss: 5.9406 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0790 - accuracy: 0.0833 - val_loss: 6.0604 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0649 - accuracy: 0.0417 - val_loss: 6.2449 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0647 - accuracy: 0.0417 - val_loss: 6.3668 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0544 - accuracy: 0.0833 - val_loss: 6.4533 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0571 - accuracy: 0.0417 - val_loss: 6.5478 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0552 - accuracy: 0.0833 - val_loss: 6.6536 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0450 - accuracy: 0.0833 - val_loss: 6.7278 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0453 - accuracy: 0.0833 - val_loss: 6.8206 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0430 - accuracy: 0.0833 - val_loss: 6.8872 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0431 - accuracy: 0.0833 - val_loss: 7.0229 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0416 - accuracy: 0.0417 - val_loss: 7.0393 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0370 - accuracy: 0.0833 - val_loss: 7.1022 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0428 - accuracy: 0.0417 - val_loss: 7.1668 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0335 - accuracy: 0.0833 - val_loss: 7.2209 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0373 - accuracy: 0.0833 - val_loss: 7.2955 - val_accuracy: 0.0000e+00\n","processing data batch 146\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.4278 - accuracy: 0.0000e+00 - val_loss: 3.4844 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3644 - accuracy: 0.0833 - val_loss: 3.5383 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.3153 - accuracy: 0.0833 - val_loss: 3.5819 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 26ms/step - loss: 3.2769 - accuracy: 0.1250 - val_loss: 3.6399 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2205 - accuracy: 0.1250 - val_loss: 3.6884 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1879 - accuracy: 0.1250 - val_loss: 3.7477 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 26ms/step - loss: 3.1375 - accuracy: 0.1250 - val_loss: 3.8123 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0993 - accuracy: 0.1667 - val_loss: 3.8897 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0467 - accuracy: 0.1667 - val_loss: 3.9648 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9909 - accuracy: 0.1250 - val_loss: 4.0376 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9276 - accuracy: 0.1667 - val_loss: 4.1012 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8634 - accuracy: 0.2083 - val_loss: 4.1593 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8640 - accuracy: 0.1667 - val_loss: 4.1742 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8138 - accuracy: 0.1667 - val_loss: 4.2032 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7896 - accuracy: 0.1667 - val_loss: 4.2315 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7648 - accuracy: 0.2083 - val_loss: 4.2730 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7347 - accuracy: 0.2083 - val_loss: 4.3235 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7098 - accuracy: 0.1667 - val_loss: 4.3738 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6913 - accuracy: 0.1667 - val_loss: 4.4203 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6720 - accuracy: 0.2083 - val_loss: 4.4610 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6506 - accuracy: 0.2083 - val_loss: 4.5594 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6374 - accuracy: 0.1667 - val_loss: 4.6173 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6264 - accuracy: 0.1667 - val_loss: 4.6652 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6137 - accuracy: 0.1667 - val_loss: 4.7077 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6050 - accuracy: 0.1667 - val_loss: 4.7613 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5913 - accuracy: 0.1667 - val_loss: 4.8222 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5846 - accuracy: 0.1667 - val_loss: 4.8726 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5730 - accuracy: 0.1250 - val_loss: 4.9128 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5605 - accuracy: 0.1667 - val_loss: 4.9606 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5418 - accuracy: 0.1667 - val_loss: 4.9943 - val_accuracy: 0.0000e+00\n","processing data batch 147\n","Epoch 1/30\n","6/6 [==============================] - 2s 125ms/step - loss: 3.4629 - accuracy: 0.0417 - val_loss: 3.4726 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3370 - accuracy: 0.0417 - val_loss: 3.5210 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2850 - accuracy: 0.0417 - val_loss: 3.6223 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2060 - accuracy: 0.0833 - val_loss: 3.7515 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1308 - accuracy: 0.1250 - val_loss: 3.9309 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0386 - accuracy: 0.1250 - val_loss: 4.1096 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9629 - accuracy: 0.0833 - val_loss: 4.3018 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8924 - accuracy: 0.1250 - val_loss: 4.4633 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8463 - accuracy: 0.1250 - val_loss: 4.6107 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8132 - accuracy: 0.0833 - val_loss: 4.7064 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7739 - accuracy: 0.1250 - val_loss: 4.8370 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7447 - accuracy: 0.0833 - val_loss: 4.9420 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7227 - accuracy: 0.0833 - val_loss: 5.0257 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6996 - accuracy: 0.1250 - val_loss: 5.1615 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6902 - accuracy: 0.1667 - val_loss: 5.2594 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6504 - accuracy: 0.1667 - val_loss: 5.3377 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6307 - accuracy: 0.2083 - val_loss: 5.3948 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.6044 - accuracy: 0.2083 - val_loss: 5.4692 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5765 - accuracy: 0.2083 - val_loss: 5.6379 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5662 - accuracy: 0.2083 - val_loss: 5.4633 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5775 - accuracy: 0.1250 - val_loss: 5.3179 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5727 - accuracy: 0.2083 - val_loss: 5.4549 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5243 - accuracy: 0.2083 - val_loss: 5.4194 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4902 - accuracy: 0.2500 - val_loss: 5.6007 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4611 - accuracy: 0.2083 - val_loss: 5.7962 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4847 - accuracy: 0.2500 - val_loss: 6.0377 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4436 - accuracy: 0.2083 - val_loss: 5.8702 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4310 - accuracy: 0.2500 - val_loss: 6.0929 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4385 - accuracy: 0.2083 - val_loss: 6.2365 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4263 - accuracy: 0.2500 - val_loss: 6.2121 - val_accuracy: 0.0000e+00\n","processing data batch 148\n","Epoch 1/30\n","6/6 [==============================] - 2s 121ms/step - loss: 3.5851 - accuracy: 0.0000e+00 - val_loss: 3.5632 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3727 - accuracy: 0.0417 - val_loss: 3.5783 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3043 - accuracy: 0.0833 - val_loss: 3.5920 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2517 - accuracy: 0.0833 - val_loss: 3.6079 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1727 - accuracy: 0.0833 - val_loss: 3.6255 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1187 - accuracy: 0.0833 - val_loss: 3.6457 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0719 - accuracy: 0.0833 - val_loss: 3.6690 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0180 - accuracy: 0.1667 - val_loss: 3.6596 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9608 - accuracy: 0.1667 - val_loss: 3.7268 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8029 - accuracy: 0.1667 - val_loss: 3.9957 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.6436 - accuracy: 0.2083 - val_loss: 4.3283 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5531 - accuracy: 0.2500 - val_loss: 4.6703 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4735 - accuracy: 0.2083 - val_loss: 4.9427 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3645 - accuracy: 0.2917 - val_loss: 5.0900 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3139 - accuracy: 0.2500 - val_loss: 5.4062 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2561 - accuracy: 0.3750 - val_loss: 5.5881 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1667 - accuracy: 0.3750 - val_loss: 5.7465 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1455 - accuracy: 0.3750 - val_loss: 5.8600 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0581 - accuracy: 0.3750 - val_loss: 5.9766 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9704 - accuracy: 0.4167 - val_loss: 6.0800 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9035 - accuracy: 0.4167 - val_loss: 6.2104 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.8055 - accuracy: 0.4167 - val_loss: 6.3141 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.7794 - accuracy: 0.4583 - val_loss: 6.4396 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7205 - accuracy: 0.5000 - val_loss: 6.4859 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7175 - accuracy: 0.5000 - val_loss: 6.5782 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6403 - accuracy: 0.5000 - val_loss: 6.6394 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6090 - accuracy: 0.5000 - val_loss: 6.6583 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5876 - accuracy: 0.5000 - val_loss: 6.7682 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5692 - accuracy: 0.4583 - val_loss: 6.8300 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5512 - accuracy: 0.5000 - val_loss: 6.9643 - val_accuracy: 0.0000e+00\n","processing data batch 149\n","Epoch 1/30\n","6/6 [==============================] - 3s 253ms/step - loss: 3.5139 - accuracy: 0.0000e+00 - val_loss: 3.4399 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.2811 - accuracy: 0.0417 - val_loss: 3.4475 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.1952 - accuracy: 0.0833 - val_loss: 3.4556 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1034 - accuracy: 0.1250 - val_loss: 3.4740 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9931 - accuracy: 0.2917 - val_loss: 3.5356 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.7764 - accuracy: 0.3750 - val_loss: 3.7236 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5484 - accuracy: 0.4167 - val_loss: 4.0135 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3190 - accuracy: 0.4167 - val_loss: 4.2876 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1226 - accuracy: 0.5000 - val_loss: 4.5849 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.9625 - accuracy: 0.4583 - val_loss: 4.8397 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.8494 - accuracy: 0.4583 - val_loss: 5.1268 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.7555 - accuracy: 0.4583 - val_loss: 5.2786 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.6838 - accuracy: 0.5000 - val_loss: 5.4222 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6412 - accuracy: 0.4583 - val_loss: 5.3860 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.6038 - accuracy: 0.4583 - val_loss: 5.1696 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.5653 - accuracy: 0.4583 - val_loss: 5.2472 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5379 - accuracy: 0.5000 - val_loss: 5.1956 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5280 - accuracy: 0.5000 - val_loss: 5.1052 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5137 - accuracy: 0.5000 - val_loss: 5.0511 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4969 - accuracy: 0.5000 - val_loss: 5.5003 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4836 - accuracy: 0.4583 - val_loss: 5.4083 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4995 - accuracy: 0.4583 - val_loss: 5.2739 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.4859 - accuracy: 0.5000 - val_loss: 5.2999 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.5031 - accuracy: 0.5000 - val_loss: 5.3418 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4967 - accuracy: 0.4583 - val_loss: 5.4277 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 29ms/step - loss: 1.4720 - accuracy: 0.5000 - val_loss: 5.5778 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4721 - accuracy: 0.5000 - val_loss: 5.4791 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4631 - accuracy: 0.5000 - val_loss: 5.4124 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4632 - accuracy: 0.5000 - val_loss: 5.4072 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4487 - accuracy: 0.4583 - val_loss: 5.4195 - val_accuracy: 0.0000e+00\n","processing data batch 150\n","Epoch 1/30\n","6/6 [==============================] - 2s 128ms/step - loss: 3.4850 - accuracy: 0.0000e+00 - val_loss: 3.4536 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3723 - accuracy: 0.0417 - val_loss: 3.4905 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3330 - accuracy: 0.0833 - val_loss: 3.6519 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2621 - accuracy: 0.0833 - val_loss: 3.9569 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1830 - accuracy: 0.0833 - val_loss: 4.3635 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1382 - accuracy: 0.0833 - val_loss: 4.6074 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0847 - accuracy: 0.0833 - val_loss: 4.8217 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0331 - accuracy: 0.0417 - val_loss: 4.9987 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9682 - accuracy: 0.1250 - val_loss: 5.2843 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9190 - accuracy: 0.1667 - val_loss: 5.4732 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8720 - accuracy: 0.1667 - val_loss: 5.6055 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7948 - accuracy: 0.1667 - val_loss: 5.8013 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7204 - accuracy: 0.2083 - val_loss: 6.0022 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6612 - accuracy: 0.2083 - val_loss: 6.2891 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5853 - accuracy: 0.2083 - val_loss: 6.5538 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5197 - accuracy: 0.2500 - val_loss: 6.7846 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4524 - accuracy: 0.2083 - val_loss: 7.0014 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4506 - accuracy: 0.2500 - val_loss: 7.2005 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4114 - accuracy: 0.2083 - val_loss: 7.2980 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3672 - accuracy: 0.2083 - val_loss: 7.3495 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3254 - accuracy: 0.3333 - val_loss: 7.3799 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2998 - accuracy: 0.2917 - val_loss: 7.4894 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2796 - accuracy: 0.2500 - val_loss: 7.5907 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2593 - accuracy: 0.2500 - val_loss: 7.6821 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3563 - accuracy: 0.2083 - val_loss: 7.7265 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3645 - accuracy: 0.2500 - val_loss: 7.6742 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3548 - accuracy: 0.2083 - val_loss: 7.7805 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3035 - accuracy: 0.2917 - val_loss: 7.7828 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2491 - accuracy: 0.2917 - val_loss: 7.6828 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2721 - accuracy: 0.2500 - val_loss: 7.7569 - val_accuracy: 0.0000e+00\n","processing data batch 151\n","Epoch 1/30\n","6/6 [==============================] - 2s 126ms/step - loss: 3.4523 - accuracy: 0.0000e+00 - val_loss: 3.6901 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4322 - accuracy: 0.0000e+00 - val_loss: 3.7167 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.4301 - accuracy: 0.0417 - val_loss: 3.6158 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.4274 - accuracy: 0.0833 - val_loss: 3.6086 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.4511 - accuracy: 0.0417 - val_loss: 3.8728 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.4113 - accuracy: 0.0417 - val_loss: 3.8790 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3802 - accuracy: 0.0417 - val_loss: 4.0016 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3657 - accuracy: 0.0417 - val_loss: 4.2538 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2891 - accuracy: 0.0000e+00 - val_loss: 4.4596 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1598 - accuracy: 0.0833 - val_loss: 4.5460 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0309 - accuracy: 0.1250 - val_loss: 4.5675 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8822 - accuracy: 0.0833 - val_loss: 4.8391 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8577 - accuracy: 0.1250 - val_loss: 5.2872 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7501 - accuracy: 0.1250 - val_loss: 5.4517 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2494 - accuracy: 0.0833 - val_loss: 5.6849 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.5314 - accuracy: 0.0833 - val_loss: 5.5717 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3474 - accuracy: 0.0000e+00 - val_loss: 5.6360 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1289 - accuracy: 0.0417 - val_loss: 5.7945 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9326 - accuracy: 0.0417 - val_loss: 5.8124 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7997 - accuracy: 0.0833 - val_loss: 5.8620 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7307 - accuracy: 0.1250 - val_loss: 6.0074 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6888 - accuracy: 0.0833 - val_loss: 6.0240 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6479 - accuracy: 0.1250 - val_loss: 6.1769 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6102 - accuracy: 0.1250 - val_loss: 6.3020 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6276 - accuracy: 0.1250 - val_loss: 6.3226 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5799 - accuracy: 0.1667 - val_loss: 6.4062 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5769 - accuracy: 0.1667 - val_loss: 6.0658 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5626 - accuracy: 0.0417 - val_loss: 6.1881 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5922 - accuracy: 0.1250 - val_loss: 6.2476 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5123 - accuracy: 0.1250 - val_loss: 6.3555 - val_accuracy: 0.0000e+00\n","processing data batch 152\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.4215 - accuracy: 0.0000e+00 - val_loss: 3.5814 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3037 - accuracy: 0.0417 - val_loss: 3.6118 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2780 - accuracy: 0.0833 - val_loss: 3.6358 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 26ms/step - loss: 3.2513 - accuracy: 0.1250 - val_loss: 3.6554 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 26ms/step - loss: 3.2033 - accuracy: 0.0833 - val_loss: 3.6761 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 26ms/step - loss: 3.1308 - accuracy: 0.0833 - val_loss: 3.6951 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0500 - accuracy: 0.1250 - val_loss: 3.6913 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9508 - accuracy: 0.1250 - val_loss: 3.6708 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8496 - accuracy: 0.1250 - val_loss: 3.6497 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7552 - accuracy: 0.1667 - val_loss: 3.6405 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.6676 - accuracy: 0.1667 - val_loss: 3.6494 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5959 - accuracy: 0.1250 - val_loss: 3.6677 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5046 - accuracy: 0.2500 - val_loss: 3.7053 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4493 - accuracy: 0.1667 - val_loss: 3.7415 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.3688 - accuracy: 0.2500 - val_loss: 3.7878 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3184 - accuracy: 0.2500 - val_loss: 3.8460 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2561 - accuracy: 0.2500 - val_loss: 3.9220 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2082 - accuracy: 0.2500 - val_loss: 3.9929 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1660 - accuracy: 0.2917 - val_loss: 4.0669 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1210 - accuracy: 0.3750 - val_loss: 4.1439 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0886 - accuracy: 0.3333 - val_loss: 4.2171 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0875 - accuracy: 0.2917 - val_loss: 4.2941 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0895 - accuracy: 0.2917 - val_loss: 4.3828 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1357 - accuracy: 0.2500 - val_loss: 4.4629 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1149 - accuracy: 0.2083 - val_loss: 4.5417 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.0595 - accuracy: 0.3333 - val_loss: 4.6434 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0067 - accuracy: 0.2500 - val_loss: 4.7103 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9953 - accuracy: 0.2917 - val_loss: 4.8116 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9583 - accuracy: 0.3750 - val_loss: 4.8988 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9251 - accuracy: 0.3750 - val_loss: 4.9764 - val_accuracy: 0.0000e+00\n","processing data batch 153\n","Epoch 1/30\n","6/6 [==============================] - 2s 124ms/step - loss: 3.6478 - accuracy: 0.0417 - val_loss: 3.9914 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.4243 - accuracy: 0.0417 - val_loss: 4.0033 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.3402 - accuracy: 0.0833 - val_loss: 4.1373 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2168 - accuracy: 0.0833 - val_loss: 4.2758 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0770 - accuracy: 0.0833 - val_loss: 4.3568 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9917 - accuracy: 0.0833 - val_loss: 4.3783 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9076 - accuracy: 0.0833 - val_loss: 4.3721 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8193 - accuracy: 0.1250 - val_loss: 4.3348 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7542 - accuracy: 0.1667 - val_loss: 4.4151 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6951 - accuracy: 0.1250 - val_loss: 4.4935 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6415 - accuracy: 0.1667 - val_loss: 4.5139 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5841 - accuracy: 0.2083 - val_loss: 4.5091 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5198 - accuracy: 0.2917 - val_loss: 4.5906 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4679 - accuracy: 0.3333 - val_loss: 4.6086 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4375 - accuracy: 0.3333 - val_loss: 4.5628 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3963 - accuracy: 0.2917 - val_loss: 4.6104 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3794 - accuracy: 0.3750 - val_loss: 4.6448 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3249 - accuracy: 0.3333 - val_loss: 4.7148 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2865 - accuracy: 0.3750 - val_loss: 4.7971 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2504 - accuracy: 0.3333 - val_loss: 4.8209 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2095 - accuracy: 0.3333 - val_loss: 4.8957 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1657 - accuracy: 0.3750 - val_loss: 4.7145 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1455 - accuracy: 0.3750 - val_loss: 4.8154 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0879 - accuracy: 0.3750 - val_loss: 5.0042 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0558 - accuracy: 0.3750 - val_loss: 5.0343 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0115 - accuracy: 0.3333 - val_loss: 5.1631 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9761 - accuracy: 0.3750 - val_loss: 5.0901 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9479 - accuracy: 0.3750 - val_loss: 5.2033 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9277 - accuracy: 0.3750 - val_loss: 5.0494 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.9762 - accuracy: 0.3750 - val_loss: 4.7150 - val_accuracy: 0.0000e+00\n","processing data batch 154\n","Epoch 1/30\n","6/6 [==============================] - 3s 138ms/step - loss: 3.5124 - accuracy: 0.0417 - val_loss: 3.9352 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 31ms/step - loss: 3.2720 - accuracy: 0.0833 - val_loss: 3.8889 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.2059 - accuracy: 0.0833 - val_loss: 3.9701 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.1370 - accuracy: 0.0833 - val_loss: 4.0466 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0482 - accuracy: 0.1667 - val_loss: 4.1255 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.9573 - accuracy: 0.1667 - val_loss: 4.3005 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.8557 - accuracy: 0.1250 - val_loss: 4.4736 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.7639 - accuracy: 0.2083 - val_loss: 4.6245 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.6788 - accuracy: 0.2083 - val_loss: 4.7730 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.6049 - accuracy: 0.1667 - val_loss: 4.8319 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.5608 - accuracy: 0.2083 - val_loss: 4.9642 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4917 - accuracy: 0.2917 - val_loss: 5.0592 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.4462 - accuracy: 0.2917 - val_loss: 5.1405 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 29ms/step - loss: 2.4027 - accuracy: 0.2917 - val_loss: 5.1064 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3790 - accuracy: 0.2917 - val_loss: 5.1192 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3434 - accuracy: 0.3333 - val_loss: 5.2410 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3320 - accuracy: 0.2917 - val_loss: 5.2769 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3083 - accuracy: 0.2917 - val_loss: 5.3493 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2891 - accuracy: 0.3333 - val_loss: 5.3535 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2687 - accuracy: 0.2917 - val_loss: 5.4463 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2514 - accuracy: 0.2917 - val_loss: 5.6310 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2400 - accuracy: 0.3333 - val_loss: 5.7214 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2175 - accuracy: 0.2917 - val_loss: 5.8009 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2141 - accuracy: 0.2917 - val_loss: 5.8356 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2070 - accuracy: 0.2917 - val_loss: 5.8925 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1904 - accuracy: 0.3333 - val_loss: 5.9336 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1835 - accuracy: 0.2917 - val_loss: 6.0296 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1711 - accuracy: 0.2917 - val_loss: 6.0855 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1626 - accuracy: 0.2917 - val_loss: 6.0808 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1586 - accuracy: 0.2917 - val_loss: 6.0984 - val_accuracy: 0.0000e+00\n","processing data batch 155\n","Epoch 1/30\n","6/6 [==============================] - 3s 127ms/step - loss: 3.6456 - accuracy: 0.0417 - val_loss: 3.5127 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 30ms/step - loss: 3.3619 - accuracy: 0.0417 - val_loss: 3.5473 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.2632 - accuracy: 0.0417 - val_loss: 3.5381 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1702 - accuracy: 0.0833 - val_loss: 3.5601 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1052 - accuracy: 0.1250 - val_loss: 3.5979 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.0350 - accuracy: 0.1250 - val_loss: 3.6861 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.9501 - accuracy: 0.1250 - val_loss: 3.8120 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8995 - accuracy: 0.1250 - val_loss: 3.9425 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8440 - accuracy: 0.2083 - val_loss: 3.9895 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.7755 - accuracy: 0.2500 - val_loss: 4.0349 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6715 - accuracy: 0.2083 - val_loss: 4.6854 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5482 - accuracy: 0.2500 - val_loss: 5.4115 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4287 - accuracy: 0.2917 - val_loss: 5.7532 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3693 - accuracy: 0.2917 - val_loss: 5.9400 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.3213 - accuracy: 0.3333 - val_loss: 6.1589 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2952 - accuracy: 0.3333 - val_loss: 6.5046 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2560 - accuracy: 0.3333 - val_loss: 6.8075 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2458 - accuracy: 0.3333 - val_loss: 6.9023 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 30ms/step - loss: 2.2168 - accuracy: 0.3333 - val_loss: 6.9780 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 30ms/step - loss: 2.2072 - accuracy: 0.2917 - val_loss: 7.1087 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1917 - accuracy: 0.3333 - val_loss: 7.1409 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1789 - accuracy: 0.3333 - val_loss: 7.1196 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1741 - accuracy: 0.3333 - val_loss: 7.1205 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1643 - accuracy: 0.3750 - val_loss: 7.1592 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1578 - accuracy: 0.3333 - val_loss: 7.2022 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1447 - accuracy: 0.3750 - val_loss: 7.2611 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1418 - accuracy: 0.3750 - val_loss: 7.3380 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1329 - accuracy: 0.3750 - val_loss: 7.3940 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1289 - accuracy: 0.3750 - val_loss: 7.4484 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1263 - accuracy: 0.3750 - val_loss: 7.5065 - val_accuracy: 0.0000e+00\n","processing data batch 156\n","Epoch 1/30\n","6/6 [==============================] - 2s 123ms/step - loss: 3.5316 - accuracy: 0.0000e+00 - val_loss: 3.6177 - val_accuracy: 0.0000e+00\n","Epoch 2/30\n","6/6 [==============================] - 0s 29ms/step - loss: 3.2460 - accuracy: 0.0833 - val_loss: 3.6631 - val_accuracy: 0.0000e+00\n","Epoch 3/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1808 - accuracy: 0.1250 - val_loss: 3.6915 - val_accuracy: 0.0000e+00\n","Epoch 4/30\n","6/6 [==============================] - 0s 27ms/step - loss: 3.1137 - accuracy: 0.1250 - val_loss: 3.7607 - val_accuracy: 0.0000e+00\n","Epoch 5/30\n","6/6 [==============================] - 0s 28ms/step - loss: 3.0504 - accuracy: 0.1667 - val_loss: 3.8246 - val_accuracy: 0.0000e+00\n","Epoch 6/30\n","6/6 [==============================] - 0s 26ms/step - loss: 2.9728 - accuracy: 0.2083 - val_loss: 3.9091 - val_accuracy: 0.0000e+00\n","Epoch 7/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8997 - accuracy: 0.3333 - val_loss: 3.9748 - val_accuracy: 0.0000e+00\n","Epoch 8/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8311 - accuracy: 0.3333 - val_loss: 4.0224 - val_accuracy: 0.0000e+00\n","Epoch 9/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.7515 - accuracy: 0.3750 - val_loss: 4.1008 - val_accuracy: 0.0000e+00\n","Epoch 10/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.6810 - accuracy: 0.3750 - val_loss: 4.1765 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.5868 - accuracy: 0.3750 - val_loss: 4.2142 - val_accuracy: 0.0000e+00\n","Epoch 12/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.4854 - accuracy: 0.3333 - val_loss: 4.2785 - val_accuracy: 0.0000e+00\n","Epoch 13/30\n","6/6 [==============================] - 0s 28ms/step - loss: 2.3589 - accuracy: 0.4583 - val_loss: 4.3878 - val_accuracy: 0.0000e+00\n","Epoch 14/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2310 - accuracy: 0.5417 - val_loss: 4.4543 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0981 - accuracy: 0.6250 - val_loss: 4.5158 - val_accuracy: 0.0000e+00\n","Epoch 16/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.9549 - accuracy: 0.6250 - val_loss: 4.5791 - val_accuracy: 0.0000e+00\n","Epoch 17/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.8127 - accuracy: 0.6250 - val_loss: 4.6443 - val_accuracy: 0.0000e+00\n","Epoch 18/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.6905 - accuracy: 0.6667 - val_loss: 4.7557 - val_accuracy: 0.0000e+00\n","Epoch 19/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5648 - accuracy: 0.6250 - val_loss: 4.8709 - val_accuracy: 0.0000e+00\n","Epoch 20/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4591 - accuracy: 0.6667 - val_loss: 5.0158 - val_accuracy: 0.0000e+00\n","Epoch 21/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.3522 - accuracy: 0.6667 - val_loss: 5.2226 - val_accuracy: 0.0000e+00\n","Epoch 22/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2554 - accuracy: 0.6667 - val_loss: 5.2918 - val_accuracy: 0.0000e+00\n","Epoch 23/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1878 - accuracy: 0.6667 - val_loss: 5.5882 - val_accuracy: 0.0000e+00\n","Epoch 24/30\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1168 - accuracy: 0.7083 - val_loss: 5.6829 - val_accuracy: 0.0000e+00\n","Epoch 25/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9905 - accuracy: 0.6667 - val_loss: 6.0566 - val_accuracy: 0.0000e+00\n","Epoch 26/30\n","6/6 [==============================] - 0s 27ms/step - loss: 1.1423 - accuracy: 0.6250 - val_loss: 6.0994 - val_accuracy: 0.0000e+00\n","Epoch 27/30\n","6/6 [==============================] - 0s 28ms/step - loss: 0.8918 - accuracy: 0.7500 - val_loss: 5.9236 - val_accuracy: 0.0000e+00\n","Epoch 28/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8471 - accuracy: 0.6667 - val_loss: 6.0730 - val_accuracy: 0.0000e+00\n","Epoch 29/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.8382 - accuracy: 0.7083 - val_loss: 6.2013 - val_accuracy: 0.0000e+00\n","Epoch 30/30\n","6/6 [==============================] - 0s 27ms/step - loss: 0.9145 - accuracy: 0.6667 - val_loss: 6.0601 - val_accuracy: 0.0000e+00\n"]}],"source":["# using a for loop to train all models would very likely\n","# cause not enough memory error due to the size of data\n","# and complexity of model\n","# when necessary, manually inputting data batch might be required\n","\n","# uncomment this part to use for loop training\n","num_batch = 157\n","\n","curr_progress = len([f for f in os.listdir('/content/drive/My Drive/test_models2/') \n","if f.endswith('.h5') and os.path.isfile(os.path.join('/content/drive/My Drive/test_models2/', f))])\n","\n","for i in range(curr_progress, num_batch):\n","    model = training(root_dir, i)\n","    # save model\n","    model.save('/content/drive/My Drive/test_models2/model_' + str(i) + '.h5')\n","\n","# uncomment this part to use manual input training\n","# model = training(root_dir, 0)\n","# # save model\n","# model.save('/content/drive/My Drive/models/model_' + str(0) + '.h5')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7aIsjIeBvVkd","executionInfo":{"status":"ok","timestamp":1685082336745,"user_tz":-600,"elapsed":16,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Reshape\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","def prepare_test_data(data_path, behaviour_num):\n","    x_data, y_data = get_training_data(data_path)\n","\n","    # Reshape each 3D array in x_data to a 2D array of shape (num_frames, img_height * img_width)\n","    x_data_2d = [x.reshape(x.shape[0], -1) for x in x_data]\n","\n","    # Normalize x_data_2d to the range [0, 1]\n","    scaler = MinMaxScaler()\n","    x_data_norm_2d = [scaler.fit_transform(x) for x in x_data_2d]\n","\n","    # Reshape each 2D array back to a 3D array of shape (num_frames, img_height, img_width)\n","    x_data = [x.reshape(x.shape[0], 64, 64) for x in x_data_norm_2d]\n","\n","    # find the maximum length of frames arrays\n","    max_length = max(len(frames) for frames in x_data)\n","\n","    # restrict the shape of x_data to become a 10 second video data of 24 fps\n","    if max_length > 240:\n","        x_data = x_data[:240]\n","\n","    # pad the frames arrays with zeros to 240 if less than 240\n","    x_padded = pad_sequences(x_data, maxlen=240, dtype='float32', padding='post', truncating='post')\n","\n","    # y_data squeeze\n","    y_data = [labels[0] for labels in y_data]\n","\n","    # reshape x_padded to have the correct shape for model input\n","    x_reshaped = np.reshape(x_padded, (len(x_data), 240, 64, 64, 1))\n","\n","    # transform into np array\n","    x_test = np.array(x_reshaped)\n","    y_test = np.array(y_data)\n","\n","    y_test = to_categorical(y_test, num_classes=31)\n","\n","    x_test = x_test[behaviour_num]\n","    y_test = y_test[behaviour_num]\n","\n","    return x_test, y_test"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"JES5ipYZ05F0","executionInfo":{"status":"ok","timestamp":1685082336746,"user_tz":-600,"elapsed":12,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["behaviours = {'book': 0,\n","            'cell_phone': 1,\n","            'drink_water': 2,\n","            'speaking': 3,\n","            'stand_up': 4,\n","            'sit_down': 5,\n","            'face_up': 6,\n","            'face_down': 7,\n","            'face_left': 8,\n","            'face_right': 9,\n","            'face_upper_left': 10,\n","            'face_upper_right': 11,\n","            'face_lower_left': 12,\n","            'face_lower_right': 13,\n","            'hands_up': 14,\n","            'look_up': 15,\n","            'look_down': 16,\n","            'look_left': 17,\n","            'look_right': 18,\n","            'look_upper_left': 19,\n","            'look_upper_right': 20,\n","            'look_lower_left': 21,\n","            'look_lower_right': 22,\n","            'makefau1': 23,\n","            'makefau4': 24,\n","            'makefau5': 25,\n","            'makefau7': 26,\n","            'makefau9': 27,\n","            'makefau17': 28,\n","            'makefau23': 29,\n","            'makefau28': 30}\n","\n","def get_key_by_value(dictionary, value):\n","    for key, val in dictionary.items():\n","        if val == value:\n","            return key\n","    return None  # Value not found in the dictionary      "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ZHrsqSGKEBf0","executionInfo":{"status":"ok","timestamp":1685082336746,"user_tz":-600,"elapsed":12,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["import random\n","\n","def generate_random_batches(exclude_value, num_values, maximum_value):\n","\n","    all_values = list(range(0, maximum_value))\n","    all_values.remove(exclude_value)\n","    random_values = random.sample(all_values, num_values)\n","\n","    return random_values"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TUrmiF0law3x","executionInfo":{"status":"ok","timestamp":1685082336746,"user_tz":-600,"elapsed":12,"user":{"displayName":"凌豪","userId":"01537499298288856098"}}},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","\n","def evaluate_model(model_num, total_model_num):\n","    # list to store all evaluation accuracies:\n","    overall_accuracy = []\n","\n","    # Load the saved model\n","    model = load_model('/content/drive/My Drive/test_models2/model_' + str(model_num) + '.h5')\n","\n","    # randomly select 20 datasets\n","    random_model_batch = generate_random_batches(model_num, 20, total_model_num)\n","\n","    for curr_model_num in random_model_batch:\n","        # test on all models except for the one it trained on\n","        if not curr_model_num == model_num:\n","            print(\"Evaluating model {} with dataset from model {}\".format(model_num, curr_model_num))\n","\n","            curr_accuracy = 0\n","            # 31 labels\n","            for behaviour_label_num in range(31):\n","                behaviour_name = get_key_by_value(behaviours, behaviour_label_num)\n","                print(\"Evaluating behaviour <{}>\".format(behaviour_name))\n","\n","                x_test, y_test = prepare_test_data(root_dir + str(curr_model_num) + '/', behaviour_label_num)\n","    \n","                # Reshape x_test to match the input shape of the trained model\n","                x_test_reshaped = np.expand_dims(x_test, axis=0)  # Add an extra dimension for the num_classes dimension\n","\n","                # Reshape y_test to match the expected shape of the labels\n","                y_test_reshaped = np.expand_dims(y_test, axis=0)  # Add an extra dimension for the num_classes dimension\n","\n","                # Evaluate the model on the test data\n","                loss, accuracy = model.evaluate(x_test_reshaped, y_test_reshaped)\n","                \n","                # add the accuracy (which is either 0 or 1)\n","                curr_accuracy += accuracy\n","\n","            # get percentage accuracy of current model on all labels\n","            curr_accuracy = curr_accuracy / 31\n","\n","            # store in list\n","            overall_accuracy.append(curr_accuracy)\n","\n","    # get the averaged evaluation on sampled models\n","    overall_accuracy = np.sum(overall_accuracy) / 20\n","\n","    return overall_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjEfTdpxe5mR","executionInfo":{"status":"ok","timestamp":1684709306752,"user_tz":-600,"elapsed":2454793,"user":{"displayName":"凌豪","userId":"01537499298288856098"}},"outputId":"cf63d74d-920b-483b-e05a-a5211868f265"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.2867 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7621 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6739 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2237 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.3000 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.5319 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.1004 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.3187 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 32\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.3290 - accuracy: 1.0000\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0746 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.9482 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.4202 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.7373 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.1111 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.6901 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.0162 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6209 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 4.5646 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 43\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.5330 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.9433 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8357 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1637 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8636 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.8091 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.7765 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2463 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.1354 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9499 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7936 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.1809 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6455 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5226 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.9513 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0264 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.6245 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.8233 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.1323 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 17\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6853 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2177 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7818 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.9880 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5371 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.0437 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7503 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.9538 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.0936 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.1163 - accuracy: 1.0000\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.4321 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6533 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6268 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.5282 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.9021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.5326 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6176 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.8001 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.4442 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 130\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.3274 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.3129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.3874 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.8497 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.0896 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.5341 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.5489 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 132\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.5443 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 42ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.4626 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6764 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5139 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.3970 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.5075 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7054 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8497 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5087 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.6547 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.0879 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.4719 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8385 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.0448 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 41ms/step - loss: 4.6249 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 148\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 0.8729 - accuracy: 1.0000\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.2239 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.5400 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2651 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3857 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0744 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.4867 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.0517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 1.8626 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4949 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.3904 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.7423 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.7804 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 78\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 36ms/step - loss: 0.9727 - accuracy: 1.0000\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 41ms/step - loss: 2.2696 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.0682 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1132 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.5914 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 1.7632 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1766 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2581 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.7066 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9532 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.4233 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.3868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 72\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 41ms/step - loss: 2.7054 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.8497 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 44ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 103\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.0193 - accuracy: 1.0000\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.2205 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.9692 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.6944 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.1821 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.7974 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2718 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.2562 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 4.3384 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.0517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.8704 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9265 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 133\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7583 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7534 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.4076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8497 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.6985 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.9795 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0579 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4459 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.1462 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0393 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0013 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3498 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.7042 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 113\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6854 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.0698 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.1769 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.7191 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.5126 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.4276 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4701 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.4477 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.1805 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.4093 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.2050 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6413 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.8787 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.7098 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6876 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6084 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.6250 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8608 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6448 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2218 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0719 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 48\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.1620 - accuracy: 1.0000\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.1996 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7001 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8890 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.4870 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8052 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3584 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2092 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.2725 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.4877 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.3589 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0929 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.4842 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.8786 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 42ms/step - loss: 2.6245 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.9082 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.6197 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4755 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6920 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.1887 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3401 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6557 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.9056 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.0668 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 41\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8847 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.9687 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2427 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0744 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4365 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2596 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7054 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.4076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8497 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2842 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6712 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8923 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.2844 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0049 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.4666 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.7679 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 121\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.5645 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9299 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6355 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8988 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.0203 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6569 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.5768 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.8532 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.2645 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.0950 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0041 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8658 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.7823 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.5060 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.2205 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.4940 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 93\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 31ms/step - loss: 2.6854 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3411 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6824 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 4.3531 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 42ms/step - loss: 2.7054 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.4077 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.8490 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7319 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6863 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.9104 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.2313 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.5665 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.9414 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.8824 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4325 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.5388 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 95\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7972 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.0267 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6152 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.8234 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8873 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3961 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.1163 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 40ms/step - loss: 3.3695 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 43ms/step - loss: 2.1423 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.1730 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0132 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.2053 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.0619 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2798 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7697 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0294 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0682 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.5451 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6672 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7865 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7573 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.5405 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 108\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.4426 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8242 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7562 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8573 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.9338 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.7785 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.4697 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7867 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.8668 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.0275 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.1168 - accuracy: 1.0000\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 3.1361 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.0517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7997 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8330 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.0370 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7533 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0634 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.1188 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.9552 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.1711 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0623 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7699 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9206 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 137\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0295 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.0658 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4030 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.1923 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2018 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8497 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4266 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0507 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1783 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6592 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.4878 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.0585 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.1269 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.9422 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2177 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1787 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3699 - accuracy: 0.0000e+00\n","Evaluating model 153 with dataset from model 135\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.2709 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5891 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.4082 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 43ms/step - loss: 2.6862 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.3372 - accuracy: 1.0000\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.1158 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4692 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5516 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3334 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.7957 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.4393 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8405 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.1703 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2829 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.6322 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6566 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0866 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4342 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.5438 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0965 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.7052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7696 - accuracy: 0.0000e+00\n","Model 153's accuracy is 0.045161290322580636\n","Evaluating model 154\n","Evaluating model 154 with dataset from model 21\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 420ms/step - loss: 5.9152 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9936 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.3425 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2587 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7681 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2487 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2619 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0979 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.1728 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3550 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4425 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.1054 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.7965 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6915 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0220 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4709 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0026 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.9975 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.8215 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9917 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0974 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0839 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6133 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.2453 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0266 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.1984 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1946 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.5102 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9940 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 130\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8340 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4934 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7125 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9659 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.7681 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.5700 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 45ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.6423 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.4538 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8980 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8720 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7375 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8724 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8402 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6338 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7847 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 48ms/step - loss: 7.2453 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.0266 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.1984 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1946 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.5102 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9940 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 83\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4035 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9299 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2442 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6235 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8515 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.0409 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8860 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.5968 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 1.3878 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6042 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.0151 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4107 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.5602 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8811 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0754 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8235 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.0978 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8117 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8935 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5792 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7737 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3985 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0463 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8208 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 138\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.7570 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9435 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6477 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7938 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8470 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3087 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9138 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6414 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0172 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0318 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7574 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7379 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8801 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3447 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.8485 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 46ms/step - loss: 5.9554 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.1123 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.1712 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3123 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4489 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7160 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3399 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9982 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.9410 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 33\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8340 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8183 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6198 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7344 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.4810 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7589 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4409 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9078 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8977 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8718 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8809 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8726 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8616 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1602 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9437 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5292 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5047 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.7690 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4940 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 40ms/step - loss: 5.9494 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7905 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 2\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6580 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1292 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.1452 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.1822 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9650 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.2594 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8478 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7458 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 3.9888 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.4264 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8063 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9126 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.1154 - accuracy: 1.0000\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.8154 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0347 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4876 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7434 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.9232 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4525 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7617 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9938 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1980 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9531 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9822 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4777 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8176 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4883 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8398 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.2868 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 110\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8340 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.3091 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7682 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.0969 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2610 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.6041 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8064 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9472 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4413 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9075 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8980 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8720 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8568 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8724 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.8402 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7881 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0825 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.6123 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.2436 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0255 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 39ms/step - loss: 7.1978 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1945 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 39ms/step - loss: 7.5090 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9943 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 80\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8340 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6626 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.2289 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.6552 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4412 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9076 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8980 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8720 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6687 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8724 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.8402 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7881 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.0147 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5028 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6093 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5093 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8238 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.3098 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.1335 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.3842 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 143\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8340 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3211 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2264 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.3931 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.2569 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7588 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.8219 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4397 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9075 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8969 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8719 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0084 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8725 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8404 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7881 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0826 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 31ms/step - loss: 7.6121 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.2281 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0255 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.1978 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.2224 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.4503 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.0224 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 106\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8468 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.9834 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7826 - accuracy: 1.0000\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6591 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7952 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.6556 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.3321 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9064 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4296 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.6740 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.0212 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.4496 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 42ms/step - loss: 5.7901 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.8315 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.0239 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.3853 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.7441 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 43ms/step - loss: 5.6166 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.9583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.3802 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.4534 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.8428 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 17\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8340 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.6181 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.4203 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.3078 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.6269 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.5419 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 40ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.2617 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.0919 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.0963 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.7298 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 4.2636 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.1410 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3053 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.8725 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 37ms/step - loss: 1.2453 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 44ms/step - loss: 5.4121 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.2453 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.8637 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 40ms/step - loss: 5.7261 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 39ms/step - loss: 4.9521 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2061 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.6237 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 73\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8353 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8180 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 41ms/step - loss: 6.7125 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 41ms/step - loss: 3.0466 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.7681 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 46ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.6423 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4400 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9083 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.8970 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8711 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8811 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8728 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8411 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0839 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6133 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.2453 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.0266 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1984 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1946 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.5102 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9940 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 51\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.2993 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9403 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.6808 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.2032 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.2056 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1357 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8606 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0572 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1231 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3776 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.8877 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.9909 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4494 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4237 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2836 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.3782 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8858 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8615 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.0974 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.7130 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5716 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8061 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4730 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4492 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8912 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 5\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7134 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9877 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4404 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.3774 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1849 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.5898 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8478 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7239 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.8566 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0840 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9112 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2163 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9105 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.2197 - accuracy: 1.0000\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 0.7021 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0871 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0853 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.9166 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.1147 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.1341 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.5660 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 46ms/step - loss: 5.9880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2072 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8925 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9693 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7076 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.8087 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5724 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9953 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.0585 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 109\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1878 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.6680 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6993 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3545 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7461 - accuracy: 1.0000\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2623 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8103 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.3733 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5686 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3575 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.6956 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4850 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8378 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8798 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3124 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4914 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.1575 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0839 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.6133 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.2453 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0266 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1984 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1946 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.5102 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.9940 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 46\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6371 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6843 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.3826 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.3067 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5785 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.3913 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9837 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0837 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6093 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9383 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.1488 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 42ms/step - loss: 2.8299 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0323 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.5080 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 1.4004 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.1091 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6853 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6410 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.8953 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.2707 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8899 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3505 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6341 - accuracy: 1.0000\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.5385 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9872 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9151 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8078 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4644 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.6165 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.2212 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 29\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8341 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.1881 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1051 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.6857 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.6098 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.5725 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7488 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1299 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0680 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.4252 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4410 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9077 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8980 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8719 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8805 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8725 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8403 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7872 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.0826 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 42ms/step - loss: 7.6120 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.2436 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0255 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1978 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1944 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.5088 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9943 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 140\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6802 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1003 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.3772 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3941 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 41ms/step - loss: 6.0388 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.1282 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0163 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8138 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5626 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.5128 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2606 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.0106 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9309 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.5179 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2848 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5946 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8882 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8811 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.0425 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4277 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1252 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7212 - accuracy: 1.0000\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4388 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5177 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5405 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7434 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6298 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 41ms/step - loss: 6.0142 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5441 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 101\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3455 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8184 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.0075 - accuracy: 1.0000\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9648 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4571 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8469 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.8427 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 4.2625 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9137 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9123 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.1478 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.5185 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2057 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8980 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4313 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6538 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.3272 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1196 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5367 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6265 - accuracy: 1.0000\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3172 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8406 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5132 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0826 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.4030 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.7477 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9290 - accuracy: 0.0000e+00\n","Evaluating model 154 with dataset from model 136\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9288 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9186 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3212 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 1.2872 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6365 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.2386 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.8471 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0794 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2622 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3978 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.8865 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.9121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8062 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.0631 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.2665 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3730 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0246 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4724 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9563 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.8967 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1697 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9164 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7419 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9837 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.5398 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.3855 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.3780 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7938 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.2385 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.7407 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.2426 - accuracy: 0.0000e+00\n","Model 154's accuracy is 0.04032258064516129\n","Evaluating model 155\n","Evaluating model 155 with dataset from model 90\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 415ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.5384 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4254 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2770 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6112 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5130 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.3624 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5014 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5192 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9220 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 0.7747 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1709 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 1.9791 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.2524 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6811 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.5388 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5614 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5002 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6539 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.2146 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.7104 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.5687 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1670 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6561 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0993 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.1454 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 124\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.3053 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.2274 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4238 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6269 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6332 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7830 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0630 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.2797 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.6851 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4765 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5837 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.3549 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.1198 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9052 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3868 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.3445 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.7096 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.4939 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.8819 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.7933 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 8.2769 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.9805 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 18\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7002 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.8141 - accuracy: 1.0000\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4254 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9257 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.2207 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0024 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0606 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0712 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0306 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.2543 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6329 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9573 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.0552 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4687 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.1447 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2597 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7929 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9093 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7440 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0043 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.2563 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.8995 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 96\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.6041 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.8885 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4360 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8346 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0347 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9256 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8030 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4271 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.4736 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.6305 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4269 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.5647 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6478 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7605 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.1639 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9316 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.8311 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6329 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.9440 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.4432 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3031 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6404 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.0296 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6331 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.3124 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.8824 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.7080 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.9583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.8954 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 52\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7773 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8363 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4247 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7970 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.6441 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.0700 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.8752 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.9272 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9178 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.0753 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6386 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0043 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2622 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5612 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.4335 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5493 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4346 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0694 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7371 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.5513 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0861 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6379 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4964 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.6462 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1596 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 84\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.5884 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.3727 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.4349 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.7835 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.3680 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 41ms/step - loss: 6.2978 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8596 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 0.7523 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.0810 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6521 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.8337 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8657 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.9939 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.3171 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7021 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7247 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1049 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8058 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.5686 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.8583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6561 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0993 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1454 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 152\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5384 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.1392 - accuracy: 1.0000\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7575 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6332 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7601 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6396 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.8189 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6163 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0395 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2837 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3294 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.8147 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.4998 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3430 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.6181 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.9189 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.3006 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.0814 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5290 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6208 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7509 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.7104 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.5686 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6561 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0993 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1454 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 112\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6024 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.5385 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7092 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.2501 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1755 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6332 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.3222 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5465 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6004 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.2753 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7830 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7732 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4999 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.3431 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6436 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.9106 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3006 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0814 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.3770 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.6199 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.2849 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1444 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.7416 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 43ms/step - loss: 6.6520 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.6137 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.0953 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.9813 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 43\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5384 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4902 - accuracy: 1.0000\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6269 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1700 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6571 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7830 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3173 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0812 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 1.9435 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.9769 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 48ms/step - loss: 5.5311 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 41ms/step - loss: 3.5124 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 4.3414 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.3188 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5931 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1758 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7943 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3968 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8915 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6000 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.4150 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.7048 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 71\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5384 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4254 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2114 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4404 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 40ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.5336 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.5009 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4998 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3430 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6181 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6329 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3006 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0814 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5290 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.1111 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7104 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.5686 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6561 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0993 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.1454 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 60\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.5316 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.8897 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4254 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3828 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.7974 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 4.6489 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8718 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 41ms/step - loss: 0.7664 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.4998 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9661 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.7991 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0189 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3006 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.2517 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.5290 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6410 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.2694 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.7440 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.4935 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.9737 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.7938 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 32ms/step - loss: 8.3132 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 8.0438 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 35\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.4807 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.8368 - accuracy: 1.0000\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4250 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6269 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.4674 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7830 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7632 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.1626 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0616 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.0704 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 4.9686 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9521 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 3.4094 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3603 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.3713 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 42ms/step - loss: 6.4178 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.8538 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1715 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5165 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.9683 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.2857 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 61\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8041 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9540 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9457 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.2769 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0488 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 31ms/step - loss: 0.0868 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6344 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.9977 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.1892 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.6506 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.7111 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5829 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4282 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.5894 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 36ms/step - loss: 8.1872 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8301 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.4345 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 8.6811 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.5030 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 8.5887 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.1181 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 28\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.1214 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.4252 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6269 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2425 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 31ms/step - loss: 5.2673 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 42ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.7830 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 42ms/step - loss: 5.3664 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.5423 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.8279 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3729 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 44ms/step - loss: 2.1497 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.9635 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.5047 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.0048 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.1111 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.7104 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.5686 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.8583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6561 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.0993 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.1454 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 129\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.5384 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.4254 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.2812 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.6507 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.2375 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.8705 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.9140 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.5009 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.4998 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3430 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.6181 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.5763 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3006 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.0814 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.5290 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6880 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 40ms/step - loss: 7.1111 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.6342 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.3043 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 39ms/step - loss: 7.8840 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.5209 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 38ms/step - loss: 8.1850 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.6973 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 46\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 49ms/step - loss: 2.7397 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 38ms/step - loss: 1.7991 - accuracy: 1.0000\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 39ms/step - loss: 4.3391 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 38ms/step - loss: 4.2705 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.2277 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.2579 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7864 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4684 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.9961 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.2970 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.9743 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6845 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.5910 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.1100 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.9527 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0029 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.1368 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 3.0842 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.9165 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9896 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5429 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4188 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4241 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2260 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7585 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8498 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8797 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0194 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.4100 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.9091 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 37\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.5313 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.5384 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4254 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8738 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.6332 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6052 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6165 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0960 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5009 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4998 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3430 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6181 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6329 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3006 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 7.0814 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5290 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1568 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2859 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7983 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.3622 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8676 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0094 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4224 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.9128 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 108\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2177 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.2127 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4253 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.1648 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.8976 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6771 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6833 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0022 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.1066 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.2897 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 3.6692 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.8916 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6329 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.4434 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.3033 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.6720 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.7137 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 8.3372 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8747 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.4436 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 31ms/step - loss: 8.2487 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 8.0079 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 8.9289 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1999 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 49\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.2023 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7270 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9533 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0686 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.8019 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.6106 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6214 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.0102 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 0.1068 - accuracy: 1.0000\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5259 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.6694 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.0792 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6329 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7188 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4809 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0534 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2478 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7272 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5692 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3652 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8583 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0177 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.2763 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9092 - accuracy: 0.0000e+00\n","Evaluating model 155 with dataset from model 31\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.8895 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.2187 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.2809 - accuracy: 1.0000\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6260 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6332 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.7603 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.6380 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.5849 - accuracy: 1.0000\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.6046 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 45ms/step - loss: 2.6164 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.6844 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.6894 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.7830 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5009 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4998 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3430 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6181 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2436 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0749 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.9488 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6654 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.1655 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2128 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.7377 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3618 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8815 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.0209 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4419 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8994 - accuracy: 0.0000e+00\n","Model 155's accuracy is 0.053225806451612886\n","Evaluating model 156\n","Evaluating model 156 with dataset from model 111\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 449ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.1151 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3659 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3658 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0493 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.9780 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0357 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.8209 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6581 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3381 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.0886 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.7218 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.9442 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.7330 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.5931 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8108 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.5817 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4605 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8047 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8274 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1727 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 113\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.4331 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.3023 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.3634 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9872 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7560 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0025 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0130 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9776 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9130 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.6068 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.7145 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 39ms/step - loss: 7.6747 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.6870 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.2876 - accuracy: 1.0000\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.6546 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.0112 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.8551 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 3.0169 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.7000 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.5219 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1268 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.5293 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.2630 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6743 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.3642 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.9445 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.4680 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 60\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3372 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.1276 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.3193 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.6294 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 39ms/step - loss: 8.0060 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 41ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 41ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 3.7641 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.0705 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.8207 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.0578 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9492 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.8293 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.7218 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.4659 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.9532 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9870 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.5838 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1231 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 8.3483 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.2482 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1415 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 43ms/step - loss: 6.7539 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 140\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6312 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.5348 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.2593 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7515 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3724 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.6541 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6726 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1152 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7926 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1725 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7503 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 32ms/step - loss: 6.9485 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7852 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3904 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2999 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.5154 - accuracy: 1.0000\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4871 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.9590 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9177 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6500 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9145 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.3601 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3118 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4855 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3672 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.6527 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5917 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 32ms/step - loss: 5.7828 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.3950 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.9427 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 53\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1774 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1151 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9615 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 41ms/step - loss: 1.4688 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0463 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 42ms/step - loss: 0.7122 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0088 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.0156 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.4932 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9652 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0976 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9122 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9341 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.5989 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.8994 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0778 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.4489 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.8318 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.2128 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.2486 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.7306 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.7298 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.5905 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.2617 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.7670 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9556 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4726 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 39ms/step - loss: 7.8791 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.8829 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.3557 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0101 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 123\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1151 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8048 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.2849 - accuracy: 1.0000\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0492 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.3043 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1712 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0433 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.0725 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8413 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.8209 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6581 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3383 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.2131 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.7219 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.9447 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.0254 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.5102 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.6500 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9074 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7611 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6534 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8613 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.7330 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 27\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.0383 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.2816 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.5829 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3624 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0490 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0024 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0130 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6467 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.4983 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.8190 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.4709 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.7794 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.1113 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.7906 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6350 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 4.5030 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 3.0765 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.8367 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.6903 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9392 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.0393 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4174 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6649 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4200 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.5570 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6876 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 11\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.5427 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.0067 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6736 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.6982 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0277 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 4.9356 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4931 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.2974 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.4418 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.5731 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.9634 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.5343 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9354 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6067 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.7105 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.3272 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 1.4704 - accuracy: 1.0000\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 41ms/step - loss: 1.4948 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.6774 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 0.9121 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 3.6312 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.4788 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.7065 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.2920 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3460 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1645 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6049 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.6855 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7454 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.3107 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8460 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 72\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1151 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3656 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0488 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0024 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7656 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9119 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.8247 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1035 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.8207 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 4.6581 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.3383 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9175 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.7218 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.9447 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7433 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.6879 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2185 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.8619 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4580 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1925 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4736 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9706 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 155\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1294 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.6784 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 8.1211 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3657 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0293 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.0488 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8250 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.6180 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.9594 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.3171 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 3.9286 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9177 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 4.5910 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.2641 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.6796 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.7439 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0494 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1519 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.5345 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.4260 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.8989 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.2269 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.6691 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 134\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.0924 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.0315 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3579 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.1819 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0431 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 42ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.8108 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9729 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.5817 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3361 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 3.9001 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.2560 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.7077 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.5808 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.3750 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.6887 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1929 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9262 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.6299 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.9011 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.5727 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.2692 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6973 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 34\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4638 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8804 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.2010 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.4184 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.0438 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.4308 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0130 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0890 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9130 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9398 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.5240 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.5441 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.2649 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.7386 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.4500 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.6905 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 0.6137 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.8363 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.5265 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4466 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3031 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.0096 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.2824 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.2658 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.3140 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.6244 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.9788 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.1194 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 92\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.2947 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3636 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.3502 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.0491 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0131 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.2195 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 44ms/step - loss: 6.1764 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.3350 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 41ms/step - loss: 7.7278 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.7319 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.4603 - accuracy: 1.0000\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 3.1637 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.2035 - accuracy: 1.0000\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.5646 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.2716 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7435 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.6881 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2210 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8619 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4580 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1925 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4738 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.9707 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 33\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 33ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.1149 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 38ms/step - loss: 3.5214 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 4.0838 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.2042 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.0024 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 41ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 42ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 39ms/step - loss: 4.5059 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.1033 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.8208 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 4.6581 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.3382 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 40ms/step - loss: 5.9176 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.7218 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.9411 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.3845 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.0968 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.6197 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.5408 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 44ms/step - loss: 5.1306 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.9591 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 40ms/step - loss: 5.5040 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 40ms/step - loss: 5.7600 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 149\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.1157 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9615 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.2954 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 41ms/step - loss: 4.0171 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 3.9749 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 40ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 45ms/step - loss: 4.1210 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.1021 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 40ms/step - loss: 3.4087 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 47ms/step - loss: 3.3068 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 3.3234 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 44ms/step - loss: 3.0054 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 44ms/step - loss: 3.4226 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 44ms/step - loss: 2.4353 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 41ms/step - loss: 3.7285 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.7433 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.6879 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.7818 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 44ms/step - loss: 6.9245 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 38ms/step - loss: 6.3325 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.8073 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.9561 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.1034 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 125\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.3565 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 37ms/step - loss: 3.7112 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8154 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.1779 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1194 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.1234 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 43ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.8254 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 41ms/step - loss: 7.6412 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.4741 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.5457 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.4674 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.6954 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9795 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 41ms/step - loss: 4.2376 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 5.7387 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.7141 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.1471 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9827 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.6719 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.1154 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.2605 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.0792 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7881 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 104\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.4639 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1151 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.4622 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 37ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.0049 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.2449 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.5417 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9399 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.3854 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.1035 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8207 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 37ms/step - loss: 4.6581 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3383 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3483 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.7218 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9447 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.7357 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6853 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.2193 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.8627 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.4582 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1926 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.4696 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 40ms/step - loss: 6.9667 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 137\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4662 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1086 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.8079 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 34ms/step - loss: 3.3032 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0322 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.7121 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0029 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.0130 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.1150 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9769 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0969 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 36ms/step - loss: 4.2390 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4125 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8237 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 4.6565 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.3376 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.9176 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.7212 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.9357 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8511 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.3693 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.1205 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.7190 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.9228 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3972 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 36ms/step - loss: 7.8714 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.2488 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.1647 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 61\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4638 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 37ms/step - loss: 2.6866 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 38ms/step - loss: 7.9276 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 44ms/step - loss: 0.9091 - accuracy: 1.0000\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.0289 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 44ms/step - loss: 1.0696 - accuracy: 1.0000\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0129 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9777 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 38ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 1.9132 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 33ms/step - loss: 1.9400 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.6069 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.3133 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 7.4722 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9010 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.1395 - accuracy: 1.0000\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 3.4734 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 8.2994 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5713 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 36ms/step - loss: 2.3969 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 38ms/step - loss: 3.8416 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.2718 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.9303 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.8049 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.8734 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.2777 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 42ms/step - loss: 7.9646 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 41ms/step - loss: 5.8793 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 35ms/step - loss: 7.1852 - accuracy: 0.0000e+00\n","Evaluating model 156 with dataset from model 26\n","Evaluating behaviour <book>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.4638 - accuracy: 0.0000e+00\n","Evaluating behaviour <cell_phone>\n","1/1 [==============================] - 0s 34ms/step - loss: 6.1148 - accuracy: 0.0000e+00\n","Evaluating behaviour <drink_water>\n","1/1 [==============================] - 0s 36ms/step - loss: 1.9614 - accuracy: 0.0000e+00\n","Evaluating behaviour <speaking>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.0730 - accuracy: 0.0000e+00\n","Evaluating behaviour <stand_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.9090 - accuracy: 0.0000e+00\n","Evaluating behaviour <sit_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 6.0488 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_down>\n","1/1 [==============================] - 0s 33ms/step - loss: 2.0138 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 2.1153 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_right>\n","1/1 [==============================] - 0s 39ms/step - loss: 5.9772 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 2.0980 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 1.9131 - accuracy: 1.0000\n","Evaluating behaviour <face_lower_left>\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9397 - accuracy: 0.0000e+00\n","Evaluating behaviour <face_lower_right>\n","1/1 [==============================] - 0s 36ms/step - loss: 6.6068 - accuracy: 0.0000e+00\n","Evaluating behaviour <hands_up>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9745 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_up>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.1034 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_down>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.8209 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.6580 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_right>\n","1/1 [==============================] - 0s 37ms/step - loss: 6.3382 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_left>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.9176 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_upper_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.7218 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_left>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.9443 - accuracy: 0.0000e+00\n","Evaluating behaviour <look_lower_right>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.8507 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau1>\n","1/1 [==============================] - 0s 36ms/step - loss: 5.3483 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau4>\n","1/1 [==============================] - 0s 38ms/step - loss: 5.5235 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau5>\n","1/1 [==============================] - 0s 35ms/step - loss: 6.3498 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau7>\n","1/1 [==============================] - 0s 34ms/step - loss: 4.4889 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau9>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.2211 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau17>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.8077 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau23>\n","1/1 [==============================] - 0s 35ms/step - loss: 5.4217 - accuracy: 0.0000e+00\n","Evaluating behaviour <makefau28>\n","1/1 [==============================] - 0s 34ms/step - loss: 5.7965 - accuracy: 0.0000e+00\n","Model 156's accuracy is 0.0532258064516129\n"]}],"source":["import numpy as np\n","\n","model_accuracies = []\n","total_model_num = 157\n","\n","# beware, this chunk can take very long time to run\n","\n","# check current progress, and set i to current progress\n","with open(\"/content/drive/My Drive/model_weights/weights_evaluation.txt\", \"r\", encoding=\"utf-8\") as f:\n","    lines = f.readlines()\n","    count = sum(1 for s in lines if s.startswith(\"M\"))\n","\n","for i in range(count, total_model_num):\n","    print(\"Evaluating model {}\".format(i))\n","\n","    # get model accuracy for model i\n","    model_accuracy = evaluate_model(i, total_model_num)\n","\n","    with open(\"/content/drive/My Drive/model_weights/weights_evaluation.txt\", \"a\", encoding=\"utf-8\") as f:\n","        f.write(\"Model \" + str(i) + \": \" + str(model_accuracy))\n","        f.write(\"\\n\")\n","\n","    # add to total accuracy list\n","    model_accuracies.append(model_accuracy)\n","\n","    print(\"Model {}'s accuracy is {}\".format(i, model_accuracy))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4cpKlpQyrGYm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685082337766,"user_tz":-600,"elapsed":1031,"user":{"displayName":"凌豪","userId":"01537499298288856098"}},"outputId":"aa443796-5fc1-4f15-bbd8-9885c34c2c3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.2162162162162162, 0.2054054054054054, 0.2, 0.1891891891891892, 0.18918918918918917]\n"]}],"source":["def normalize_weights(array):\n","    total_sum = sum(array)\n","    normalized_array = [element / total_sum for element in array]\n","    return normalized_array\n","\n","def get_top_indices(array, num_indices):\n","    normalized_array = normalize_weights(array)\n","    indices = sorted(range(len(normalized_array)), key=lambda i: normalized_array[i], reverse=True)[:num_indices]\n","    return indices\n","\n","# calculate the weights based on each model's overall performance\n","evaluated_weights = []\n","\n","with open(\"/content/drive/My Drive/model_weights/weights_evaluation.txt\", \"r\", encoding=\"utf-8\") as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        evaluated_weights.append(float(line.split(\": \")[1]))\n","\n","# get the top 5 models who has the highest evaluation accuracy\n","top_5_models_idx = get_top_indices(evaluated_weights, 5)\n","\n","top_5_model_weights = []\n","for idx in top_5_models_idx:\n","    top_5_model_weights.append(evaluated_weights[idx])\n","\n","top_5_model_weights = normalize_weights(top_5_model_weights)\n","\n","print(top_5_model_weights)"]},{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","random_batch_value = random.randint(0, 156)\n","random_behaviour_value = random.randint(0 ,30)\n","random_batch_data_path = root_dir + str(random_batch_value) + '/'\n","behaviour_name = get_key_by_value(behaviours, random_behaviour_value)\n","\n","print(\"Testing with dataset {}, behaviour is {}\".format(str(random_batch_value), behaviour_name))\n","\n","x_test, y_test = prepare_test_data(random_batch_data_path, random_behaviour_value)\n","\n","# Reshape x_test to match the input shape of the trained model\n","x_test_reshaped = np.expand_dims(x_test, axis=0)  \n","\n","# Reshape y_test to match the expected shape of the labels\n","y_test_reshaped = np.expand_dims(y_test, axis=0)  \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gbtbKXnJQpv","executionInfo":{"status":"ok","timestamp":1685083412759,"user_tz":-600,"elapsed":33376,"user":{"displayName":"凌豪","userId":"01537499298288856098"}},"outputId":"a32aefe2-f1fb-4719-a74b-0d456991a4ed"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing with dataset 127, behaviour is makefau9\n"]}]},{"cell_type":"code","source":["%%time\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","\n","predictions = {}\n","\n","for model_idx in top_5_models_idx:\n","    model = load_model('/content/drive/My Drive/test_models2/model_' + str(model_idx) + '.h5', compile=False)\n","    probabilities = model.predict_on_batch(x_test_reshaped)\n","    predicted_class_probability = np.max(probabilities)\n","    predicted_class = np.argmax(probabilities, axis=1)\n","    predicted_class_probability *= top_5_model_weights[top_5_models_idx.index(model_idx)]\n","    predicted_label = get_key_by_value(behaviours, predicted_class)\n","    if predicted_label in predictions:\n","        predictions[predicted_label] += predicted_class_probability\n","    else:\n","        predictions[predicted_label] = predicted_class_probability\n","\n","print(\"Probabilities distribution:\")\n","print(predictions)\n","\n","prediction = max(predictions, key=lambda k: predictions[k])\n","print(\"Prediction is {}\".format(prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ur_SbD2YRZT7","executionInfo":{"status":"ok","timestamp":1685083416465,"user_tz":-600,"elapsed":3719,"user":{"displayName":"凌豪","userId":"01537499298288856098"}},"outputId":"fb1165f0-f45b-4e7a-9b68-50e5df5f8f7d"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilities distribution:\n","{'face_upper_right': 0.0768909808751699, 'face_upper_left': 0.028195442742592575, 'face_left': 0.02575189769268036}\n","Prediction is face_upper_right\n","CPU times: user 3.19 s, sys: 328 ms, total: 3.52 s\n","Wall time: 3.95 s\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM6PDEAr65Y/9+MTXm+p/qZ"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}